{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nguyen/projects/reinforce-ml\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scorer import Scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = 'In statistics, overfitting is \"the production of an analysis that corresponds too closely ' \\\n",
    "             'or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_nlp = model.nlp(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subm = 'When the model memorizes the training data and performs badly with the test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_nlp = model.nlp(user_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root score: 0.38894438104970114\n",
      "sentence similarity score: 0.8831680417060852\n",
      "bonus score: 0.5019652446111044\n",
      "total calculated score: 0.8454684919553543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84546849195535434"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(definition, user_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_pickle('data/180530_def.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.raw_data.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json1_data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'definition': 'Machine learning is a field of computer science that often uses statistical techniques to give computers the ability to \"learn\" (i.e., progressively improve performance on a specific task) with data, without being explicitly programmed.[1]', 'href': '/wiki/Machine_learning', 'section': 'Introduction and Main Principles', 'title': 'Machine learning'}\n",
      "{'definition': 'Numerical analysis\\xa0· Simulation', 'href': '/wiki/Data_analysis', 'section': 'Introduction and Main Principles', 'title': 'Data analysis'}\n",
      "{'definition': 'Occam\\'s razor (also Ockham\\'s razor or Ocham\\'s razor; Latin: lex parsimoniae \"law of parsimony\") is the problem-solving principle that, when presented with competing hypothetical answers to a problem, one should select the answer that makes the fewest assumptions. The idea is attributed to William of Ockham (c. 1287–1347), who was an English Franciscan friar, scholastic philosopher, and theologian.', 'href': '/wiki/Occam%27s_razor', 'section': 'Introduction and Main Principles', 'title': \"Occam's razor\"}\n",
      "{'definition': 'The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces (often with hundreds or thousands of dimensions) that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience. The expression was coined by Richard E. Bellman when considering problems in dynamic optimization.[1][2]', 'href': '/wiki/Curse_of_dimensionality', 'section': 'Introduction and Main Principles', 'title': 'Curse of dimensionality'}\n",
      "{'definition': 'In mathematical folklore, the \"no free lunch\" (NFL) theorem (sometimes pluralized) of David Wolpert and William Macready appears in the 1997 \"No Free Lunch Theorems for Optimization\".[1] Wolpert had previously derived no free lunch theorems for machine learning (statistical inference).[2]', 'href': '/wiki/No_free_lunch_theorem', 'section': 'Introduction and Main Principles', 'title': 'No free lunch theorem'}\n",
      "{'definition': 'The accuracy paradox for predictive analytics states that predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. It may be better to avoid the accuracy metric in favor of other metrics such as precision and recall.', 'href': '/wiki/Accuracy_paradox', 'section': 'Introduction and Main Principles', 'title': 'Accuracy paradox'}\n",
      "{'definition': 'In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\".[1] An overfitted model is a statistical model that contains more parameters than can be justified by the data.[2] The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.[3]:45', 'href': '/wiki/Overfitting', 'section': 'Introduction and Main Principles', 'title': 'Overfitting'}\n",
      "{'definition': 'In mathematics, statistics, and computer science, particularly in the fields of machine learning and inverse problems, regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.[1]', 'href': '/wiki/Regularization_(machine_learning)', 'section': 'Introduction and Main Principles', 'title': 'Regularization (machine learning)'}\n",
      "{'definition': 'The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs given inputs that it has not encountered.[1]', 'href': '/wiki/Inductive_bias', 'section': 'Introduction and Main Principles', 'title': 'Inductive bias'}\n",
      "{'definition': 'Data dredging (also data fishing, data snooping, and p-hacking) is the use of data mining to uncover patterns in data that can be presented as statistically significant, without first devising a specific hypothesis as to the underlying causality.', 'href': '/wiki/Data_dredging', 'section': 'Introduction and Main Principles', 'title': 'Data dredging'}\n",
      "{'definition': 'The Ugly Duckling theorem is an argument asserting that classification is impossible without some sort of bias. More particularly, it assumes finitely many properties combinable by logical connectives, and finitely many objects; it asserts that any two different objects share the same number of (extensional) properties. The theorem is named after Hans Christian Andersen\\'s story \"The Ugly Duckling\", because it shows that a duckling is just as similar to a swan as two duckling are to each other. It was proposed by Satosi Watanabe in 1969.[1]:376–377', 'href': '/wiki/Ugly_duckling_theorem', 'section': 'Introduction and Main Principles', 'title': 'Ugly duckling theorem'}\n",
      "{'definition': 'In computer science, uncertain data is data that contains noise that makes it deviate from the correct, intended or original values. In the age of big data, uncertainty or data veracity is one of the defining characteristics of data. Data is constantly growing in volume, variety, velocity and uncertainty (1/veracity). Uncertain data is found in abundance today on the web, in sensor networks, within enterprises both in their structured and unstructured sources. For example, there may be uncertainty regarding the address of a customer in an enterprise dataset, or the temperature readings captured by a sensor due to aging of the sensor. In 2012 IBM called out managing uncertain data at scale in its global technology outlook report[1] that presents a comprehensive analysis looking three to ten years into the future seeking to identify significant, disruptive technologies that will change the world. In order to make confident business decisions based on real-world data, analyses must necessarily account for many different kinds of uncertainty present in very large amounts of data. Analyses based on uncertain data will have an effect on the quality of subsequent decisions, so the degree and types of inaccuracies in this uncertain data cannot be ignored.', 'href': '/wiki/Uncertain_data', 'section': 'Introduction and Main Principles', 'title': 'Uncertain data'}\n",
      "{'definition': 'Knowledge extraction is the creation of knowledge from structured (relational databases, XML) and unstructured (text, documents, images) sources. The resulting knowledge needs to be in a machine-readable and machine-interpretable format and must represent knowledge in a manner that facilitates inferencing. Although it is methodically similar to information extraction (NLP) and ETL (data warehouse), the main criteria is that the extraction result goes beyond the creation of structured information or the transformation into a relational schema. It requires either the reuse of existing formal knowledge (reusing identifiers or ontologies) or the generation of a schema based on the source data.', 'href': '/wiki/Knowledge_discovery', 'section': 'Background and Preliminaries', 'title': 'Knowledge discovery'}\n",
      "{'definition': 'Data mining is the process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.[1] It is an essential process where intelligent methods are applied to extract data patterns.[1][2] It is an interdisciplinary subfield of computer science.[1][3][4] The overall goal of the data mining process is to extract information from a data set and transform it into an understandable structure for further use.[1] Aside from the raw analysis step, it involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.[1] Data mining is the analysis step of the \"knowledge discovery in databases\" process, or KDD.[5]', 'href': '/wiki/Data_mining', 'section': 'Background and Preliminaries', 'title': 'Data mining'}\n",
      "{'definition': 'Predictive analytics encompasses a variety of statistical techniques from predictive modelling, machine learning, and data mining that analyze current and historical facts to make predictions about future or otherwise unknown events.[1][2]', 'href': '/wiki/Predictive_analytics', 'section': 'Background and Preliminaries', 'title': 'Predictive analytics'}\n",
      "{'definition': 'Predictive modelling uses statistics to predict outcomes.[1] Most often the event one wants to predict is in the future, but predictive modelling can be applied to any type of unknown event, regardless of when it occurred. For example, predictive models are often used to detect crimes and identify suspects, after the crime has taken place.[2]', 'href': '/wiki/Predictive_modelling', 'section': 'Background and Preliminaries', 'title': 'Predictive modelling'}\n",
      "{'definition': 'Business intelligence (BI) comprises the strategies and technologies used by enterprises for the data analysis of business information.[1] BI technologies provide historical, current and predictive views of business operations. Common functions of business intelligence technologies include reporting, online analytical processing, analytics, data mining, process mining, complex event processing, business performance management, benchmarking, text mining, predictive analytics and prescriptive analytics. BI technologies can handle large amounts of structured and sometimes unstructured data to help identify, develop and otherwise create new strategic business opportunities. They aim to allow for the easy interpretation of these big data. Identifying new opportunities and implementing an effective strategy based on insights can provide businesses with a competitive market advantage and long-term stability.[2]', 'href': '/wiki/Business_intelligence', 'section': 'Background and Preliminaries', 'title': 'Business intelligence'}\n",
      "{'definition': 'LIONsolver is an integrated software for data mining, business intelligence, analytics, and modeling Learning and Intelligent OptimizatioN[1] and reactive business intelligence approach.[2] A non-profit version is available as LIONoso.', 'href': '/wiki/Reactive_business_intelligence', 'section': 'Background and Preliminaries', 'title': 'Reactive business intelligence'}\n",
      "{'definition': 'Business analytics (BA) refers to the skills, technologies, practices for continuous iterative exploration and investigation of past business performance to gain insight and drive business planning.[1] Business analytics focuses on developing new insights and understanding of business performance based on data and statistical methods. In contrast, business intelligence traditionally focuses on using a consistent set of metrics to both measure past performance and guide business planning, which is also based on data and statistical methods.[citation needed]', 'href': '/wiki/Business_analytics', 'section': 'Background and Preliminaries', 'title': 'Business analytics'}\n",
      "{'definition': 'LIONsolver is an integrated software for data mining, business intelligence, analytics, and modeling Learning and Intelligent OptimizatioN[1] and reactive business intelligence approach.[2] A non-profit version is available as LIONoso.', 'href': '/wiki/Reactive_business_intelligence', 'section': 'Background and Preliminaries', 'title': 'Reactive business intelligence'}\n",
      "{'definition': 'Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data, although it is in some cases considered to be nearly synonymous with machine learning.[1] Pattern recognition systems are in many cases trained from labeled \"training\" data (supervised learning), but when no labeled data are available other algorithms can be used to discover previously unknown patterns (unsupervised learning).', 'href': '/wiki/Pattern_recognition', 'section': 'Background and Preliminaries', 'title': 'Pattern recognition'}\n",
      "{'definition': 'Abductive reasoning (also called abduction,[1] abductive inference,[1] or retroduction[2]) is a form of logical inference which starts with an observation or set of observations then seeks to find the simplest and most likely explanation. In abductive reasoning, unlike in deductive reasoning, the premises do not guarantee the conclusion. One can understand abductive reasoning as inference to the best explanation,[3] although not all uses of the terms abduction and inference to the best explanation are exactly equivalent.[4][5]', 'href': '/wiki/Abductive_reasoning', 'section': 'Reasoning', 'title': 'Abductive reasoning'}\n",
      "{'definition': 'Inductive reasoning (as opposed to deductive reasoning or abductive reasoning) is a method of reasoning in which the premises are viewed as supplying some evidence for the truth of the conclusion. While the conclusion of a deductive argument is certain, the truth of the conclusion of an inductive argument may be probable, based upon the evidence given.[1]', 'href': '/wiki/Inductive_reasoning', 'section': 'Reasoning', 'title': 'Inductive reasoning'}\n",
      "{'definition': 'First-order logic—also known as first-order predicate calculus and predicate logic—is a collection of formal systems used in mathematics, philosophy, linguistics, and computer science. First-order logic uses quantified variables over non-logical objects and allows the use of sentences that contain variables, so that rather than propositions such as Socrates is a man one can have expressions in the form \"there exists X such that X is Socrates and X is a man\" and there exists is a quantifier while X is a variable.[1] This distinguishes it from propositional logic, which does not use quantifiers or relations.[2]', 'href': '/wiki/First-order_logic', 'section': 'Reasoning', 'title': 'First-order logic'}\n",
      "{'definition': 'Inductive logic programming (ILP) is a subfield of machine learning which uses logic programming as a uniform representation for examples, background knowledge and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesised logic program which entails all the positive and none of the negative examples.', 'href': '/wiki/Inductive_logic_programming', 'section': 'Reasoning', 'title': 'Inductive logic programming'}\n",
      "{'definition': 'In information technology a reasoning system is a software system that generates conclusions from available knowledge using logical techniques such as deduction and induction. Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems.', 'href': '/wiki/Reasoning_system', 'section': 'Reasoning', 'title': 'Reasoning system'}\n",
      "{'definition': 'Case-based reasoning (CBR), broadly construed, is the process of solving new problems based on the solutions of similar past problems. An auto mechanic who fixes an engine by recalling another car that exhibited similar symptoms is using case-based reasoning. A lawyer who advocates a particular outcome in a trial based on legal precedents or a judge who creates case law is using case-based reasoning. So, too, an engineer copying working elements of nature (practicing biomimicry), is treating nature as a database of solutions to problems. Case-based reasoning is a prominent type of analogy solution making.', 'href': '/wiki/Case-based_reasoning', 'section': 'Reasoning', 'title': 'Case-based reasoning'}\n",
      "{'definition': 'Textual case-based reasoning is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence. CBR suggests the ways to use past experiences to solve future similar problems, requiring that past experiences be structured in a form similar to attribute - value pairs. This leads to the investigation of textual descriptions for knowledge exploration whose output will be, in turn, used to solve similar problems.[1]', 'href': '/wiki/Textual_case_based_reasoning', 'section': 'Reasoning', 'title': 'Textual case based reasoning'}\n",
      "{'definition': 'Causality (also referred to as causation,[1] or cause and effect) is what connects one process (the cause) with another process or state (the effect),[citation needed] where the first is partly responsible for the second, and the second is partly dependent on the first. In general, a process has many causes,[2] which are said to be causal factors for it, and all lie in its past. An effect can in turn be a cause of, or causal factor for, many other effects, which all lie in its future. Causality is metaphysically prior to notions of time and space.[3][4]', 'href': '/wiki/Causality', 'section': 'Reasoning', 'title': 'Causality'}\n",
      "{'definition': 'Nearest neighbor search (NNS), as a form of proximity search, is the optimization problem of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set S of points in a space M and a query point q\\xa0∈\\xa0M, find the closest point in S to q. Donald Knuth in vol. 3 of The Art of Computer Programming (1973) called it the post-office problem, referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a k-NN search, where we need to find the k closest points.', 'href': '/wiki/Nearest_neighbor_search', 'section': 'Search Methods', 'title': 'Nearest neighbor search'}\n",
      "{'definition': 'Stochastic gradient descent (often shortened to SGD), also known as incremental gradient descent, is a stochastic approximation of the gradient descent optimization and iterative method for minimizing an objective function that is written as a sum of differentiable functions. In essence, SGD tries to find minima or maxima by iteration.', 'href': '/wiki/Stochastic_gradient_descent', 'section': 'Search Methods', 'title': 'Stochastic gradient descent'}\n",
      "{'definition': 'In computer science, beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. Beam search is an optimization of best-first search that reduces its memory requirements. Best-first search is a graph search which orders all partial solutions (states) according to some heuristic which attempts to predict how close a partial solution is to a complete solution (goal state). But in beam search, only a predetermined number of best partial solutions are kept as candidates.[1] It is thus a greedy algorithm.', 'href': '/wiki/Beam_search', 'section': 'Search Methods', 'title': 'Beam search'}\n",
      "{'definition': 'Best-first search is a search algorithm which explores a graph by expanding the most promising node chosen according to a specified rule.', 'href': '/wiki/Best-first_search', 'section': 'Search Methods', 'title': 'Best-first search'}\n",
      "{'definition': \"Breadth-first search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root (or some arbitrary node of a graph, sometimes referred to as a 'search key'[1]) and explores the neighbor nodes first, before moving to the next level neighbors.\", 'href': '/wiki/Breadth-first_search', 'section': 'Search Methods', 'title': 'Breadth-first search'}\n",
      "{'definition': 'In numerical analysis, hill climbing is a mathematical optimization technique which belongs to the family of local search. It is an iterative algorithm that starts with an arbitrary solution to a problem, then attempts to find a better solution by making an incremental change to the solution. If the change produces a better solution, another incremental change is made to the new solution, and so on until no further improvements can be found.', 'href': '/wiki/Hill_climbing', 'section': 'Search Methods', 'title': 'Hill climbing'}\n",
      "{'definition': 'In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.', 'href': '/wiki/Grid_search', 'section': 'Search Methods', 'title': 'Grid search'}\n",
      "{'definition': \"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement.\", 'href': '/wiki/Brute-force_search', 'section': 'Search Methods', 'title': 'Brute-force search'}\n",
      "{'definition': 'Depth-first search (DFS) is an algorithm for traversing or searching tree or graph data structures. One starts at the root (selecting some arbitrary node as the root in the case of a graph) and explores as far as possible along each branch before backtracking.', 'href': '/wiki/Depth-first_search', 'section': 'Search Methods', 'title': 'Depth-first search'}\n",
      "{'definition': 'Tabu search, created by Fred W. Glover in 1986[1] and formalized in 1989,[2][3] is a metaheuristic search method employing local search methods used for mathematical optimization.', 'href': '/wiki/Tabu_search', 'section': 'Search Methods', 'title': 'Tabu search'}\n",
      "{'definition': 'In computer science, an anytime algorithm is an algorithm that can return a valid solution to a problem even if it is interrupted before it ends. The algorithm is expected to find better and better solutions the more time it keeps running.', 'href': '/wiki/Anytime_algorithm', 'section': 'Search Methods', 'title': 'Anytime algorithm'}\n",
      "{'definition': 'In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA),[1] which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.', 'href': '/wiki/Exploratory_data_analysis', 'section': 'Statistics', 'title': 'Exploratory data analysis'}\n",
      "{'definition': 'In mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables represent inputs or causes, i.e., potential reasons for variation or, in the experimental setting, the variable controlled by the experimenter. Models and experiments test or determine the effects that the independent variables have on the dependent variables. Sometimes, independent variables may be included for other reasons, such as for their potential confounding effect, without a wish to test their effect directly.', 'href': '/wiki/Covariate', 'section': 'Statistics', 'title': 'Covariate'}\n",
      "{'definition': 'Statistical inference is the process of using data analysis to deduce properties of an underlying probability distribution.[1] Inferential statistical analysis infers properties of a population, for example by testing hypotheses and deriving estimates. It is assumed that the observed data set is sampled from a larger population.', 'href': '/wiki/Statistical_inference', 'section': 'Statistics', 'title': 'Statistical inference'}\n",
      "{'definition': 'Algorithmic inference gathers new developments in the statistical inference methods made feasible by the powerful computing devices widely available to any data analyst. Cornerstones in this field are computational learning theory, granular computing, bioinformatics, and, long ago, structural probability (Fraser 1966). The main focus is on the algorithms which compute statistics rooting the study of a random phenomenon, along with the amount of data they must feed on to produce reliable results. This shifts the interest of mathematicians from the study of the distribution laws to the functional properties of the statistics, and the interest of computer scientists from the algorithms for processing data to the information they process.', 'href': '/wiki/Algorithmic_inference', 'section': 'Statistics', 'title': 'Algorithmic inference'}\n",
      "{'definition': 'Bayesian inference is a method of statistical inference in which Bayes\\' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. Bayesian updating is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called \"Bayesian probability\".', 'href': '/wiki/Bayesian_inference', 'section': 'Statistics', 'title': 'Bayesian inference'}\n",
      "{'definition': 'In probability and statistics, base rate generally refers to the (base) class probabilities unconditioned on featural evidence, frequently also known as prior probabilities. For example, if it were the case that 1% of the public were \"medical professionals\", and 99% of the public were not \"medical professionals\", then the base rate of medical professionals is simply 1%.', 'href': '/wiki/Base_rate', 'section': 'Statistics', 'title': 'Base rate'}\n",
      "{'definition': 'Statistical bias is a feature of a statistical technique or of its results whereby the expected value of the results differs from the true underlying quantitative parameter being estimated.', 'href': '/wiki/Bias_(statistics)', 'section': 'Statistics', 'title': 'Bias (statistics)'}\n",
      "{'definition': 'In statistics, Gibbs sampling or a Gibbs sampler is a Markov chain Monte Carlo (MCMC) algorithm for obtaining a sequence of observations which are approximated from a specified multivariate probability distribution, when direct sampling is difficult. This sequence can be used to approximate the joint distribution (e.g., to generate a histogram of the distribution); to approximate the marginal distribution of one of the variables, or some subset of the variables (for example, the unknown parameters or latent variables); or to compute an integral (such as the expected value of one of the variables). Typically, some of the variables correspond to observations whose values are known, and hence do not need to be sampled.', 'href': '/wiki/Gibbs_sampling', 'section': 'Statistics', 'title': 'Gibbs sampling'}\n",
      "{'definition': 'The cross-entropy (CE) method developed by Reuven Rubinstein is a general Monte Carlo approach to combinatorial and continuous multi-extremal optimization and importance sampling. The method originated from the field of rare event simulation, where very small probabilities need to be accurately estimated, for example in network reliability analysis, queueing models, or performance analysis of telecommunication systems. The CE method can be applied to static and noisy combinatorial optimization problems such as the traveling salesman problem, the quadratic assignment problem, DNA sequence alignment, the max-cut problem and the buffer allocation problem, as well as continuous global optimization problems with many local extrema.', 'href': '/wiki/Cross-entropy_method', 'section': 'Statistics', 'title': 'Cross-entropy method'}\n",
      "{'definition': 'In statistics, latent variables (from Latin: present participle of lateo (“lie hidden”), as opposed to observable variables), are variables that are not directly observed but are rather inferred (through a mathematical model) from other variables that are observed (directly measured). Mathematical models that aim to explain observed variables in terms of latent variables are called latent variable models. Latent variable models are used in many disciplines, including psychology, demography, economics, engineering, medicine, physics, machine learning/artificial intelligence, bioinformatics, natural language processing, econometrics, management and the social sciences.', 'href': '/wiki/Latent_variable', 'section': 'Statistics', 'title': 'Latent variable'}\n",
      "{'definition': 'In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model, given observations. MLE attempts to find the parameter values that maximize the likelihood function, given the observations. The resulting estimate is called a maximum likelihood estimate, which is also abbreviated as MLE.', 'href': '/wiki/Maximum_likelihood', 'section': 'Statistics', 'title': 'Maximum likelihood'}\n",
      "{'definition': 'In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data. It is closely related to the method of maximum likelihood (ML) estimation, but employs an augmented optimization objective which incorporates a prior distribution (that quantifies the additional information available through prior knowledge of a related event) over the quantity one wants to estimate. MAP estimation can therefore be seen as a regularization of ML estimation.', 'href': '/wiki/Maximum_a_posteriori_estimation', 'section': 'Statistics', 'title': 'Maximum a posteriori estimation'}\n",
      "{'definition': 'In statistics, an expectation–maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.', 'href': '/wiki/Expectation%E2%80%93maximization_algorithm', 'section': 'Statistics', 'title': 'Expectation–maximization algorithm'}\n",
      "{'definition': 'Expectation propagation (EP) is a technique in Bayesian machine learning.', 'href': '/wiki/Expectation_propagation', 'section': 'Statistics', 'title': 'Expectation propagation'}\n",
      "{'definition': 'In mathematical statistics, the Kullback–Leibler divergence (also called relative entropy) is a measure of how one probability distribution diverges from a second, expected probability distribution.[1][2] Applications include characterizing the relative (Shannon) entropy in information systems, randomness in continuous time-series, and information gain when comparing statistical models of inference. In contrast to variation of information, it is a distribution-wise asymmetric measure and thus does not qualify as a statistical metric of spread. In the simple case, a Kullback–Leibler divergence of 0 indicates that we can expect similar, if not the same, behavior of two different distributions, while a Kullback–Leibler divergence of 1 indicates that the two distributions behave in such a different manner that the expectation given the first distribution approaches zero. In simplified terms, it is a measure of surprise, with diverse applications such as applied statistics, fluid mechanics, neuroscience and machine learning.', 'href': '/wiki/Kullback%E2%80%93Leibler_divergence', 'section': 'Statistics', 'title': 'Kullback–Leibler divergence'}\n",
      "{'definition': 'In statistical classification, including machine learning, two main approaches are called the generative approach and the discriminative approach. These compute classifiers by different approaches, differing in the degree of statistical modelling. Terminology is inconsistent,[a] but three major types can be distinguished, following (Jebara 2004). Given an observable variable X and a target variable Y, a generative model is a statistical model of the joint probability distribution on X\\xa0×\\xa0Y, \\n\\n\\n\\nP\\n(\\nX\\n,\\nY\\n)\\n\\n\\n{\\\\displaystyle P(X,Y)}\\n\\n;[1] a discriminative model is a model of the conditional probability of the target Y, given an observation x, symbolically, \\n\\n\\n\\nP\\n(\\nY\\n\\n|\\n\\nX\\n=\\nx\\n)\\n\\n\\n{\\\\displaystyle P(Y|X=x)}\\n\\n; and classifiers computed without using a probability model are also referred to loosely as \"discriminative\". The distinction between these last two classes is not consistently made;[2] (Jebara 2004) refers to these three classes as generative learning, conditional learning, and discriminative learning, but (Ng & Jordan 2002) only distinguishes two classes, calling them generative classifiers (joint distribution) and discriminative classifiers (conditional distribution or no distribution), not distinguishing between the latter two classes.[3] Analogously, a classifier based on a generative model is a generative classifier, while a classifier based on a discriminative model is a discriminative classifier, though this term also refers to classifiers that are not based on a model. Standard examples of each, all of which are linear classifiers, are: generative classifiers: naive Bayes classifier and linear discriminant analysis; discriminative model: logistic regression; non-model classifier: perceptron and support vector machine.', 'href': '/wiki/Generative_model', 'section': 'Statistics', 'title': 'Generative model'}\n",
      "{'definition': 'Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.[1] It infers a function from labeled training data consisting of a set of training examples.[2] In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias).', 'href': '/wiki/Supervised_learning', 'section': 'Main Learning Paradigms', 'title': 'Supervised learning'}\n",
      "{'definition': 'Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from \"unlabeled\" data (a classification or categorization is not included in the observations). Since the examples given to the learner are unlabeled, there is no evaluation of the accuracy of the structure that is output by the relevant algorithm—which is one way of distinguishing unsupervised learning from supervised learning and reinforcement learning.', 'href': '/wiki/Unsupervised_learning', 'section': 'Main Learning Paradigms', 'title': 'Unsupervised learning'}\n",
      "{'definition': 'Active learning is a special case of semi-supervised machine learning in which a learning algorithm is able to interactively query the user (or some other information source) to obtain the desired outputs at new data points.[1] [2] [3] In statistics literature it is sometimes also called optimal experimental design. [4]', 'href': '/wiki/Active_learning_(machine_learning)', 'section': 'Main Learning Paradigms', 'title': 'Active learning (machine learning)'}\n",
      "{'definition': 'Reinforcement learning (RL) is an area of machine learning inspired by behaviourist psychology[citation needed], concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In the operations research and control literature, reinforcement learning is called approximate dynamic programming, or neuro-dynamic programming.[1][2] The problems of interest in reinforcement learning have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation, particularly in the absence of a mathematical model of the environment. In economics and game theory, reinforcement learning may be used to explain how equilibrium may arise under bounded rationality.[citation needed]', 'href': '/wiki/Reinforcement_learning', 'section': 'Main Learning Paradigms', 'title': 'Reinforcement learning'}\n",
      "{'definition': 'Multi-task learning (MTL) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks. This can result in improved learning efficiency and prediction accuracy for the task-specific models, when compared to training the models separately.[1][2][3] Early versions of MTL were called \"hints\"[4][5]', 'href': '/wiki/Multi-task_learning', 'section': 'Main Learning Paradigms', 'title': 'Multi-task learning'}\n",
      "{'definition': 'In logic, statistical inference, and supervised learning, transduction or transductive inference is reasoning from observed, specific (training) cases to specific (test) cases. In contrast, induction is reasoning from observed training cases to general rules, which are then applied to the test cases. The distinction is most interesting in cases where the predictions of the transductive model are not achievable by any inductive model. Note that this is caused by transductive inference on different test sets producing mutually inconsistent predictions.', 'href': '/wiki/Transduction_(machine_learning)', 'section': 'Main Learning Paradigms', 'title': 'Transduction (machine learning)'}\n",
      "{'definition': 'Explanation-based learning (EBL) is a form of machine learning that exploits a very strong, or even perfect, domain theory in order to make generalizations or form concepts from training examples.[1]', 'href': '/wiki/Explanation-based_learning', 'section': 'Main Learning Paradigms', 'title': 'Explanation-based learning'}\n",
      "{'definition': 'In machine learning, systems which employ offline learning do not change their approximation of the target function when the initial training phase has been completed.[citation needed] These systems are also typically examples of eager learning.[citation needed]', 'href': '/wiki/Offline_learning', 'section': 'Main Learning Paradigms', 'title': 'Offline learning'}\n",
      "{'definition': 'In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update our best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g. stock price prediction. Online learning algorithms may be prone to catastrophic interference. This problem is tackled by incremental learning approaches.', 'href': '/wiki/Online_learning_model', 'section': 'Main Learning Paradigms', 'title': 'Online learning model'}\n",
      "{'definition': 'In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update our best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g. stock price prediction. Online learning algorithms may be prone to catastrophic interference. This problem is tackled by incremental learning approaches.', 'href': '/wiki/Online_machine_learning', 'section': 'Main Learning Paradigms', 'title': 'Online machine learning'}\n",
      "{'definition': 'In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.', 'href': '/wiki/Hyperparameter_optimization', 'section': 'Main Learning Paradigms', 'title': 'Hyperparameter optimization'}\n",
      "{'definition': 'In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (gender, blood pressure, presence or absence of certain symptoms, etc.). Classification is an example of pattern recognition.', 'href': '/wiki/Classification_in_machine_learning', 'section': 'Classification Tasks', 'title': 'Classification in machine learning'}\n",
      "{'definition': 'A concept over a domain X is a total Boolean function over X. A concept class is a class of concepts. Concept class is a subject of computational learning theory.', 'href': '/wiki/Concept_class', 'section': 'Classification Tasks', 'title': 'Concept class'}\n",
      "{'definition': 'In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed.[1] Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of \"feature\" is related to that of explanatory variable used in statistical techniques such as linear regression.', 'href': '/wiki/Features_(pattern_recognition)', 'section': 'Classification Tasks', 'title': 'Features (pattern recognition)'}\n",
      "{'definition': 'In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed.[1] Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of \"feature\" is related to that of explanatory variable used in statistical techniques such as linear regression.', 'href': '/wiki/Feature_vector', 'section': 'Classification Tasks', 'title': 'Feature vector'}\n",
      "{'definition': 'In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed.[1] Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of \"feature\" is related to that of explanatory variable used in statistical techniques such as linear regression.', 'href': '/wiki/Feature_space', 'section': 'Classification Tasks', 'title': 'Feature space'}\n",
      "{'definition': 'Concept learning, also known as category learning, concept attainment, and concept formation, is defined by Bruner, Goodnow, & Austin (1967) as \"the search for and listing of attributes that can be used to distinguish exemplars from non exemplars of various categories\". More simply put, concepts are the mental categories that help us classify objects, events, or ideas, building on the understanding that each object, event, or idea has a set of common relevant features. Thus, concept learning is a strategy which requires a learner to compare and contrast groups or categories that contain concept-relevant features with groups or categories that do not contain concept-relevant features.', 'href': '/wiki/Concept_learning', 'section': 'Classification Tasks', 'title': 'Concept learning'}\n",
      "{'definition': 'Binary or binomial classification is the task of classifying the elements of a given set into two groups (predicting which group each one belongs to) on the basis of a classification rule. Contexts requiring a decision as to whether or not an item has some qualitative property, some specified characteristic, or some typical binary classification include:', 'href': '/wiki/Binary_classification', 'section': 'Classification Tasks', 'title': 'Binary classification'}\n",
      "{'definition': 'In a statistical-classification problem with two classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class.', 'href': '/wiki/Decision_boundary', 'section': 'Classification Tasks', 'title': 'Decision boundary'}\n",
      "{'definition': 'Not to be confused with multi-label classification.', 'href': '/wiki/Multiclass_classification', 'section': 'Classification Tasks', 'title': 'Multiclass classification'}\n",
      "{'definition': 'In machine learning, a probabilistic classifier is a classifier that is able to predict, given an observation of an input, a probability distribution over a set of classes, rather than only outputting the most likely class that the observation should belong to. Probabilistic classifiers provide classification that can be useful in its own right[1] or when combining classifiers into ensembles.', 'href': '/wiki/Class_membership_probabilities', 'section': 'Classification Tasks', 'title': 'Class membership probabilities'}\n",
      "{'definition': 'There are two main uses of the term calibration in statistics that denote special types of statistical inference problems. Thus \"calibration\" can mean', 'href': '/wiki/Calibration_(statistics)', 'section': 'Classification Tasks', 'title': 'Calibration (statistics)'}\n",
      "{'definition': 'In predictive analytics and machine learning, the concept drift means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways. This causes problems because the predictions become less accurate as time passes.', 'href': '/wiki/Concept_drift', 'section': 'Classification Tasks', 'title': 'Concept drift'}\n",
      "{'definition': 'Pattern recognition is a very active field of research intimately bound to machine learning. Also known as classification or statistical classification, pattern recognition aims at building a classifier that can determine the class of an input pattern. This procedure, known as training, corresponds to learning an unknown decision function based only on a set of input-output pairs \\n\\n\\n\\n(\\n\\n\\nx\\n\\n\\ni\\n\\n\\n,\\n\\ny\\n\\ni\\n\\n\\n)\\n\\n\\n{\\\\displaystyle ({\\\\boldsymbol {x}}_{i},y_{i})}\\n\\n that form the training data (or training set). Nonetheless, in real world applications such as character recognition, a certain amount of information on the problem is usually known beforehand. The incorporation of this prior knowledge into the training is the key element that will allow an increase of performance in many applications.', 'href': '/wiki/Prior_knowledge_for_pattern_recognition', 'section': 'Classification Tasks', 'title': 'Prior knowledge for pattern recognition'}\n",
      "{'definition': 'The Iris flower data set or Fisher\\'s Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson\\'s Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gaspé Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]', 'href': '/wiki/Iris_flower_data_set', 'section': 'Classification Tasks', 'title': 'Iris flower data set'}\n",
      "{'definition': 'Margin-infused relaxed algorithm (MIRA)[1] is a machine learning algorithm, an online algorithm for multiclass classification problems. It is designed to learn a set of parameters (vector or matrix) by processing all the given training examples one-by-one and updating the parameters according to each training example, so that the current training example is classified correctly with a margin against incorrect classifications at least as large as their loss.[2] The change of the parameters is kept as small as possible.', 'href': '/wiki/Margin_Infused_Relaxed_Algorithm', 'section': 'Online Learning', 'title': 'Margin Infused Relaxed Algorithm'}\n",
      "{'definition': 'Semi-supervised learning is a class of supervised learning tasks and techniques that also make use of unlabeled data for training – typically a small amount of labeled data with a large amount of unlabeled data. Semi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render a fully labeled training set infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value. Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.', 'href': '/wiki/Semi-supervised_learning', 'section': 'Semi-supervised learning', 'title': 'Semi-supervised learning'}\n",
      "{'definition': \"In machine learning, one-class classification, also known as unary classification or class-modelling, tries to identify objects of a specific class amongst all objects, by learning from a training set containing only the objects of that class[1]. This is different from and more difficult than the traditional classification problem, which tries to distinguish between two or more classes with the training set containing objects from all the classes. An example is the classification of the operational status of a nuclear plant as 'normal':[2] In this scenario, there are few, if any, examples of catastrophic system states; only the statistics of normal operation are known. The term one-class classification was coined by Moya & Hush (1996)[3] and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection. A feature of one-class classification is that it uses only sample points from the assigned class, so that a representative sampling is not strictly required for non-target classes.[4]\", 'href': '/wiki/One-class_classification', 'section': 'Semi-supervised learning', 'title': 'One-class classification'}\n",
      "{'definition': 'Coupled Pattern Learner (CPL) is a machine learning algorithm which couples the semi-supervised learning of categories and relations to forestall the problem of semantic drift associated with boot-strap learning methods.', 'href': '/wiki/Coupled_pattern_learner', 'section': 'Semi-supervised learning', 'title': 'Coupled pattern learner'}\n",
      "{'definition': 'In machine learning, lazy learning is a learning method in which generalization of the training data is delayed until a query is made to the system, as opposed to in eager learning, where the system tries to generalize the training data before receiving queries.', 'href': '/wiki/Lazy_learning', 'section': 'Lazy learning and nearest neighbors', 'title': 'Lazy learning'}\n",
      "{'definition': 'In artificial intelligence, eager learning is a learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to lazy learning, where generalization beyond the training data is delayed until a query is made to the system. [1] The main advantage gained in employing an eager learning method, such as an artificial neural network, is that the target function will be approximated globally during training, thus requiring much less space than using a lazy learning system. Eager learning systems also deal much better with noise in the training data. Eager learning is an example of offline learning, in which post-training queries to the system have no effect on the system itself, and thus the same query to the system will always produce the same result.', 'href': '/wiki/Eager_learning', 'section': 'Lazy learning and nearest neighbors', 'title': 'Eager learning'}\n",
      "{'definition': 'In machine learning, instance-based learning (sometimes called memory-based learning[1]) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.', 'href': '/wiki/Instance-based_learning', 'section': 'Lazy learning and nearest neighbors', 'title': 'Instance-based learning'}\n",
      "{'definition': 'In machine learning and information retrieval, the cluster hypothesis is an assumption about the nature of the data handled in those fields, which takes various forms. In information retrieval, it states that documents that are clustered together \"behave similarly with respect to relevance to information needs\".[1] In terms of classification, it states that if points are in the same cluster, they are likely to be of the same class.[2] There may be multiple clusters forming a single class.', 'href': '/wiki/Cluster_assumption', 'section': 'Lazy learning and nearest neighbors', 'title': 'Cluster assumption'}\n",
      "{'definition': 'In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression.[1] In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:', 'href': '/wiki/K-nearest_neighbor_algorithm', 'section': 'Lazy learning and nearest neighbors', 'title': 'K-nearest neighbor algorithm'}\n",
      "{'definition': 'In pattern recognition, the iDistance is an indexing and query processing technique for k-nearest neighbor queries on point data in multi-dimensional metric spaces. The kNN query is one of the hardest problems on multi-dimensional data, especially when the dimensionality of the data is high. The iDistance is designed to process kNN queries in high-dimensional spaces efficiently and it is especially good for skewed data distributions, which usually occur in real-life data sets.', 'href': '/wiki/IDistance', 'section': 'Lazy learning and nearest neighbors', 'title': 'IDistance'}\n",
      "{'definition': 'Large margin nearest neighbor (LMNN)[1] classification is a statistical machine learning algorithm for metric learning. It learns a pseudometric designed for k-nearest neighbor classification. The algorithm is based on semidefinite programming, a sub-class of convex optimization.', 'href': '/wiki/Large_margin_nearest_neighbor', 'section': 'Lazy learning and nearest neighbors', 'title': 'Large margin nearest neighbor'}\n",
      "{'definition': \"Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.\", 'href': '/wiki/Decision_tree_learning', 'section': 'Decision Trees', 'title': 'Decision tree learning'}\n",
      "{'definition': 'A decision stump is a machine learning model consisting of a one-level decision tree.[1] That is, it is a decision tree with one internal node (the root) which is immediately connected to the terminal nodes (its leaves). A decision stump makes a prediction based on the value of just a single input feature. Sometimes they are also called 1-rules.[2]', 'href': '/wiki/Decision_stump', 'section': 'Decision Trees', 'title': 'Decision stump'}\n",
      "{'definition': 'Pruning is a technique in machine learning that reduces the size of decision trees by removing sections of the tree that provide little power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.', 'href': '/wiki/Pruning_(decision_trees)', 'section': 'Decision Trees', 'title': 'Pruning (decision trees)'}\n",
      "{'definition': 'In probability theory and information theory, the mutual information (MI) of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the \"amount of information\" (in units such as shannons, more commonly called bits) obtained about one random variable, through the other random variable. The concept of mutual information is intricately linked to that of entropy of a random variable, a fundamental notion in information theory, that defines the \"amount of information\" held in a random variable.', 'href': '/wiki/Mutual_information', 'section': 'Decision Trees', 'title': 'Mutual information'}\n",
      "{'definition': 'In probability theory and information theory, adjusted mutual information, a variation of mutual information may be used for comparing clusterings.[1] It corrects the effect of agreement solely due to chance between clusterings, similar to the way the adjusted rand index corrects the Rand index. It is closely related to variation of information:[2] when a similar adjustment is made to the VI index, it becomes equivalent to the AMI.[1] The adjusted measure however is no longer metrical.[3]', 'href': '/wiki/Adjusted_mutual_information', 'section': 'Decision Trees', 'title': 'Adjusted mutual information'}\n",
      "{'definition': 'In decision tree learning, Information gain ratio is a ratio of information gain to the intrinsic information. It is used to reduce a bias towards multi-valued attributes by taking the number and size of branches into account when choosing an attribute.[1]', 'href': '/wiki/Information_gain_ratio', 'section': 'Decision Trees', 'title': 'Information gain ratio'}\n",
      "{'definition': 'In information theory and machine learning, information gain is a synonym for Kullback–Leibler divergence. However, in the context of decision trees, the term is sometimes used synonymously with mutual information, which is the expected value of the Kullback–Leibler divergence of the univariate probability distribution of one variable from the conditional distribution of this variable given the other one.', 'href': '/wiki/Information_gain_in_decision_trees', 'section': 'Decision Trees', 'title': 'Information gain in decision trees'}\n",
      "{'definition': 'In decision tree learning, ID3 (Iterative Dichotomiser 3) is an algorithm invented by Ross Quinlan[1] used to generate a decision tree from a dataset. ID3 is the precursor to the C4.5 algorithm, and is typically used in the machine learning and natural language processing domains.', 'href': '/wiki/ID3_algorithm', 'section': 'Decision Trees', 'title': 'ID3 algorithm'}\n",
      "{'definition': 'C4.5 is an algorithm used to generate a decision tree developed by Ross Quinlan.[1] C4.5 is an extension of Quinlan\\'s earlier ID3 algorithm. The decision trees generated by C4.5 can be used for classification, and for this reason, C4.5 is often referred to as a statistical classifier. Authors of the Weka machine learning software described the C4.5 algorithm as \"a landmark decision tree program that is probably the machine learning workhorse most widely used in practice to date\".[2]', 'href': '/wiki/C4.5_algorithm', 'section': 'Decision Trees', 'title': 'C4.5 algorithm'}\n",
      "{'definition': 'Chi-square automatic interaction detection (CHAID) is a decision tree technique, based on adjusted significance testing (Bonferroni testing). The technique was developed in South Africa and was published in 1980 by Gordon V. Kass, who had completed a PhD thesis on this topic. CHAID can be used for prediction (in a similar fashion to regression analysis, this version of CHAID being originally known as XAID) as well as classification, and for detection of interaction between variables. CHAID is based on a formal extension of the US AID (Automatic Interaction Detection) and THAID (THeta Automatic Interaction Detection) procedures of the 1960s and 1970s, which in turn were extensions of earlier research, including that performed in the UK in the 1950s.', 'href': '/wiki/CHAID', 'section': 'Decision Trees', 'title': 'CHAID'}\n",
      "{'definition': \"Information fuzzy networks (IFN) is a greedy machine learning algorithm for supervised learning. The data structure produced by the learning algorithm is also called Info Fuzzy Network. IFN construction is quite similar to decision trees' construction. However, IFN constructs a directed graph and not a tree. IFN also uses the conditional mutual information metric in order to choose features during the construction stage while decision trees usually use other metrics like entropy or gini.\", 'href': '/wiki/Information_Fuzzy_Networks', 'section': 'Decision Trees', 'title': 'Information Fuzzy Networks'}\n",
      "{'definition': 'Grafting is the process of adding nodes to inferred decision trees to improve the predictive accuracy.[clarification needed] A decision tree is a graphical model that is used as a support tool for decision process.', 'href': '/wiki/Grafting_(decision_trees)', 'section': 'Decision Trees', 'title': 'Grafting (decision trees)'}\n",
      "{'definition': 'An incremental decision tree algorithm is an online machine learning algorithm that outputs a decision tree. Many decision tree methods, such as C4.5, construct a tree using a complete dataset. Incremental decision tree methods allow an existing tree to be updated using only new individual data instances, without having to re-process past instances. This may be useful in situations where the entire dataset is not available when the tree is updated (i.e. the data was not stored), the original data set is too large to process or the characteristics of the data change over time.', 'href': '/wiki/Incremental_decision_tree', 'section': 'Decision Trees', 'title': 'Incremental decision tree'}\n",
      "{'definition': 'An alternating decision tree (ADTree) is a machine learning method for classification. It generalizes decision trees and has connections to boosting.', 'href': '/wiki/Alternating_decision_tree', 'section': 'Decision Trees', 'title': 'Alternating decision tree'}\n",
      "{'definition': 'In computer science, a logistic model tree (LMT) is a classification model with an associated supervised training algorithm that combines logistic regression (LR) and decision tree learning.[1][2]', 'href': '/wiki/Logistic_model_tree', 'section': 'Decision Trees', 'title': 'Logistic model tree'}\n",
      "{'definition': \"Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.[1][2] Random decision forests correct for decision trees' habit of overfitting to their training set.[3]:587–588\", 'href': '/wiki/Random_forest', 'section': 'Decision Trees', 'title': 'Random forest'}\n",
      "{'definition': \"In the field of machine learning, the goal of statistical classification is to use an object's characteristics to identify which class (or group) it belongs to. A linear classifier achieves this by making a classification decision based on the value of a linear combination of the characteristics. An object's characteristics are also known as feature values and are typically presented to the machine in a vector called a feature vector. Such classifiers work well for practical problems such as document classification, and more generally for problems with many variables (features), reaching accuracy levels comparable to non-linear classifiers while taking less time to train and use.[1]\", 'href': '/wiki/Linear_classifier', 'section': 'Linear Classifiers', 'title': 'Linear classifier'}\n",
      "{'definition': 'In machine learning the margin of a single data point is defined to be the distance from the data point to a decision boundary. Note that there are many distances and decision boundaries that may be appropriate for certain datasets and goals. A margin classifier is a classifier that explicitly utilizes the margin of each example while learning a classifier. There are theoretical justifications (based on the VC dimension) as to why maximizing the margin (under some suitable constraints) may be beneficial for machine learning and statistical inferences algorithms.', 'href': '/wiki/Margin_(machine_learning)', 'section': 'Linear Classifiers', 'title': 'Margin (machine learning)'}\n",
      "{'definition': 'In machine learning, a margin classifier is a classifier which is able to give an associated distance from the decision boundary for each example. For instance, if a linear classifier (e.g. perceptron or linear discriminant analysis) is used, the distance (typically euclidean distance, though others may be used) of an example from the separating hyperplane is the margin of that example.', 'href': '/wiki/Margin_classifier', 'section': 'Linear Classifiers', 'title': 'Margin classifier'}\n",
      "{'definition': 'Soft independent modelling by class analogy (SIMCA) is a statistical method for supervised classification of data. The method requires a training data set consisting of samples (or objects) with a set of attributes and their class membership. The term soft refers to the fact the classifier can identify samples as belonging to multiple classes and not necessarily producing a classification of samples into non-overlapping classes.', 'href': '/wiki/Soft_independent_modelling_of_class_analogies', 'section': 'Linear Classifiers', 'title': 'Soft independent modelling of class analogies'}\n",
      "{'definition': 'In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (gender, blood pressure, presence or absence of certain symptoms, etc.). Classification is an example of pattern recognition.', 'href': '/wiki/Statistical_classification', 'section': 'Statistical classification', 'title': 'Statistical classification'}\n",
      "{'definition': 'Probability matching is a decision strategy in which predictions of class membership are proportional to the class base rates. Thus, if in the training set positive examples are observed 60% of the time, and negative examples are observed 40% of the time, then the observer using a probability-matching strategy will predict (for unlabeled examples) a class label of \"positive\" on 60% of instances, and a class label of \"negative\" on 40% of instances.', 'href': '/wiki/Probability_matching', 'section': 'Statistical classification', 'title': 'Probability matching'}\n",
      "{'definition': 'Discriminative models, also called conditional models, are a class of models used in machine learning for modeling the dependence of unobserved (target) variables \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n on observed variables \\n\\n\\n\\nx\\n\\n\\n{\\\\displaystyle x}\\n\\n. Within a probabilistic framework, this is done by modeling the conditional probability distribution \\n\\n\\n\\nP\\n(\\ny\\n\\n|\\n\\nx\\n)\\n\\n\\n{\\\\displaystyle P(y|x)}\\n\\n, which can be used for predicting \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n from \\n\\n\\n\\nx\\n\\n\\n{\\\\displaystyle x}\\n\\n.', 'href': '/wiki/Discriminative_model', 'section': 'Statistical classification', 'title': 'Discriminative model'}\n",
      "{'definition': \"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.\", 'href': '/wiki/Linear_discriminant_analysis', 'section': 'Statistical classification', 'title': 'Linear discriminant analysis'}\n",
      "{'definition': \"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.\", 'href': '/wiki/Multiclass_LDA', 'section': 'Statistical classification', 'title': 'Multiclass LDA'}\n",
      "{'definition': 'Multiple Discriminant Analysis (MDA) is a multivariate technique used to predict corporate failure.[1]', 'href': '/wiki/Multiple_discriminant_analysis', 'section': 'Statistical classification', 'title': 'Multiple discriminant analysis'}\n",
      "{'definition': 'Optimal Discriminant Analysis (ODA) [1] and the related classification tree analysis (CTA) are exact statistical methods that maximize predictive accuracy. For any specific sample and exploratory or confirmatory hypothesis, optimal discriminant analysis (ODA) identifies the statistical model that yields maximum predictive accuracy, assesses the exact Type I error rate, and evaluates potential cross-generalizability. Optimal discriminant analysis may be applied to >\\xa00 dimensions, with the one-dimensional case being referred to as UniODA and the multidimensional case being referred to as MultiODA. Classification tree analysis is a generalization of optimal discriminant analysis to non-orthogonal trees. Classification tree analysis has more recently been called \"hierarchical optimal discriminant analysis\". Optimal discriminant analysis and classification tree analysis may be used to find the combination of variables and cut points that best separate classes of objects or events. These variables and cut points may then be used to reduce dimensions and to then build a statistical model that optimally describes the data.', 'href': '/wiki/Optimal_discriminant_analysis', 'section': 'Statistical classification', 'title': 'Optimal discriminant analysis'}\n",
      "{'definition': 'In statistical classification, the Fisher kernel, named after Ronald Fisher, is a function that measures the similarity of two objects on the basis of sets of measurements for each object and a statistical model. In a classification procedure, the class for a new object (whose real class is unknown) can be estimated by minimising, across classes, an average of the Fisher kernel distance from the new object to each known member of the given class.', 'href': '/wiki/Fisher_kernel', 'section': 'Statistical classification', 'title': 'Fisher kernel'}\n",
      "{'definition': \"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.\", 'href': '/wiki/Discriminant_function_analysis', 'section': 'Statistical classification', 'title': 'Discriminant function analysis'}\n",
      "{'definition': 'Multilinear subspace learning is an approach to dimensionality reduction.[1][2][3][4][5] Dimensionality reduction can be performed on a data tensor whose observations have been vectorized[1] and organized into a data tensor, or whose observations are matrices that are concatenated into a data tensor.[6][7] Here are some examples of data tensors whose observations are vectorized or whose observations are matrices concatenated into data tensor images (2D/3D), video sequences (3D/4D), and hyperspectral cubes (3D/4D).', 'href': '/wiki/Multilinear_subspace_learning', 'section': 'Statistical classification', 'title': 'Multilinear subspace learning'}\n",
      "{'definition': 'A quadratic classifier is used in machine learning and statistical classification to separate measurements of two or more classes of objects or events by a quadric surface. It is a more general version of the linear classifier.', 'href': '/wiki/Quadratic_classifier', 'section': 'Statistical classification', 'title': 'Quadratic classifier'}\n",
      "{'definition': 'In statistics, adaptive or \"variable-bandwidth\" kernel density estimation is a form of kernel density estimation in which the size of the kernels used in the estimate are varied depending upon either the location of the samples or the location of the test point. It is a particularly effective technique when the sample space is multi-dimensional. [1]', 'href': '/wiki/Variable_kernel_density_estimation', 'section': 'Statistical classification', 'title': 'Variable kernel density estimation'}\n",
      "{'definition': 'Category utility is a measure of \"category goodness\" defined in Gluck & Corter (1985) and Corter & Gluck (1992). It attempts to maximize both the probability that two objects in the same category have attribute values in common, and the probability that objects from different categories have different attribute values. It was intended to supersede more limited measures of category goodness such as \"cue validity\" (Reed 1972; Rosch & Mervis 1975) and \"collocation index\" (Jones 1983). It provides a normative information-theoretic measure of the predictive advantage gained by the observer who possesses knowledge of the given category structure (i.e., the class labels of instances) over the observer who does not possess knowledge of the category structure. In this sense the motivation for the category utility measure is similar to the information gain metric used in decision tree learning. In certain presentations, it is also formally equivalent to the mutual information, as discussed below. A review of category utility in its probabilistic incarnation, with applications to machine learning, is provided in Witten & Frank (2005, pp.\\xa0260–262).', 'href': '/wiki/Category_utility', 'section': 'Statistical classification', 'title': 'Category utility'}\n",
      "{'definition': 'In business intelligence, data classification has close ties to data clustering, but where data clustering is descriptive, data classification is predictive.[1][2] In essence data classification consists of using variables with known values to predict the unknown or future values of other variables. It can be used in e.g. direct marketing, insurance fraud detection or medical diagnosis.[2]', 'href': '/wiki/Data_classification_(business_intelligence)', 'section': 'Evaluation of Classification Models', 'title': 'Data classification (business intelligence)'}\n",
      "{'definition': 'In machine learning, the study and construction of algorithms that can learn from and make predictions on data[1] is a common task. Such algorithms work by making data-driven predictions or decisions,[2]:2 through building a mathematical model from input data.', 'href': '/wiki/Training_set', 'section': 'Evaluation of Classification Models', 'title': 'Training set'}\n",
      "{'definition': 'In machine learning, the study and construction of algorithms that can learn from and make predictions on data[1] is a common task. Such algorithms work by making data-driven predictions or decisions,[2]:2 through building a mathematical model from input data.', 'href': '/wiki/Test_set', 'section': 'Evaluation of Classification Models', 'title': 'Test set'}\n",
      "{'definition': 'Synthetic data is \"any production data applicable to a given situation that are not obtained by direct measurement\" according to the McGraw-Hill Dictionary of Scientific and Technical Terms;[1] where Craig S. Mullins, an expert in data management, defines production data as \"information that is persistently stored and used by professionals to conduct business processes.\".[2]', 'href': '/wiki/Synthetic_data', 'section': 'Evaluation of Classification Models', 'title': 'Synthetic data'}\n",
      "{'definition': 'Cross-validation, sometimes called rotation estimation,[1][2][3] or out-of-sample testing is any of various similar model validation techniques for assessing how the results of a statistical analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. In a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (called the validation dataset or testing set).[4] The goal of cross-validation is to test the model’s ability to predict new data that were not used in estimating it, in order to flag problems like overfitting[citation needed] and to give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem).', 'href': '/wiki/Cross-validation_(statistics)', 'section': 'Evaluation of Classification Models', 'title': 'Cross-validation (statistics)'}\n",
      "{'definition': 'In mathematical optimization, statistics, econometrics, decision theory, machine learning and computational neuroscience, a loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its negative (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized.', 'href': '/wiki/Loss_function', 'section': 'Evaluation of Classification Models', 'title': 'Loss function'}\n",
      "{'definition': 'In machine learning, the hinge loss is a loss function used for training classifiers. The hinge loss is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs).[1] For an intended output t = ±1 and a classifier score y, the hinge loss of the prediction y is defined as', 'href': '/wiki/Hinge_loss', 'section': 'Evaluation of Classification Models', 'title': 'Hinge loss'}\n",
      "{'definition': 'In supervised learning applications in machine learning and statistical learning theory, generalization error (also known as the out-of-sample error[1]) is a measure of how accurately an algorithm is able to predict outcome values for previously unseen data. Because learning algorithms are evaluated on finite samples, the evaluation of a learning algorithm may be sensitive to sampling error. As a result, measurements of prediction error on the current data may not provide much information about predictive ability on new data. Generalization error can be minimized by avoiding overfitting in the learning algorithm. The performance of a machine learning algorithm is measured by plots of the generalization error values through the learning process, which are called learning curves.', 'href': '/wiki/Generalization_error', 'section': 'Evaluation of Classification Models', 'title': 'Generalization error'}\n",
      "{'definition': 'In statistical hypothesis testing, a type I error is the rejection of a true null hypothesis (also known as a \"false positive\" finding), while a type II error is retaining a false null hypothesis (also known as a \"false negative\" finding).[1] More simply stated, a type I error is to falsely infer the existence of something that is not there, while a type II error is to falsely infer the absence of something that is.', 'href': '/wiki/Type_I_and_type_II_errors', 'section': 'Evaluation of Classification Models', 'title': 'Type I and type II errors'}\n",
      "{'definition': 'Sensitivity and specificity are statistical measures of the performance of a binary classification test, also known in statistics as a classification function:', 'href': '/wiki/Sensitivity_and_specificity', 'section': 'Evaluation of Classification Models', 'title': 'Sensitivity and specificity'}\n",
      "{'definition': 'In pattern recognition, information retrieval and binary classification, precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Both precision and recall are therefore based on an understanding and measure of relevance.', 'href': '/wiki/Precision_and_recall', 'section': 'Evaluation of Classification Models', 'title': 'Precision and recall'}\n",
      "{'definition': \"In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\", 'href': '/wiki/F1_score', 'section': 'Evaluation of Classification Models', 'title': 'F1 score'}\n",
      "{'definition': 'Sources: Fawcett (2006), Powers (2011), and Ting (2011) [1] [2] [3]', 'href': '/wiki/Confusion_matrix', 'section': 'Evaluation of Classification Models', 'title': 'Confusion matrix'}\n",
      "{'definition': 'The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications, introduced by biochemist Brian W. Matthews in 1975.[1] It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes.[2] The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between −1 and +1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and −1 indicates total disagreement between prediction and observation. The statistic is also known as the phi coefficient. MCC is related to the chi-square statistic for a 2×2 contingency table', 'href': '/wiki/Matthews_correlation_coefficient', 'section': 'Evaluation of Classification Models', 'title': 'Matthews correlation coefficient'}\n",
      "{'definition': 'In statistics, a receiver operating characteristic curve, i.e. ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.', 'href': '/wiki/Receiver_operating_characteristic', 'section': 'Evaluation of Classification Models', 'title': 'Receiver operating characteristic'}\n",
      "{'definition': 'In data mining and association rule learning, lift is a measure of the performance of a targeting model (association rule) at predicting or classifying cases as having an enhanced response (with respect to the population as a whole), measured against a random choice targeting model. A targeting model is doing a good job if the response within the target is much better than the average for the population as a whole. Lift is simply the ratio of these values: target response divided by average response.', 'href': '/wiki/Lift_(data_mining)', 'section': 'Evaluation of Classification Models', 'title': 'Lift (data mining)'}\n",
      "{'definition': 'Stability, also known as algorithmic stability, is a notion in computational learning theory of how a machine learning algorithm is perturbed by small changes to its inputs. A stable learning algorithm is one for which the prediction does not change much when the training data is modified slightly. For instance, consider a machine learning algorithm that is being trained to recognize handwritten letters of the alphabet, using 1000 examples of handwritten letters and their labels (\"A\" to \"Z\") as a training set. One way to modify this training set is to leave out an example, so that only 999 examples of handwritten letters and their labels are available. A stable learning algorithm would produce a similar classifier with both the 1000-element and 999-element training sets.', 'href': '/wiki/Stability_in_learning', 'section': 'Evaluation of Classification Models', 'title': 'Stability in learning'}\n",
      "{'definition': 'Data pre-processing is an important step in the data mining process. The phrase \"garbage in, garbage out\" is particularly applicable to data mining and machine learning projects. Data-gathering methods are often loosely controlled, resulting in out-of-range values (e.g., Income: −100), impossible data combinations (e.g., Sex: Male, Pregnant: Yes), missing values, etc. Analyzing data that has not been carefully screened for such problems can produce misleading results. Thus, the representation and quality of data is first and foremost before running an analysis.[1] Often, data pre-processing is the most important phase of a machine learning project, especially in computational biology.[2]', 'href': '/wiki/Data_Pre-processing', 'section': 'Feature Creation and Optimization', 'title': 'Data Pre-processing'}\n",
      "{'definition': 'In statistics and machine learning, discretization refers to the process of converting or partitioning continuous attributes, features or variables to discretized or nominal attributes/features/variables/intervals. This can be useful when creating probability mass functions – formally, in density estimation. It is a form of discretization in general and also of binning, as in making a histogram. Whenever continuous data is discretized, there is always some amount of discretization error. The goal is to reduce the amount to a level considered negligible for the modeling purposes at hand.', 'href': '/wiki/Discretization_of_continuous_features', 'section': 'Feature Creation and Optimization', 'title': 'Discretization of continuous features'}\n",
      "{'definition': 'Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning.', 'href': '/wiki/Feature_engineering', 'section': 'Feature Creation and Optimization', 'title': 'Feature engineering'}\n",
      "{'definition': 'In machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction. Feature selection techniques are used for four reasons:', 'href': '/wiki/Feature_selection', 'section': 'Feature Creation and Optimization', 'title': 'Feature selection'}\n",
      "{'definition': 'In machine learning, pattern recognition and in image processing, feature extraction starts from an initial set of measured data and builds derived values (features) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps, and in some cases leading to better human interpretations. Feature extraction is related to dimensionality reduction.', 'href': '/wiki/Feature_extraction', 'section': 'Feature Creation and Optimization', 'title': 'Feature extraction'}\n",
      "{'definition': 'In statistics, machine learning, and information theory, dimensionality reduction or dimension reduction is the process of reducing the number of random variables under consideration[1] by obtaining a set of principal variables. It can be divided into feature selection and feature extraction.[2]', 'href': '/wiki/Dimension_reduction', 'section': 'Feature Creation and Optimization', 'title': 'Dimension reduction'}\n",
      "{'definition': 'Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables[clarification needed] into a set of values of linearly uncorrelated variables called principal components. If there are \\n\\n\\n\\nn\\n\\n\\n{\\\\displaystyle n}\\n\\n observations with \\n\\n\\n\\np\\n\\n\\n{\\\\displaystyle p}\\n\\n variables, then the number of distinct principal components is \\n\\n\\n\\nmin\\n(\\nn\\n−\\n1\\n,\\np\\n)\\n\\n\\n{\\\\displaystyle \\\\min(n-1,p)}\\n\\n. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors[clarification needed] are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables.', 'href': '/wiki/Principal_component_analysis', 'section': 'Feature Creation and Optimization', 'title': 'Principal component analysis'}\n",
      "{'definition': 'Multilinear principal component analysis (MPCA) is a multilinear extension of principal component analysis (PCA). MPCA is employed in the analysis of n-way arrays, i.e. a cube or hyper-cube of numbers, also informally referred to as a \"data tensor\". N-way arrays may be decomposed, analyzed, or modeled by', 'href': '/wiki/Multilinear_principal-component_analysis', 'section': 'Feature Creation and Optimization', 'title': 'Multilinear principal-component analysis'}\n",
      "{'definition': 'Multifactor dimensionality reduction (MDR) is a statistical approach, also used in machine learning automatic approaches[1], for detecting and characterizing combinations of attributes or independent variables that interact to influence a dependent or class variable.[2][3][4][5][6][7][8] MDR was designed specifically to identify nonadditive interactions among discrete variables that influence a binary outcome and is considered a nonparametric and model-free alternative to traditional statistical methods such as logistic regression.', 'href': '/wiki/Multifactor_dimensionality_reduction', 'section': 'Feature Creation and Optimization', 'title': 'Multifactor dimensionality reduction'}\n",
      "{'definition': 'Targeted projection pursuit is a type of statistical technique used for exploratory data analysis, information visualization, and feature selection. It allows the user to interactively explore very complex data (typically having tens to hundreds of attributes) to find features or patterns of potential interest.', 'href': '/wiki/Targeted_projection_pursuit', 'section': 'Feature Creation and Optimization', 'title': 'Targeted projection pursuit'}\n",
      "{'definition': 'Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix. It is a form of non-linear dimensionality reduction. An MDS algorithm aims to place each object in N-dimensional space such that the between-object distances are preserved as well as possible. Each object is then assigned coordinates in each of the N dimensions. The number of dimensions of an MDS plot N can exceed 2 and is specified a priori. Choosing N=2 optimizes the object locations for a two-dimensional scatterplot.[1]', 'href': '/wiki/Multidimensional_scaling', 'section': 'Feature Creation and Optimization', 'title': 'Multidimensional scaling'}\n",
      "{'definition': 'High-dimensional data, meaning data that requires more than two or three dimensions to represent, can be difficult to interpret. One approach to simplification is to assume that the data of interest lie on an embedded non-linear manifold within the higher-dimensional space. If the manifold is of low enough dimension, the data can be visualised in the low-dimensional space.', 'href': '/wiki/Nonlinear_dimensionality_reduction', 'section': 'Feature Creation and Optimization', 'title': 'Nonlinear dimensionality reduction'}\n",
      "{'definition': 'In the field of multivariate statistics, kernel principal component analysis (kernel PCA) [1] is an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.', 'href': '/wiki/Kernel_principal_component_analysis', 'section': 'Feature Creation and Optimization', 'title': 'Kernel principal component analysis'}\n",
      "{'definition': 'Speaker adaptation is an important technology to fine-tune either features or speech models for mis-match due to inter-speaker variation. In the last decade, eigenvoice (EV) speaker adaptation has been developed. It makes use of the prior knowledge of training speakers to provide a fast adaptation algorithm (in other words, only a small amount of adaptation data is needed). Inspired by the kernel eigenface idea in face recognition, kernel eigenvoice (KEV) is proposed.[1] KEV is a non-linear generalization to EV. This incorporates Kernel principal component analysis, a non-linear version of Principal Component Analysis, to capture the higher order correlations in order to further explore the speaker space and enhance recognition performance.', 'href': '/wiki/Kernel_eigenvoice', 'section': 'Feature Creation and Optimization', 'title': 'Kernel eigenvoice'}\n",
      "{'definition': 'In linear algebra, the Gram matrix (Gramian matrix or Gramian) of a set of vectors \\n\\n\\n\\n\\nv\\n\\n1\\n\\n\\n,\\n…\\n,\\n\\nv\\n\\nn\\n\\n\\n\\n\\n{\\\\displaystyle v_{1},\\\\dots ,v_{n}}\\n\\n in an inner product space is the Hermitian matrix of inner products, whose entries are given by \\n\\n\\n\\n\\nG\\n\\ni\\nj\\n\\n\\n=\\n⟨\\n\\nv\\n\\ni\\n\\n\\n,\\n\\nv\\n\\nj\\n\\n\\n⟩\\n\\n\\n{\\\\displaystyle G_{ij}=\\\\langle v_{i},v_{j}\\\\rangle }\\n\\n.[1]', 'href': '/wiki/Gramian_matrix', 'section': 'Feature Creation and Optimization', 'title': 'Gramian matrix'}\n",
      "{'definition': 'In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.', 'href': '/wiki/Gaussian_process', 'section': 'Feature Creation and Optimization', 'title': 'Gaussian process'}\n",
      "{'definition': 'In signal processing, a kernel adaptive filter is a type of nonlinear adaptive filter.[1] An adaptive filter is a filter that adapts its transfer function to changes in signal properties over time by minimizing an error or loss function that characterizes how far the filter deviates from ideal behavior. The adaptation process is based on learning from a sequence of signal samples and is thus an online algorithm. A nonlinear adaptive filter is one in which the transfer function is nonlinear.', 'href': '/wiki/Kernel_adaptive_filter', 'section': 'Feature Creation and Optimization', 'title': 'Kernel adaptive filter'}\n",
      "{'definition': 'Isomap is a nonlinear dimensionality reduction method. It is one of several widely used low-dimensional embedding methods.[1] Isomap is used for computing a quasi-isometric, low-dimensional embedding of a set of high-dimensional data points. The algorithm provides a simple method for estimating the intrinsic geometry of a data manifold based on a rough estimate of each data point’s neighbors on the manifold. Isomap is highly efficient and generally applicable to a broad range of data sources and dimensionalities.', 'href': '/wiki/Isomap', 'section': 'Feature Creation and Optimization', 'title': 'Isomap'}\n",
      "{'definition': 'Manifold alignment is a class of machine learning algorithms that produce projections between sets of data, given that the original data sets lie on a common manifold. The concept was first introduced as such by Ham, Lee, and Saul in 2003,[1] adding a manifold constraint to the general problem of correlating sets of high-dimensional vectors.[2]', 'href': '/wiki/Manifold_alignment', 'section': 'Feature Creation and Optimization', 'title': 'Manifold alignment'}\n",
      "{'definition': 'Diffusion maps is a dimensionality reduction or feature extraction algorithm introduced by Coifman and Lafon[1][2][3][4] which computes a family of embeddings of a data set into Euclidean space (often low-dimensional) whose coordinates can be computed from the eigenvectors and eigenvalues of a diffusion operator on the data. The Euclidean distance between points in the embedded space is equal to the \"diffusion distance\" between probability distributions centered at those points. Different from linear dimensionality reduction methods such as principal component analysis (PCA) and multi-dimensional scaling (MDS), diffusion maps is part of the family of nonlinear dimensionality reduction methods which focus on discovering the underlying manifold that the data has been sampled from. By integrating local similarities at different scales, diffusion maps gives a global description of the data-set. Compared with other methods, the diffusion maps algorithm is robust to noise perturbation and is computationally inexpensive.', 'href': '/wiki/Diffusion_map', 'section': 'Feature Creation and Optimization', 'title': 'Diffusion map'}\n",
      "{'definition': 'Elastic maps provide a tool for nonlinear dimensionality reduction. By their construction, they are a system of elastic springs embedded in the data space.[1] This system approximates a low-dimensional manifold. The elastic coefficients of this system allow the switch from completely unstructured k-means clustering (zero elasticity) to the estimators located closely to linear PCA manifolds (for high bending and low stretching modules). With some intermediate values of the elasticity coefficients, this system effectively approximates non-linear principal manifolds. This approach is based on a mechanical analogy between principal manifolds, that are passing through \"the middle\" of the data distribution, and elastic membranes and plates. The method was developed by A.N. Gorban, A.Y. Zinovyev and A.A. Pitenko in 1996–1998.', 'href': '/wiki/Elastic_map', 'section': 'Feature Creation and Optimization', 'title': 'Elastic map'}\n",
      "{'definition': 'Locality-sensitive hashing (LSH) reduces the dimensionality of high-dimensional data. LSH hashes input items so that similar items map to the same “buckets” with high probability (the number of buckets being much smaller than the universe of possible input items). LSH differs from conventional and cryptographic hash functions because it aims to maximize the probability of a “collision” for similar items.[1] Locality-sensitive hashing has much in common with data clustering and nearest neighbor search.', 'href': '/wiki/Locality-sensitive_hashing', 'section': 'Feature Creation and Optimization', 'title': 'Locality-sensitive hashing'}\n",
      "{'definition': 'In multivariate statistics and the clustering of data, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions. The similarity matrix is provided as an input and consists of a quantitative assessment of the relative similarity of each pair of points in the dataset.', 'href': '/wiki/Spectral_clustering', 'section': 'Feature Creation and Optimization', 'title': 'Spectral clustering'}\n",
      "{'definition': 'Minimum redundancy feature selection is an algorithm frequently used in a method to accurately identify characteristics of genes and phenotypes and narrow down their relevance and is usually described in its pairing with relevant feature selection as Minimum Redundancy Maximum Relevance (mRMR).', 'href': '/wiki/Minimum_redundancy_feature_selection', 'section': 'Feature Creation and Optimization', 'title': 'Minimum redundancy feature selection'}\n",
      "{'definition': 'Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics.', 'href': '/wiki/Cluster_analysis', 'section': 'Clustering', 'title': 'Cluster analysis'}\n",
      "{'definition': 'k-means clustering is a method of vector quantization, originally from signal processing, that is popular for cluster analysis in data mining. k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells.', 'href': '/wiki/K-means_clustering', 'section': 'Clustering', 'title': 'K-means clustering'}\n",
      "{'definition': 'In data mining, k-means++[1][2] is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm. It was proposed in 2007 by David Arthur and Sergei Vassilvitskii, as an approximation algorithm for the NP-hard k-means problem—a way of avoiding the sometimes poor clusterings found by the standard k-means algorithm. It is similar to the first of three seeding methods proposed, in independent work, in 2006[3] by Rafail Ostrovsky, Yuval Rabani, Leonard Schulman and Chaitanya Swamy. (The distribution of the first seed is different.)', 'href': '/wiki/K-means%2B%2B', 'section': 'Clustering', 'title': 'K-means++'}\n",
      "{'definition': 'In statistics and data mining, k-medians clustering[1][2] is a cluster analysis algorithm. It is a variation of k-means clustering where instead of calculating the mean for each cluster to determine its centroid, one instead calculates the median. This has the effect of minimizing error over all clusters with respect to the 1-norm distance metric, as opposed to the square of the 2-norm distance metric (which k-means does.)', 'href': '/wiki/K-medians_clustering', 'section': 'Clustering', 'title': 'K-medians clustering'}\n",
      "{'definition': '\\nThe k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups) and both attempt to minimize the distance between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between datapoints instead of \\n\\n\\n\\n\\nl\\n\\n2\\n\\n\\n\\n\\n{\\\\displaystyle l_{2}}\\n\\n. This method was proposed in 1987[1] for the work with \\n\\n\\n\\n\\nl\\n\\n1\\n\\n\\n\\n\\n{\\\\displaystyle l_{1}}\\n\\n norm and other distances.', 'href': '/wiki/K-medoids', 'section': 'Clustering', 'title': 'K-medoids'}\n",
      "{'definition': 'Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander and Xiaowei Xu in 1996.[1] It is a density-based clustering algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). DBSCAN is one of the most common clustering algorithms and also most cited in scientific literature.[2]', 'href': '/wiki/DBSCAN', 'section': 'Clustering', 'title': 'DBSCAN'}\n",
      "{'definition': 'Fuzzy clustering (also referred to as soft clustering) is a form of clustering in which each data point can belong to more than one cluster.', 'href': '/wiki/Fuzzy_clustering', 'section': 'Clustering', 'title': 'Fuzzy clustering'}\n",
      "{'definition': 'BIRCH (balanced iterative reducing and clustering using hierarchies) is an unsupervised data mining algorithm used to perform hierarchical clustering over particularly large data-sets.[1] An advantage of BIRCH is its ability to incrementally and dynamically cluster incoming, multi-dimensional metric data points in an attempt to produce the best quality clustering for a given set of resources (memory and time constraints). In most cases, BIRCH only requires a single scan of the database.', 'href': '/wiki/BIRCH_(data_clustering)', 'section': 'Clustering', 'title': 'BIRCH (data clustering)'}\n",
      "{'definition': 'The canopy clustering algorithm is an unsupervised pre-clustering algorithm introduced by Andrew McCallum, Kamal Nigam and Lyle Ungar in 2000.[1] It is often used as preprocessing step for the K-means algorithm or the Hierarchical clustering algorithm. It is intended to speed up clustering operations on large data sets, where using another algorithm directly may be impractical due to the size of the data set.', 'href': '/wiki/Canopy_clustering_algorithm', 'section': 'Clustering', 'title': 'Canopy clustering algorithm'}\n",
      "{'definition': 'In data mining, cluster-weighted modeling (CWM) is an algorithm-based approach to non-linear prediction of outputs (dependent variables) from inputs (independent variables) based on density estimation using a set of models (clusters) that are each notionally appropriate in a sub-region of the input space. The overall approach works in jointly input-output space and an initial version was proposed by Neil Gershenfeld.[1][2]', 'href': '/wiki/Cluster-weighted_modeling', 'section': 'Clustering', 'title': 'Cluster-weighted modeling'}\n",
      "{'definition': 'Clustering high-dimensional data is the cluster analysis of data with anywhere from a few dozen to many thousands of dimensions. Such high-dimensional spaces of data are often encountered in areas such as medicine, where DNA microarray technology can produce a large number of measurements at once, and the clustering of text documents, where, if a word-frequency vector is used, the number of dimensions equals the size of the vocabulary.', 'href': '/wiki/Clustering_high-dimensional_data', 'section': 'Clustering', 'title': 'Clustering high-dimensional data'}\n",
      "{'definition': 'COBWEB is an incremental system for hierarchical conceptual clustering. COBWEB was invented by Professor Douglas H. Fisher, currently at Vanderbilt University.[1][2]', 'href': '/wiki/Cobweb_(clustering)', 'section': 'Clustering', 'title': 'Cobweb (clustering)'}\n",
      "{'definition': \"Complete-linkage clustering is one of several methods of agglomerative hierarchical clustering. At the beginning of the process, each element is in a cluster of its own. The clusters are then sequentially combined into larger clusters until all elements end up being in the same cluster. At each step, the two clusters separated by the shortest distance are combined. The definition of 'shortest distance' is what differentiates between the different agglomerative clustering methods. In complete-linkage clustering, the link between two clusters contains all element pairs, and the distance between clusters equals the distance between those two elements (one in each cluster) that are farthest away from each other. The shortest of these links that remains at any step causes the fusion of the two clusters whose elements are involved. The method is also known as farthest neighbour clustering. The result of the clustering can be visualized as a dendrogram, which shows the sequence of cluster fusion and the distance at which each fusion took place.[1][2][3]\", 'href': '/wiki/Complete-linkage_clustering', 'section': 'Clustering', 'title': 'Complete-linkage clustering'}\n",
      "{'definition': 'In computer science, constrained clustering is a class of semi-supervised learning algorithms. Typically, constrained clustering incorporates either a set of must-link constraints, cannot-link constraints, or both, with a Data clustering algorithm. Both a must-link and a cannot-link constraint define a relationship between two data instances. A must-link constraint is used to specify that the two instances in the must-link relation should be associated with the same cluster. A cannot-link constraint is used to specify that the two instances in the cannot-link relation should not be associated with the same cluster. These sets of constraints acts as a guide for which a constrained clustering algorithm will attempt to find clusters in a data set which satisfy the specified must-link and cannot-link constraints. Some constrained clustering algorithms will abort if no such clustering exists which satisfies the specified constraints. Others will try to minimize the amount of constraint violation should it be impossible to find a clustering which satisfies the constraints. Constraints could also be used to guide the selection of a clustering model among several possible solutions. [1]', 'href': '/wiki/Constrained_clustering', 'section': 'Clustering', 'title': 'Constrained clustering'}\n",
      "{'definition': 'Clustering is the problem of partitioning data points into groups based on their similarity. Correlation clustering provides a method for clustering a set of objects into the optimum number of clusters without specifying that number in advance.[1]', 'href': '/wiki/Correlation_clustering', 'section': 'Clustering', 'title': 'Correlation clustering'}\n",
      "{'definition': 'CURE (Clustering Using REpresentatives) is an efficient data clustering algorithm for large databases[citation needed]. Compared with K-means clustering it is more robust to outliers and able to identify clusters having non-spherical shapes and size variances.', 'href': '/wiki/CURE_data_clustering_algorithm', 'section': 'Clustering', 'title': 'CURE data clustering algorithm'}\n",
      "{'definition': 'In computer science, data stream clustering is defined as the clustering of data that arrive continuously such as telephone records, multimedia data, financial transactions etc. Data stream clustering is usually studied as a streaming algorithm and the objective is, given a sequence of points, to construct a good clustering of the stream, using a small amount of memory and time.', 'href': '/wiki/Data_stream_clustering', 'section': 'Clustering', 'title': 'Data stream clustering'}\n",
      "{'definition': 'A dendrogram (from Greek dendro \"tree\" and gramma \"drawing\") is a tree diagram frequently used to illustrate the arrangement of the clusters produced by hierarchical clustering.[1] Dendrograms are often used in computational biology to illustrate the clustering of genes or samples, sometimes on top of heatmaps.', 'href': '/wiki/Dendrogram', 'section': 'Clustering', 'title': 'Dendrogram'}\n",
      "{'definition': 'Determining the number of clusters in a data set, a quantity often labelled k as in the k-means algorithm, is a frequent problem in data clustering, and is a distinct issue from the process of actually solving the clustering problem.', 'href': '/wiki/Determining_the_number_of_clusters_in_a_data_set', 'section': 'Clustering', 'title': 'Determining the number of clusters in a data set'}\n",
      "{'definition': 'Fuzzy clustering by Local Approximation of MEmberships (FLAME) is a data clustering algorithm that defines clusters in the dense parts of a dataset and performs cluster assignment solely based on the neighborhood relationships among objects. The key feature of this algorithm is that the neighborhood relationships among neighboring objects in the feature space are used to constrain the memberships of neighboring objects in the fuzzy membership space.', 'href': '/wiki/FLAME_clustering', 'section': 'Clustering', 'title': 'FLAME clustering'}\n",
      "{'definition': 'In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:[1]', 'href': '/wiki/Hierarchical_clustering', 'section': 'Clustering', 'title': 'Hierarchical clustering'}\n",
      "{'definition': 'The information bottleneck method is a technique in information theory introduced by Naftali Tishby, Fernando C. Pereira, and William Bialek.[1] It is designed for finding the best tradeoff between accuracy and complexity (compression) when summarizing (e.g. clustering) a random variable X, given a joint probability distribution p(X,Y) between X and an observed relevant variable Y. Other applications include distributional clustering and dimension reduction. More recently it has been suggested as a theoretical foundation for deep learning. It generalized the classical notion of minimal sufficient statistics from parametric statistics to arbitrary distributions, not necessarily of exponential form. It does so by relaxing the sufficiency condition to capture some fraction of the mutual information with the relevant variable Y.', 'href': '/wiki/Information_bottleneck_method', 'section': 'Clustering', 'title': 'Information bottleneck method'}\n",
      "{'definition': \"In computer science and electrical engineering, Lloyd's algorithm, also known as Voronoi iteration or relaxation, is an algorithm named after Stuart P. Lloyd for finding evenly spaced sets of points in subsets of Euclidean spaces and partitions of these subsets into well-shaped and uniformly sized convex cells.[1] Like the closely related k-means clustering algorithm, it repeatedly finds the centroid of each set in the partition and then re-partitions the input according to which of these centroids is closest. However, Lloyd's algorithm differs from k-means clustering in that its input is a continuous geometric region rather than a discrete set of points. Thus, when re-partitioning the input, Lloyd's algorithm uses Voronoi diagrams rather than simply determining the nearest center to each of a finite set of points as the k-means algorithm does.\", 'href': '/wiki/Lloyd%27s_algorithm', 'section': 'Clustering', 'title': \"Lloyd's algorithm\"}\n",
      "{'definition': \"In the theory of cluster analysis, the nearest-neighbor chain algorithm is an algorithm that can speed up several methods for agglomerative hierarchical clustering. These are methods that take a collection of points as input, and create a hierarchy of clusters of points by repeatedly merging pairs of smaller clusters to form larger clusters. The clustering methods that the nearest-neighbor chain algorithm can be used for include Ward's method, complete-linkage clustering, and single-linkage clustering; these all work by repeatedly merging the closest two clusters but use different definitions of the distance between clusters. The cluster distances for which the nearest-neighbor chain algorithm works are called reducible and are characterized by a simple inequality among certain cluster distances.\", 'href': '/wiki/Nearest-neighbor_chain_algorithm', 'section': 'Clustering', 'title': 'Nearest-neighbor chain algorithm'}\n",
      "{'definition': 'In bioinformatics, neighbor joining is a bottom-up (agglomerative) clustering method for the creation of phylogenetic trees, created by Naruya Saitou and Masatoshi Nei in 1987.[1] Usually used for trees based on DNA or protein sequence data, the algorithm requires knowledge of the distance between each pair of taxa (e.g., species or sequences) to form the tree.[2]', 'href': '/wiki/Neighbor_joining', 'section': 'Clustering', 'title': 'Neighbor joining'}\n",
      "{'definition': \"Ordering points to identify the clustering structure (OPTICS) is an algorithm for finding density-based[1] clusters in spatial data. It was presented by Mihael Ankerst, Markus M. Breunig, Hans-Peter Kriegel and Jörg Sander.[2] Its basic idea is similar to DBSCAN,[3] but it addresses one of DBSCAN's major weaknesses: the problem of detecting meaningful clusters in data of varying density. In order to do so, the points of the database are (linearly) ordered such that points which are spatially closest become neighbors in the ordering. Additionally, a special distance is stored for each point that represents the density that needs to be accepted for a cluster in order to have both points belong to the same cluster. This is represented as a dendrogram.\", 'href': '/wiki/OPTICS_algorithm', 'section': 'Clustering', 'title': 'OPTICS algorithm'}\n",
      "{'definition': 'In probability theory, a Pitman–Yor process[1][2][3][4] denoted PY(d,\\xa0θ,\\xa0G0), is a stochastic process whose sample path is a probability distribution. A random sample from this process is an infinite discrete probability distribution, consisting of an infinite set of atoms drawn from G0, with weights drawn from a two-parameter Poisson–Dirichlet distribution. The process is named after Jim Pitman and Marc Yor.', 'href': '/wiki/Pitman%E2%80%93Yor_process', 'section': 'Clustering', 'title': 'Pitman–Yor process'}\n",
      "{'definition': 'In statistics, single-linkage clustering is one of several methods of hierarchical clustering. It is based on grouping clusters in bottom-up fashion (agglomerative clustering), at each step combining two clusters that contain the closest pair of elements not yet belonging to the same cluster as each other.', 'href': '/wiki/Single-linkage_clustering', 'section': 'Clustering', 'title': 'Single-linkage clustering'}\n",
      "{'definition': 'SUBCLU is an algorithm for clustering high-dimensional data by Karin Kailing, Hans-Peter Kriegel and Peer Kröger.[1] It is a subspace clustering algorithm that builds on the density-based clustering algorithm DBSCAN. SUBCLU can find clusters in axis-parallel subspaces, and uses a bottom-up, greedy strategy to remain efficient.', 'href': '/wiki/SUBCLU', 'section': 'Clustering', 'title': 'SUBCLU'}\n",
      "{'definition': 'Thresholding is the simplest method of image segmentation. From a grayscale image, thresholding can be used to create binary images (Shapiro, et al. 2001:83).', 'href': '/wiki/Thresholding_(image_processing)', 'section': 'Clustering', 'title': 'Thresholding (image processing)'}\n",
      "{'definition': 'UPGMA (Unweighted Pair Group Method with Arithmetic Mean) is a simple agglomerative (bottom-up) hierarchical clustering method. The method is generally attributed to Sokal and Michener.[1]', 'href': '/wiki/UPGMA', 'section': 'Clustering', 'title': 'UPGMA'}\n",
      "{'definition': 'The Rand index[1] or Rand measure (named after William M. Rand) in statistics, and in particular in data clustering, is a measure of the similarity between two data clusterings. A form of the Rand index may be defined that is adjusted for the chance grouping of elements, this is the adjusted Rand index. From a mathematical standpoint, Rand index is related to the accuracy, but is applicable even when class labels are not used.', 'href': '/wiki/Rand_index', 'section': 'Evaluation of Clustering Methods', 'title': 'Rand index'}\n",
      "{'definition': 'The Dunn index (DI) (introduced by J. C. Dunn in 1974) is a metric for evaluating clustering algorithms.[1][2] This is part of a group of validity indices including the Davies–Bouldin index or Silhouette index, in that it is an internal evaluation scheme, where the result is based on the clustered data itself. As do all other such indices, the aim is to identify sets of clusters that are compact, with a small variance between members of the cluster, and well separated, where the means of different clusters are sufficiently far apart, as compared to the within cluster variance. For a given assignment of clusters, a higher Dunn index indicates better clustering. One of the drawbacks of using this is the computational cost as the number of clusters and dimensionality of the data increase.', 'href': '/wiki/Dunn_index', 'section': 'Evaluation of Clustering Methods', 'title': 'Dunn index'}\n",
      "{'definition': 'The Davies–Bouldin index (DBI) (introduced by David L. Davies and Donald W. Bouldin in 1979) is a metric for evaluating clustering algorithms.[1] This is an internal evaluation scheme, where the validation of how well the clustering has been done is made using quantities and features inherent to the dataset. This has a drawback that a good value reported by this method does not imply the best information retrieval.', 'href': '/wiki/Davies%E2%80%93Bouldin_index', 'section': 'Evaluation of Clustering Methods', 'title': 'Davies–Bouldin index'}\n",
      "{'definition': 'The Jaccard index, also known as Intersection over Union and the Jaccard similarity coefficient (originally coined coefficient de communauté by Paul Jaccard), is a statistic used for comparing the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets:', 'href': '/wiki/Jaccard_index', 'section': 'Evaluation of Clustering Methods', 'title': 'Jaccard index'}\n",
      "{'definition': 'In computer science and data mining, MinHash (or the min-wise independent permutations locality sensitive hashing scheme) is a technique for quickly estimating how similar two sets are. The scheme was invented by Andrei Broder\\xa0(1997),[1] and initially used in the AltaVista search engine to detect duplicate web pages and eliminate them from search results.[2] It has also been applied in large-scale clustering problems, such as clustering documents by the similarity of their sets of words.[1]', 'href': '/wiki/MinHash', 'section': 'Evaluation of Clustering Methods', 'title': 'MinHash'}\n",
      "{'definition': '\\nIn data mining and machine learning, \\n\\n\\n\\nk\\n\\n\\n{\\\\displaystyle k}\\n\\n \\n\\n\\n\\nq\\n\\n\\n{\\\\displaystyle q}\\n\\n-flats algorithm [1] [2] is an iterative method which aims to partition \\n\\n\\n\\nm\\n\\n\\n{\\\\displaystyle m}\\n\\n observations into \\n\\n\\n\\nk\\n\\n\\n{\\\\displaystyle k}\\n\\n clusters where each cluster is close to a \\n\\n\\n\\nq\\n\\n\\n{\\\\displaystyle q}\\n\\n-flat, where \\n\\n\\n\\nq\\n\\n\\n{\\\\displaystyle q}\\n\\n is a given integer.', 'href': '/wiki/K_q-flats', 'section': 'Evaluation of Clustering Methods', 'title': 'K q-flats'}\n",
      "{'definition': 'A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.', 'href': '/wiki/Decision_rules', 'section': 'Rule Induction', 'title': 'Decision rules'}\n",
      "{'definition': 'Rule induction is an area of machine learning in which formal rules are extracted from a set of observations. The rules extracted may represent a full scientific model of the data, or merely represent local patterns in the data.', 'href': '/wiki/Rule_induction', 'section': 'Rule Induction', 'title': 'Rule induction'}\n",
      "{'definition': 'Given a population whose members each belong to one of a number of different sets or classes, a classification rule or classifier is a procedure by which the elements of the population set are each predicted to belong to one of the classes.[1] A perfect classification is one for which every element in the population is assigned to the class it really belongs to. An imperfect classification is one in which some errors appear, and then statistical analysis must be applied to analyse the classification.', 'href': '/wiki/Classification_rule', 'section': 'Rule Induction', 'title': 'Classification rule'}\n",
      "{'definition': 'The CN2 induction algorithm is a learning algorithm for rule induction.[1] It is designed to work even when the training data is imperfect. It is based on ideas from the AQ algorithm and the ID3 algorithm. As a consequence it creates a rule set like that created by AQ but is able to handle noisy data like ID3.', 'href': '/wiki/CN2_algorithm', 'section': 'Rule Induction', 'title': 'CN2 algorithm'}\n",
      "{'definition': 'Decision lists are a representation for Boolean functions which can be easily learnable from examples.[1] Single term decision lists are more expressive than disjunctions and conjunctions; however, 1-term decision lists are less expressive than the general disjunctive normal form and the conjunctive normal form.', 'href': '/wiki/Decision_list', 'section': 'Rule Induction', 'title': 'Decision list'}\n",
      "{'definition': 'In machine learning, first-order inductive learner (FOIL) is a rule-based learning algorithm.', 'href': '/wiki/First_Order_Inductive_Learner', 'section': 'Rule Induction', 'title': 'First Order Inductive Learner'}\n",
      "{'definition': 'Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness.[1]', 'href': '/wiki/Association_rule_learning', 'section': 'Association rules and Frequent Item Sets', 'title': 'Association rule learning'}\n",
      "{'definition': 'Apriori[1] is an algorithm for frequent item set mining and association rule learning over transactional databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.', 'href': '/wiki/Apriori_algorithm', 'section': 'Association rules and Frequent Item Sets', 'title': 'Apriori algorithm'}\n",
      "{'definition': \"Contrast set learning is a form of association rule learning that seeks to identify meaningful differences between separate groups by reverse-engineering the key predictors that identify for each particular group. For example, given a set of attributes for a pool of students (labeled by degree type), a contrast set learner would identify the contrasting features between students seeking bachelor's degrees and those working toward PhD degrees.\", 'href': '/wiki/Contrast_set_learning', 'section': 'Association rules and Frequent Item Sets', 'title': 'Contrast set learning'}\n",
      "{'definition': 'Affinity analysis is a data analysis and data mining technique that discovers co-occurrence relationships among activities performed by (or recorded about) specific individuals or groups. In general, this can be applied to any process where agents can be uniquely identified and information about their activities can be recorded. In retail, affinity analysis is used to perform market basket analysis, in which retailers seek to understand the purchase behavior of customers. This information can then be used for purposes of cross-selling and up-selling, in addition to influencing sales promotions, loyalty programs, store design, and discount plans.[1]', 'href': '/wiki/Affinity_analysis', 'section': 'Association rules and Frequent Item Sets', 'title': 'Affinity analysis'}\n",
      "{'definition': 'K-optimal pattern discovery is a data mining technique that provides an alternative to the frequent pattern discovery approach that underlies most association rule learning techniques.', 'href': '/wiki/K-optimal_pattern_discovery', 'section': 'Association rules and Frequent Item Sets', 'title': 'K-optimal pattern discovery'}\n",
      "{'definition': 'In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance that could be obtained from any of the constituent learning algorithms alone.[1][2][3][4] Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.', 'href': '/wiki/Ensemble_learning', 'section': 'Ensemble Learning', 'title': 'Ensemble learning'}\n",
      "{'definition': 'In machine learning, particularly in the creation of artificial neural networks, ensemble averaging is the process of creating multiple models and combining them to produce a desired output, as opposed to creating just one model. Frequently an ensemble of models performs better than any individual model, because the various errors of the models \"average out.\"', 'href': '/wiki/Ensemble_averaging', 'section': 'Ensemble Learning', 'title': 'Ensemble averaging'}\n",
      "{'definition': 'Clustering is the assignment of objects into groups (called clusters) so that objects from the same cluster are more similar to each other than objects from different clusters.[1] Often similarity is assessed according to a distance measure. Clustering is a common technique for statistical data analysis, which is used in many fields, including machine learning, data mining, pattern recognition, image analysis[2][3] and bioinformatics.', 'href': '/wiki/Consensus_clustering', 'section': 'Ensemble Learning', 'title': 'Consensus clustering'}\n",
      "{'definition': \"AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire, who won the 2003 Gödel Prize for their work. It can be used in conjunction with many other types of learning algorithms to improve performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers. AdaBoost is sensitive to noisy data and outliers. In some problems it can be less susceptible to the overfitting problem than other learning algorithms. The individual learners can be weak, but as long as the performance of each one is slightly better than random guessing, the final model can be proven to converge to a strong learner.\", 'href': '/wiki/AdaBoost', 'section': 'Ensemble Learning', 'title': 'AdaBoost'}\n",
      "{'definition': 'Boost or boosting may refer to:', 'href': '/wiki/Boosting', 'section': 'Ensemble Learning', 'title': 'Boosting'}\n",
      "{'definition': 'Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.', 'href': '/wiki/Bootstrap_aggregating', 'section': 'Ensemble Learning', 'title': 'Bootstrap aggregating'}\n",
      "{'definition': 'BrownBoost is a boosting algorithm that may be robust to noisy datasets. BrownBoost is an adaptive version of the boost by majority algorithm. As is true for all boosting algorithms, BrownBoost is used in conjunction with other machine learning methods. BrownBoost was introduced by Yoav Freund in 2001.[1]', 'href': '/wiki/BrownBoost', 'section': 'Ensemble Learning', 'title': 'BrownBoost'}\n",
      "{'definition': 'Cascading is a particular case of ensemble learning based on the concatenation of several Classifiers, using all information collected from the output from a given classifier as additional information for the next classifier in the cascade. Unlike voting or stacking ensembles, which are multiexpert systems, cascading is a multistage one.', 'href': '/wiki/Cascading_classifiers', 'section': 'Ensemble Learning', 'title': 'Cascading classifiers'}\n",
      "{'definition': 'Co-training is a machine learning algorithm used when there are only small amounts of labeled data and large amounts of unlabeled data. One of its uses is in text mining for search engines. It was introduced by Avrim Blum and Tom Mitchell in 1998.', 'href': '/wiki/Co-training', 'section': 'Ensemble Learning', 'title': 'Co-training'}\n",
      "{'definition': 'CoBoost is a semi-supervised training algorithm proposed by Collins and Singer in 1999. The original application for the algorithm was the task of Named Entity Classification using very weak learners.[1] It can be used for performing semi-supervised learning in cases in which there exist redundancy in features.', 'href': '/wiki/CoBoosting', 'section': 'Ensemble Learning', 'title': 'CoBoosting'}\n",
      "{'definition': 'In statistics, Gaussian process emulator is one name for a general type of statistical model that has been used in contexts where the problem is to make maximum use of the outputs of a complicated (often non-random) computer-based simulation model. Each run of the simulation model is computationally expensive and each run is based on many different controlling inputs. The variation of the outputs of the simulation model is expected to vary reasonably smoothly with the inputs, but in an unknown way.', 'href': '/wiki/Gaussian_process_emulator', 'section': 'Ensemble Learning', 'title': 'Gaussian process emulator'}\n",
      "{'definition': 'Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.', 'href': '/wiki/Gradient_boosting', 'section': 'Ensemble Learning', 'title': 'Gradient boosting'}\n",
      "{'definition': 'In machine learning and computational learning theory, LogitBoost is a boosting algorithm formulated by Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The original paper[1] casts the AdaBoost algorithm into a statistical framework. Specifically, if one considers AdaBoost as a generalized additive model and then applies the cost functional of logistic regression, one can derive the LogitBoost algorithm.', 'href': '/wiki/LogitBoost', 'section': 'Ensemble Learning', 'title': 'LogitBoost'}\n",
      "{'definition': 'Linear Programming Boosting (LPBoost) is a supervised classifier from the boosting family of classifiers. LPBoost maximizes a margin between training samples of different classes and hence also belongs to the class of margin-maximizing supervised classification algorithms. Consider a classification function', 'href': '/wiki/LPBoost', 'section': 'Ensemble Learning', 'title': 'LPBoost'}\n",
      "{'definition': 'In statistics, a mixture model is a probabilistic model for representing the presence of subpopulations within an overall population, without requiring that an observed data set should identify the sub-population to which an individual observation belongs. Formally a mixture model corresponds to the mixture distribution that represents the probability distribution of observations in the overall population. However, while problems associated with \"mixture distributions\" relate to deriving the properties of the overall population from those of the sub-populations, \"mixture models\" are used to make statistical inferences about the properties of the sub-populations given only observations on the pooled population, without sub-population identity information.', 'href': '/wiki/Mixture_model', 'section': 'Ensemble Learning', 'title': 'Mixture model'}\n",
      "{'definition': 'Product of experts (PoE) is a machine learning technique. It models a probability distribution by combining the output from several simpler distributions. It was proposed by Geoff Hinton, along with an algorithm for training the parameters of such a system.', 'href': '/wiki/Product_of_Experts', 'section': 'Ensemble Learning', 'title': 'Product of Experts'}\n",
      "{'definition': \"Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.[1][2] Random decision forests correct for decision trees' habit of overfitting to their training set.[3]:587–588\", 'href': '/wiki/Random_multinomial_logit', 'section': 'Ensemble Learning', 'title': 'Random multinomial logit'}\n",
      "{'definition': 'In machine learning the random subspace method,[1] also called attribute bagging[2] or feature bagging, is an ensemble learning method that attempts to reduce the correlation between estimators in an ensemble by training them on random samples of features instead of the entire feature set.', 'href': '/wiki/Random_subspace_method', 'section': 'Ensemble Learning', 'title': 'Random subspace method'}\n",
      "{'definition': 'In machine learning, weighted majority algorithm (WMA) is a meta-learning algorithm used to construct a compound algorithm from a pool of prediction algorithms, which could be any type of learning algorithms, classifiers, or even real human experts.[1][2] The algorithm assumes that we have no prior knowledge about the accuracy of the algorithms in the pool, but there are sufficient reasons to believe that one or more will perform well.', 'href': '/wiki/Weighted_Majority_Algorithm', 'section': 'Ensemble Learning', 'title': 'Weighted Majority Algorithm'}\n",
      "{'definition': 'The randomized weighted majority algorithm is an algorithm in machine learning theory.[1] It improves the mistake bound of the weighted majority algorithm.', 'href': '/wiki/Randomized_weighted_majority_algorithm', 'section': 'Ensemble Learning', 'title': 'Randomized weighted majority algorithm'}\n",
      "{'definition': 'A graphical model or probabilistic graphical model (PGM) or structured probabilistic model is a probabilistic model for which a graph expresses the conditional dependence structure between random variables. They are commonly used in probability theory, statistics—particularly Bayesian statistics—and machine learning.', 'href': '/wiki/Graphical_model', 'section': 'Graphical Models', 'title': 'Graphical model'}\n",
      "{'definition': 'A state transition network is a diagram that is developed from a set of data and charts the flow of data from particular data points (called states or nodes) to the next in a probabilistic manner.', 'href': '/wiki/State_transition_network', 'section': 'Graphical Models', 'title': 'State transition network'}\n",
      "{'definition': 'In machine learning, naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes\\' theorem with strong (naive) independence assumptions between the features.', 'href': '/wiki/Naive_Bayes_classifier', 'section': 'Bayesian Learning Methods', 'title': 'Naive Bayes classifier'}\n",
      "{'definition': 'Averaged one-dependence estimators (AODE) is a probabilistic classification learning technique. It was developed to address the attribute-independence problem of the popular naive Bayes classifier. It frequently develops substantially more accurate classifiers than naive Bayes at the cost of a modest increase in the amount of computation.[1]', 'href': '/wiki/Averaged_one-dependence_estimators', 'section': 'Bayesian Learning Methods', 'title': 'Averaged one-dependence estimators'}\n",
      "{'definition': 'A Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases.', 'href': '/wiki/Bayesian_network', 'section': 'Bayesian Learning Methods', 'title': 'Bayesian network'}\n",
      "{'definition': \"Variational message passing (VMP) is an approximate inference technique for continuous- or discrete-valued Bayesian networks, with conjugate-exponential parents, developed by John Winn. VMP was developed as a means of generalizing the approximate variational methods used by such techniques as Latent Dirichlet allocation and works by updating an approximate distribution at each node through messages in the node's Markov blanket.\", 'href': '/wiki/Variational_message_passing', 'section': 'Bayesian Learning Methods', 'title': 'Variational message passing'}\n",
      "{'definition': 'In probability theory, a Markov model is a stochastic model used to model randomly changing systems.[1] It is assumed that future states depend only on the current state, not on the events that occurred before it (that is, it assumes the Markov property). Generally, this assumption enables reasoning and computation with the model that would otherwise be intractable. For this reason, in the fields of predictive modelling and probabilistic forecasting, it is desirable for a given model to exhibit the Markov property.', 'href': '/wiki/Markov_model', 'section': 'Markov Models', 'title': 'Markov model'}\n",
      "{'definition': 'In machine learning, a maximum-entropy Markov model (MEMM), or conditional Markov model (CMM), is a graphical model for sequence labeling that combines features of hidden Markov models (HMMs) and maximum entropy (MaxEnt) models. An MEMM is a discriminative model that extends a standard maximum entropy classifier by assuming that the unknown values to be learnt are connected in a Markov chain rather than being conditionally independent of each other. MEMMs find applications in natural language processing, specifically in part-of-speech tagging[1] and information extraction.[2]', 'href': '/wiki/Maximum-entropy_Markov_model', 'section': 'Markov Models', 'title': 'Maximum-entropy Markov model'}\n",
      "{'definition': 'Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.', 'href': '/wiki/Hidden_Markov_model', 'section': 'Markov Models', 'title': 'Hidden Markov model'}\n",
      "{'definition': 'In electrical engineering, computer science, statistical computing and bioinformatics, the Baum–Welch algorithm is used to find the unknown parameters of a hidden Markov model (HMM). It makes use of the forward-backward algorithm and is named for Leonard E. Baum and Lloyd R. Welch.', 'href': '/wiki/Baum%E2%80%93Welch_algorithm', 'section': 'Markov Models', 'title': 'Baum–Welch algorithm'}\n",
      "{'definition': 'The forward–backward algorithm is an inference algorithm for hidden Markov models which computes the posterior marginals of all hidden state variables given a sequence of observations/emissions \\n\\n\\n\\n\\no\\n\\n1\\n:\\nT\\n\\n\\n:=\\n\\no\\n\\n1\\n\\n\\n,\\n…\\n,\\n\\no\\n\\nT\\n\\n\\n\\n\\n{\\\\displaystyle o_{1:T}:=o_{1},\\\\dots ,o_{T}}\\n\\n, i.e. it computes, for all hidden state variables \\n\\n\\n\\n\\nX\\n\\nt\\n\\n\\n∈\\n{\\n\\nX\\n\\n1\\n\\n\\n,\\n…\\n,\\n\\nX\\n\\nT\\n\\n\\n}\\n\\n\\n{\\\\displaystyle X_{t}\\\\in \\\\{X_{1},\\\\dots ,X_{T}\\\\}}\\n\\n, the distribution \\n\\n\\n\\nP\\n(\\n\\nX\\n\\nt\\n\\n\\n\\xa0\\n\\n|\\n\\n\\xa0\\n\\no\\n\\n1\\n:\\nT\\n\\n\\n)\\n\\n\\n{\\\\displaystyle P(X_{t}\\\\ |\\\\ o_{1:T})}\\n\\n. This inference task is usually called smoothing. The algorithm makes use of the principle of dynamic programming to efficiently compute the values that are required to obtain the posterior marginal distributions in two passes. The first pass goes forward in time while the second goes backward in time; hence the name forward–backward algorithm.', 'href': '/wiki/Forward%E2%80%93backward_algorithm', 'section': 'Markov Models', 'title': 'Forward–backward algorithm'}\n",
      "{'definition': 'The hierarchical hidden Markov model (HHMM) is a statistical model derived from the hidden Markov model (HMM). In an HHMM each state is considered to be a self-contained probabilistic model. More precisely each state of the HHMM is itself an HHMM.', 'href': '/wiki/Hierarchical_hidden_Markov_model', 'section': 'Markov Models', 'title': 'Hierarchical hidden Markov model'}\n",
      "{'definition': 'A Markov logic network (MLN) is a probabilistic logic which applies the ideas of a Markov network to first-order logic, enabling uncertain inference. Markov logic networks generalize first-order logic, in the sense that, in a certain limit, all unsatisfiable statements have a probability of zero, and all tautologies have probability one.', 'href': '/wiki/Markov_logic_network', 'section': 'Markov Models', 'title': 'Markov logic network'}\n",
      "{'definition': 'In statistics, Markov chain Monte Carlo (MCMC) methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by observing the chain after a number of steps. The more steps there are, the more closely the distribution of the sample matches the actual desired distribution.', 'href': '/wiki/Markov_chain_Monte_Carlo', 'section': 'Markov Models', 'title': 'Markov chain Monte Carlo'}\n",
      "{'definition': 'In the domain of physics and probability, a Markov random field (often abbreviated as MRF), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph. In other words, a random field is said to be a Markov random field if it satisfies Markov properties.', 'href': '/wiki/Markov_random_field', 'section': 'Markov Models', 'title': 'Markov random field'}\n",
      "{'definition': 'Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. CRFs fall into the sequence modeling family. Whereas a discrete classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account; e.g., the linear chain CRF (which is popular in natural language processing) predicts sequences of labels for sequences of input samples.', 'href': '/wiki/Conditional_random_field', 'section': 'Markov Models', 'title': 'Conditional random field'}\n",
      "{'definition': \"In computer science, a predictive state representation (PSR) is a way to model a state of controlled dynamical system from a history of actions taken and resulting observations. PSR captures the state of a system as a vector of predictions for future tests (experiments) that can be done on the system.[1] A test is a sequence of action-observation pairs and its prediction is the probability of the test's observation-sequence happening if the test's action-sequence were to be executed on the system. One of the advantage of using PSR is that the predictions are directly related to observable quantities. This is in contrast to other models of dynamical systems, such as partially observable Markov decision processes (POMDPs) where the state of the system is represented as a probability distribution over unobserved nominal states.[2]\", 'href': '/wiki/Predictive_state_representation', 'section': 'Markov Models', 'title': 'Predictive state representation'}\n",
      "{'definition': 'In computer science, computational learning theory (or just learning theory) is a subfield of Artificial Intelligence devoted to studying the design and analysis of machine learning algorithms.[1]', 'href': '/wiki/Computational_learning_theory', 'section': 'Learning Theory', 'title': 'Computational learning theory'}\n",
      "{'definition': 'Version space learning is a logical approach to machine learning, specifically binary classification. Version space learning algorithms search a predefined space of hypotheses, viewed as a set of logical sentences. Formally, the hypothesis space is a disjunction[1]', 'href': '/wiki/Version_space', 'section': 'Learning Theory', 'title': 'Version space'}\n",
      "{'definition': 'In computational learning theory, probably approximately correct learning (PAC learning) is a framework for mathematical analysis of machine learning. It was proposed in 1984 by Leslie Valiant.[1]', 'href': '/wiki/Probably_approximately_correct_learning', 'section': 'Learning Theory', 'title': 'Probably approximately correct learning'}\n",
      "{'definition': 'Vapnik–Chervonenkis theory (also known as VC theory) was developed during 1960–1990 by Vladimir Vapnik and Alexey Chervonenkis. The theory is a form of computational learning theory, which attempts to explain the learning process from a statistical point of view.', 'href': '/wiki/Vapnik%E2%80%93Chervonenkis_theory', 'section': 'Learning Theory', 'title': 'Vapnik–Chervonenkis theory'}\n",
      "{'definition': 'The concept of shattered sets plays an important role in Vapnik–Chervonenkis theory, also known as VC-theory. Shattering and VC-theory are used in the study of empirical processes as well as in statistical computational learning theory.', 'href': '/wiki/Shattering_(machine_learning)', 'section': 'Learning Theory', 'title': 'Shattering (machine learning)'}\n",
      "{'definition': 'In Vapnik–Chervonenkis theory, the VC dimension (for Vapnik–Chervonenkis dimension) is a measure of the capacity (complexity, expressive power, richness, or flexibility) of a space of functions that can be learned by a statistical classification algorithm. It is defined as the cardinality of the largest set of points that the algorithm can shatter. It was originally defined by Vladimir Vapnik and Alexey Chervonenkis.[1]', 'href': '/wiki/VC_dimension', 'section': 'Learning Theory', 'title': 'VC dimension'}\n",
      "{'definition': \"The minimum description length (MDL) principle is a formalization of Occam's razor in which the best hypothesis (a model and its parameters) for a given set of data is the one that leads to the best compression of the data. MDL was introduced by Jorma Rissanen in 1978.[1] It is an important concept in information theory and computational learning theory.[2][3][4]\", 'href': '/wiki/Minimum_description_length', 'section': 'Learning Theory', 'title': 'Minimum description length'}\n",
      "{'definition': \"In mathematics, Bondy's theorem is a bound on the number of elements needed to distinguish the sets in a family of sets from each other. It belongs to the field of combinatorics, and is named after John Adrian Bondy, who published it in 1972.[1]\", 'href': '/wiki/Bondy%27s_theorem', 'section': 'Learning Theory', 'title': \"Bondy's theorem\"}\n",
      "{'definition': 'Inferential theory of learning (ITL) is an area of machine learning which describes inferential processes performed by learning agents. ITL has been developed by Ryszard S. Michalski in 1980s. In ITL learning process is viewed as a search (inference) through hypotheses space guided by a specific goal. Results of learning need to be stored, in order to be used in the future.', 'href': '/wiki/Inferential_theory_of_learning', 'section': 'Learning Theory', 'title': 'Inferential theory of learning'}\n",
      "{'definition': 'In computational learning theory (machine learning and theory of computation), Rademacher complexity, named after Hans Rademacher, measures richness of a class of real-valued functions with respect to a probability distribution.', 'href': '/wiki/Rademacher_complexity', 'section': 'Learning Theory', 'title': 'Rademacher complexity'}\n",
      "{'definition': 'In computational learning theory, the teaching dimension[1] of a concept class C is defined to be \\n\\n\\n\\n\\nmax\\n\\nc\\n∈\\nC\\n\\n\\n{\\n\\nw\\n\\nC\\n\\n\\n(\\nc\\n)\\n}\\n\\n\\n{\\\\displaystyle \\\\max _{c\\\\in C}\\\\{w_{C}(c)\\\\}}\\n\\n, where \\n\\n\\n\\n\\n\\nw\\n\\nC\\n\\n\\n(\\nc\\n)\\n\\n\\n\\n{\\\\displaystyle {w_{C}(c)}}\\n\\n is the minimum size of a witness set for c in C.', 'href': '/wiki/Teaching_dimension', 'section': 'Learning Theory', 'title': 'Teaching dimension'}\n",
      "{'definition': 'In computational learning theory in mathematics, given a class of concepts C, a subclass D is reachable if there exists a partial approximation S of some concept such that D contains exactly those concepts in C that are extensions to S (i.e., D=C|S).', 'href': '/wiki/Subclass_reachability', 'section': 'Learning Theory', 'title': 'Subclass reachability'}\n",
      "{'definition': 'In computational learning theory, sample exclusion dimensions arise in the study of exact concept learning with queries.[1]', 'href': '/wiki/Sample_exclusion_dimension', 'section': 'Learning Theory', 'title': 'Sample exclusion dimension'}\n",
      "{'definition': '\\nUnique negative dimension (UND) is a complexity measure for the model of learning from positive examples. The unique negative dimension of a class \\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n of concepts is the size of the maximum subclass \\n\\n\\n\\nD\\n⊆\\nC\\n\\n\\n{\\\\displaystyle D\\\\subseteq C}\\n\\n such that for every concept \\n\\n\\n\\nc\\n∈\\nD\\n\\n\\n{\\\\displaystyle c\\\\in D}\\n\\n, we have \\n\\n\\n\\n∩\\n(\\nD\\n∖\\n{\\nc\\n}\\n)\\n∖\\nc\\n\\n\\n{\\\\displaystyle \\\\cap (D\\\\setminus \\\\{c\\\\})\\\\setminus c}\\n\\n is nonempty.', 'href': '/wiki/Unique_negative_dimension', 'section': 'Learning Theory', 'title': 'Unique negative dimension'}\n",
      "{'definition': 'Uniform convergence in probability is a form of convergence in probability in statistical asymptotic theory and probability theory. It means that, under certain conditions, the empirical frequencies of all events in a certain event-family converge to their theoretical probabilities. Uniform convergence in probability has applications to statistics as well as machine learning as part of statistical learning theory.', 'href': '/wiki/Uniform_convergence_(combinatorics)', 'section': 'Learning Theory', 'title': 'Uniform convergence (combinatorics)'}\n",
      "{'definition': 'In computational learning theory, let C be a concept class over a domain X and c be a concept in C. A subset S of X is a witness set for c in C if c(S) verifies c (i.e., c is the only consistent concept with respect to c(S)). The minimum size of a witness set for c is called the witness size or specification number and is denoted by \\n\\n\\n\\n\\nw\\n\\nC\\n\\n\\n(\\nc\\n)\\n\\n\\n{\\\\displaystyle w_{C}(c)}\\n\\n. The value \\n\\n\\n\\nmax\\n{\\n\\nw\\n\\nC\\n\\n\\n(\\nc\\n)\\n:\\nc\\n∈\\nC\\n}\\n\\n\\n{\\\\displaystyle \\\\max\\\\{w_{C}(c):c\\\\in C\\\\}}\\n\\n is called the teaching dimension of C.', 'href': '/wiki/Witness_set', 'section': 'Learning Theory', 'title': 'Witness set'}\n",
      "{'definition': 'In machine learning, kernel methods are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM). The general task of pattern analysis is to find and study general types of relations (for example clusters, rankings, principal components, correlations, classifications) in datasets. For many algorithms that solve these tasks, the data in raw representation have to be explicitly transformed into feature vector representations via a user-specified feature map: in contrast, kernel methods require only a user-specified kernel, i.e., a similarity function over pairs of data points in raw representation.', 'href': '/wiki/Kernel_methods', 'section': 'Support Vector Machines', 'title': 'Kernel methods'}\n",
      "{'definition': 'In machine learning, support vector machines (SVMs, also support vector networks[1]) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.', 'href': '/wiki/Support_vector_machine', 'section': 'Support Vector Machines', 'title': 'Support vector machine'}\n",
      "{'definition': \"Structural risk minimization (SRM) is an inductive principle of use in machine learning. Commonly in machine learning, a generalized model must be selected from a finite data set, with the consequent problem of overfitting – the model becoming too strongly tailored to the particularities of the training set and generalizing poorly to new data. The SRM principle addresses this problem by balancing the model's complexity against its success at fitting the training data.\", 'href': '/wiki/Structural_risk_minimization', 'section': 'Support Vector Machines', 'title': 'Structural risk minimization'}\n",
      "{'definition': 'Empirical risk minimization (ERM) is a principle in statistical learning theory which defines a family of learning algorithms and is used to give theoretical bounds on their performance.', 'href': '/wiki/Empirical_risk_minimization', 'section': 'Support Vector Machines', 'title': 'Empirical risk minimization'}\n",
      "{'definition': 'In machine learning, kernel methods are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM). The general task of pattern analysis is to find and study general types of relations (for example clusters, rankings, principal components, correlations, classifications) in datasets. For many algorithms that solve these tasks, the data in raw representation have to be explicitly transformed into feature vector representations via a user-specified feature map: in contrast, kernel methods require only a user-specified kernel, i.e., a similarity function over pairs of data points in raw representation.', 'href': '/wiki/Kernel_trick', 'section': 'Support Vector Machines', 'title': 'Kernel trick'}\n",
      "{'definition': 'Least squares support vector machines (LS-SVM) are least squares versions of support vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis. In this version one finds the solution by solving a set of linear equations instead of a convex quadratic programming (QP) problem for classical SVMs. Least squares SVM classifiers, were proposed by Suykens and Vandewalle.[1] LS-SVMs are a class of kernel-based learning methods.', 'href': '/wiki/Least_squares_support_vector_machine', 'section': 'Support Vector Machines', 'title': 'Least squares support vector machine'}\n",
      "{'definition': 'In mathematics, a Relevance Vector Machine (RVM) is a machine learning technique that uses Bayesian inference to obtain parsimonious solutions for regression and probabilistic classification.[1] The RVM has an identical functional form to the support vector machine, but provides probabilistic classification.', 'href': '/wiki/Relevance_vector_machine', 'section': 'Support Vector Machines', 'title': 'Relevance vector machine'}\n",
      "{'definition': 'Sequential minimal optimization (SMO) is an algorithm for solving the quadratic programming (QP) problem that arises during the training of support vector machines. It was invented by John Platt in 1998 at Microsoft Research.[1] SMO is widely used for training support vector machines and is implemented by the popular LIBSVM tool.[2][3] The publication of the SMO algorithm in 1998 has generated a lot of excitement in the SVM community, as previously available methods for SVM training were much more complex and required expensive third-party QP solvers.[4]', 'href': '/wiki/Sequential_minimal_optimization', 'section': 'Support Vector Machines', 'title': 'Sequential minimal optimization'}\n",
      "{'definition': 'The structured support vector machine is a machine learning algorithm that generalizes the Support Vector Machine (SVM) classifier. Whereas the SVM classifier supports binary classification, multiclass classification and regression, the structured SVM allows training of a classifier for general structured output labels.', 'href': '/wiki/Structured_SVM', 'section': 'Support Vector Machines', 'title': 'Structured SVM'}\n",
      "{'definition': 'The following outline is provided as an overview of and topical guide to regression analysis:', 'href': '/wiki/Outline_of_regression_analysis', 'section': 'Regression analysis', 'title': 'Outline of regression analysis'}\n",
      "{'definition': \"In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed.\", 'href': '/wiki/Regression_analysis', 'section': 'Regression analysis', 'title': 'Regression analysis'}\n",
      "{'definition': 'In mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables represent inputs or causes, i.e., potential reasons for variation or, in the experimental setting, the variable controlled by the experimenter. Models and experiments test or determine the effects that the independent variables have on the dependent variables. Sometimes, independent variables may be included for other reasons, such as for their potential confounding effect, without a wish to test their effect directly.', 'href': '/wiki/Dependent_and_independent_variables', 'section': 'Regression analysis', 'title': 'Dependent and independent variables'}\n",
      "{'definition': 'In statistics, the term linear model is used in different ways according to the context. The most common occurrence is in connection with regression models and the term is often taken as synonymous with linear regression model. However, the term is also used in time series analysis with a different meaning. In each case, the designation \"linear\" is used to identify a subclass of models for which substantial reduction in the complexity of the related statistical theory is possible.', 'href': '/wiki/Linear_model', 'section': 'Regression analysis', 'title': 'Linear model'}\n",
      "{'definition': 'In statistics, linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.[1] This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.[2]', 'href': '/wiki/Linear_regression', 'section': 'Regression analysis', 'title': 'Linear regression'}\n",
      "{'definition': 'The method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems, i.e., sets of equations in which there are more equations than unknowns. \"Least squares\" means that the overall solution minimizes the sum of the squares of the residuals made in the results of every single equation.', 'href': '/wiki/Least_squares', 'section': 'Regression analysis', 'title': 'Least squares'}\n",
      "{'definition': 'In statistics and mathematics, linear least squares is an approach to fitting a mathematical or statistical model to data in cases where the idealized value provided by the model for any data point is expressed linearly in terms of the unknown parameters of the model. The resulting fitted model can be used to summarize the data, to predict unobserved values from the same system, and to understand the mechanisms that may underlie the system.', 'href': '/wiki/Linear_least_squares_(mathematics)', 'section': 'Regression analysis', 'title': 'Linear least squares (mathematics)'}\n",
      "{'definition': 'LOESS (/ˈloʊɛs/) and LOWESS (locally weighted scatterplot smoothing) are two strongly related non-parametric regression methods that combine multiple regression models in a k-nearest-neighbor-based meta-model. \"LOESS\" is a later generalization of LOWESS; although it is not a true acronym, it may be understood as standing for \"LOcal regrESSion\".[1]', 'href': '/wiki/Local_regression', 'section': 'Regression analysis', 'title': 'Local regression'}\n",
      "{'definition': 'In statistics, an additive model (AM) is a nonparametric regression method. It was suggested by Jerome H. Friedman and Werner Stuetzle (1981)[1] and is an essential part of the ACE algorithm. The AM uses a one-dimensional smoother to build a restricted class of nonparametric regression models. Because of this, it is less affected by the curse of dimensionality than e.g. a p-dimensional smoother. Furthermore, the AM is more flexible than a standard linear model, while being more interpretable than a general regression surface at the cost of approximation errors. Problems with AM include model selection, overfitting, and multicollinearity.', 'href': '/wiki/Additive_model', 'section': 'Regression analysis', 'title': 'Additive model'}\n",
      "{'definition': 'In statistics and social sciences, an antecedent variable is a variable that can help to explain the apparent relationship (or part of the relationship) between other variables that are nominally in a cause and effect relationship. In a regression analysis, an antecedent variable would be one that influences both the independent variable and the dependent variable.', 'href': '/wiki/Antecedent_variable', 'section': 'Regression analysis', 'title': 'Antecedent variable'}\n",
      "{'definition': 'Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them. The analysis of autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies. It is often used in signal processing for analyzing functions or series of values, such as time domain signals.', 'href': '/wiki/Autocorrelation', 'section': 'Regression analysis', 'title': 'Autocorrelation'}\n",
      "{'definition': 'In statistics, the backfitting algorithm is a simple iterative procedure used to fit a generalized additive model. It was introduced in 1985 by Leo Breiman and Jerome Friedman along with generalized additive models. In most cases, the backfitting algorithm is equivalent to the Gauss–Seidel method algorithm for solving a certain linear system of equations.', 'href': '/wiki/Backfitting_algorithm', 'section': 'Regression analysis', 'title': 'Backfitting algorithm'}\n",
      "{'definition': \"In statistics, Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference. When the regression model has errors that have a normal distribution, and if a particular form of prior distribution is assumed, explicit results are available for the posterior probability distributions of the model's parameters.\", 'href': '/wiki/Bayesian_linear_regression', 'section': 'Regression analysis', 'title': 'Bayesian linear regression'}\n",
      "{'definition': 'In statistics, Bayesian multivariate linear regression is a Bayesian approach to multivariate linear regression, i.e. linear regression where the predicted outcome is a vector of correlated random variables rather than a single scalar random variable. A more general treatment of this approach can be found in the article MMSE estimator.', 'href': '/wiki/Bayesian_multivariate_linear_regression', 'section': 'Regression analysis', 'title': 'Bayesian multivariate linear regression'}\n",
      "{'definition': 'In statistics, binomial regression is a technique in which the response (often referred to as Y) is the result of a series of Bernoulli trials, or a series of one of two possible disjoint outcomes (traditionally denoted \"success\" or 1, and \"failure\" or 0).[1] In binomial regression, the probability of a success is related to explanatory variables: the corresponding concept in ordinary regression is to relate the mean value of the unobserved response to explanatory variables.', 'href': '/wiki/Binomial_regression', 'section': 'Regression analysis', 'title': 'Binomial regression'}\n",
      "{'definition': 'In statistics, canonical analysis (from Ancient Greek: κανων bar, measuring rod, ruler) belongs to the family of regression methods for data analysis. Regression analysis quantifies a relationship between a predictor variable and a criterion variable by the coefficient of correlation r, coefficient of determination r2, and the standard regression coefficient β. Multiple regression analysis expresses a relationship between a set of predictor variables and a single criterion variable by the multiple correlation\\xa0R, multiple coefficient of determination R², and a set of standard partial regression weights β1, β2, etc. Canonical variate analysis captures a relationship between a set of predictor variables and a set of criterion variables by the canonical correlations ρ1, ρ2, ..., and by the sets of canonical weights C and D.', 'href': '/wiki/Canonical_analysis', 'section': 'Regression analysis', 'title': 'Canonical analysis'}\n",
      "{'definition': 'Censored regression models commonly arise in econometrics in cases where the variable of interest is only observable under certain conditions. A common example is labor supply. Data are frequently available on the hours worked by employees, and a labor supply model estimates the relationship between hours worked and characteristics of employees such as age, education and family status. However, such estimates undertaken using linear regression will be biased by the fact that for people who are unemployed it is not possible to observe the number of hours they would have worked had they had employment. Still we know age, education and family status for those observations. The censored model shall not be confused with the truncated regression model, which is in general different and requires different types of estimators.[1]', 'href': '/wiki/Censored_regression_model', 'section': 'Regression analysis', 'title': 'Censored regression model'}\n",
      "{'definition': 'In statistics, the coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).', 'href': '/wiki/Coefficient_of_determination', 'section': 'Regression analysis', 'title': 'Coefficient of determination'}\n",
      "{'definition': None, 'href': '/wiki/Comparison_of_general_and_generalized_linear_models', 'section': 'Regression analysis', 'title': 'Comparison of general and generalized linear models'}\n",
      "{'definition': 'Compressed sensing (also known as compressive sensing, compressive sampling, or sparse sampling) is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the Shannon-Nyquist sampling theorem. There are two conditions under which recovery is possible.[1] The first one is sparsity which requires the signal to be sparse in some domain. The second one is incoherence which is applied through the isometric property which is sufficient for sparse signals.[2][3]', 'href': '/wiki/Compressed_sensing', 'section': 'Regression analysis', 'title': 'Compressed sensing'}\n",
      "{'definition': 'The conditional change model in statistics is the analytic procedure in which change scores are regressed on baseline values, together with the explanatory variables of interest (often including indicators of treatment groups). The method has some substantial advantages over the usual two-sample t-test recommended in textbooks.', 'href': '/wiki/Conditional_change_model', 'section': 'Regression analysis', 'title': 'Conditional change model'}\n",
      "{'definition': 'In statistics, controlling for a variable is the attempt to reduce the effect of confounding variables in an observational study or experiment. It means that when looking at the effect of one variable, the effects of all other variable predictors are taken into account,[1] either by making the other variables take on a fixed value (in an experiment) or by including them in a regression to separate their effects from those of the explanatory variable of interest (in an observational study).', 'href': '/wiki/Controlling_for_a_variable', 'section': 'Regression analysis', 'title': 'Controlling for a variable'}\n",
      "{'definition': 'In statistics and econometrics, a cross-sectional regression is a type of regression in which the explained and explanatory variables are associated with one period or point in time. This type of cross-sectional analysis is in contrast to a time-series regression or longitudinal regression in which the variables are considered to be associated with a sequence of points in time.', 'href': '/wiki/Cross-sectional_regression', 'section': 'Regression analysis', 'title': 'Cross-sectional regression'}\n",
      "{'definition': 'Curve fitting[1][2] is the process of constructing a curve, or mathematical function, that has the best fit to a series of data points,[3] possibly subject to constraints.[4][5] Curve fitting can involve either interpolation,[6][7] where an exact fit to the data is required, or smoothing,[8][9] in which a \"smooth\" function is constructed that approximately fits the data. A related topic is regression analysis,[10][11] which focuses more on questions of statistical inference such as how much uncertainty is present in a curve that is fit to data observed with random errors. Fitted curves can be used as an aid for data visualization,[12][13] to infer values of a function where no data are available,[14] and to summarize the relationships among two or more variables.[15] Extrapolation refers to the use of a fitted curve beyond the range of the observed data,[16] and is subject to a degree of uncertainty[17] since it may reflect the method used to construct the curve as much as it reflects the observed data.', 'href': '/wiki/Curve_fitting', 'section': 'Regression analysis', 'title': 'Curve fitting'}\n",
      "{'definition': 'In statistics, Deming regression, named after W. Edwards Deming, is an errors-in-variables model which tries to find the line of best fit for a two-dimensional dataset. It differs from the simple linear regression in that it accounts for errors in observations on both the x- and the y- axis. It is a special case of total least squares, which allows for any number of predictors and a more complicated error structure.', 'href': '/wiki/Deming_regression', 'section': 'Regression analysis', 'title': 'Deming regression'}\n",
      "{'definition': 'In statistics, a design matrix, also known as regressor matrix or model matrix or data matrix, is a matrix of values of explanatory variables of a set of objects, often denoted by X. Each row represents an individual object, with the successive columns corresponding to the variables and their specific values for that object. The design matrix is used in certain statistical models, e.g., the general linear model.[1][2][3] It can contain indicator variables (ones and zeros) that indicate group membership in an ANOVA, or it can contain values of continuous variables.', 'href': '/wiki/Design_matrix', 'section': 'Regression analysis', 'title': 'Design matrix'}\n",
      "{'definition': \"Difference in differences (DID[1] or DD[2]) is a statistical technique used in econometrics and quantitative research in the social sciences that attempts to mimic an experimental research design using observational study data, by studying the differential effect of a treatment on a 'treatment group' versus a 'control group' in a natural experiment.[3] It calculates the effect of a treatment (i.e., an explanatory variable or an independent variable) on an outcome (i.e., a response variable or dependent variable) by comparing the average change over time in the outcome variable for the treatment group, compared to the average change over time for the control group. Although it is intended to mitigate the effects of extraneous factors and selection bias, depending on how the treatment group is chosen, this method may still be subject to certain biases (e.g., mean regression, reverse causality and omitted variable bias).\", 'href': '/wiki/Difference_in_differences', 'section': 'Regression analysis', 'title': 'Difference in differences'}\n",
      "{'definition': 'In statistics and econometrics, particularly in regression analysis, a dummy variable (also known as an indicator variable, design variable, Boolean indicator, binary variable, or qualitative variable[1][2]) is one that takes the value 0 or 1 to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.[3][4] Dummy variables are used as devices to sort data into mutually exclusive categories (such as smoker/non-smoker, etc.).[2] For example, in econometric time series analysis, dummy variables may be used to indicate the occurrence of wars or major strikes. A dummy variable can thus be thought of as a truth value represented as a numerical value 0 or 1 (as is sometimes done in computer programming).', 'href': '/wiki/Dummy_variable_(statistics)', 'section': 'Regression analysis', 'title': 'Dummy variable (statistics)'}\n",
      "{'definition': 'In statistics and optimization, errors and residuals are two closely related and easily confused measures of the deviation of an observed value of an element of a statistical sample from its \"theoretical value\". The error (or disturbance) of an observed value is the deviation of the observed value from the (unobservable) true value of a quantity of interest (for example, a population mean), and the residual of an observed value is the difference between the observed value and the estimated value of the quantity of interest (for example, a sample mean). The distinction is most important in regression analysis, where the concepts are sometimes called the regression errors and regression residuals and where they lead to the concept of studentized residuals.', 'href': '/wiki/Errors_and_residuals_in_statistics', 'section': 'Regression analysis', 'title': 'Errors and residuals in statistics'}\n",
      "{'definition': 'In statistics, errors-in-variables models or measurement error models[1][2][3] are regression models that account for measurement errors in the independent variables. In contrast, standard regression models assume that those regressors have been measured exactly, or observed without error; as such, those models account only for errors in the dependent variables, or responses.[citation needed]', 'href': '/wiki/Errors-in-variables_models', 'section': 'Regression analysis', 'title': 'Errors-in-variables models'}\n",
      "{'definition': 'In statistics, the explained sum of squares (ESS), alternatively known as the model sum of squares or sum of squares due to regression (\"SSR\" – not to be confused with the residual sum of squares RSS), is a quantity used in describing how well a model, often a regression model, represents the data being modelled. In particular, the explained sum of squares measures how much variation there is in the modelled values and this is compared to the total sum of squares, which measures how much variation there is in the observed data, and to the residual sum of squares, which measures the variation in the modelling errors.', 'href': '/wiki/Explained_sum_of_squares', 'section': 'Regression analysis', 'title': 'Explained sum of squares'}\n",
      "{'definition': 'In statistics, explained variation measures the proportion to which a mathematical model accounts for the variation (dispersion) of a given data set. Often, variation is quantified as variance; then, the more specific term explained variance can be used.', 'href': '/wiki/Explained_variation', 'section': 'Regression analysis', 'title': 'Explained variation'}\n",
      "{'definition': 'Events are often triggered when a stochastic or random process first encounters a threshold. The threshold can be a barrier, boundary or specified state of a system. The amount of time required for a stochastic process, starting from some initial state, to encounter a threshold for the first time is referred to variously as a first hitting time. In statistics, first-hitting-time models are a sub-class of survival models. The first hitting time, also called first passage time, of the barrier set \\n\\n\\n\\nB\\n\\n\\n{\\\\displaystyle B}\\n\\n with respect to an instance of a stochastic process is the time until the stochastic process first enters \\n\\n\\n\\nB\\n\\n\\n{\\\\displaystyle B}\\n\\n.', 'href': '/wiki/First-hitting-time_model', 'section': 'Regression analysis', 'title': 'First-hitting-time model'}\n",
      "{'definition': 'In statistics, a fixed effects model is a statistical model in which the model parameters are fixed or non-random quantities. This is in contrast to random effects models and mixed models in which all or some of the model parameters are considered as random variables. In many applications including econometrics[1] and biostatistics[2][3][4][5] a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.[6] Generally, data can be grouped according to several observed factors. The group means could be modeled as fixed or random effects for each grouping. In a fixed effects model each group mean is a group-specific fixed quantity.', 'href': '/wiki/Fixed_effects_model', 'section': 'Regression analysis', 'title': 'Fixed effects model'}\n",
      "{'definition': 'In statistics, the fraction of variance unexplained (FVU) in the context of a regression task is the fraction of variance of the regressand (dependent variable) Y which cannot be explained, i.e., which is not correctly predicted, by the explanatory variables X.', 'href': '/wiki/Fraction_of_variance_unexplained', 'section': 'Regression analysis', 'title': 'Fraction of variance unexplained'}\n",
      "{'definition': 'In econometrics, the Frisch–Waugh–Lovell (FWL) theorem is named after the econometricians Ragnar Frisch, Frederick V. Waugh, and Michael C. Lovell.[1][2][3]', 'href': '/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem', 'section': 'Regression analysis', 'title': 'Frisch–Waugh–Lovell theorem'}\n",
      "{'definition': 'The general linear model or multivariate regression model is a statistical linear model. It may be written as[1]', 'href': '/wiki/General_linear_model', 'section': 'Regression analysis', 'title': 'General linear model'}\n",
      "{'definition': 'In statistics, a generalized additive model (GAM) is a generalized linear model in which the linear predictor depends linearly on unknown smooth functions of some predictor variables, and interest focuses on inference about these smooth functions. GAMs were originally developed by Trevor Hastie and Robert Tibshirani[1] to blend properties of generalized linear models with additive models.', 'href': '/wiki/Generalized_additive_model', 'section': 'Regression analysis', 'title': 'Generalized additive model'}\n",
      "{'definition': 'The Generalized Additive Model for Location, Scale and Shape (GAMLSS) is about statistical modelling and learning. GAMLSS is a modern distribution based approach to (semiparametric) regression analysis. A parametric distribution is assumed for the response (target) variable but the parameters of this distribution can vary according to explanatory variables using linear, nonlinear or smooth functions. In data science language GAMLSS is about supervised machine learning.', 'href': '/wiki/Generalized_additive_model_for_location,_scale_and_shape', 'section': 'Regression analysis', 'title': 'Generalized additive model for location, scale and shape'}\n",
      "{'definition': 'In statistics, a generalized estimating equation (GEE) is used to estimate the parameters of a generalized linear model with a possible unknown correlation between outcomes.[1][2]', 'href': '/wiki/Generalized_estimating_equation', 'section': 'Regression analysis', 'title': 'Generalized estimating equation'}\n",
      "{'definition': 'In statistics, generalized least squares (GLS) is a technique for estimating the unknown parameters in a linear regression model. GLS can be used to perform linear regression when there is a certain degree of correlation between the residuals in a regression model. In these cases, ordinary least squares and weighted least squares can be statistically inefficient, or even give misleading inferences. GLS was first described by Alexander Aitken in 1934.[1]', 'href': '/wiki/Generalized_least_squares', 'section': 'Regression analysis', 'title': 'Generalized least squares'}\n",
      "{'definition': 'In statistics, the generalized linear array model (GLAM) is used for analyzing data sets with array structures. It based on the generalized linear model with the design matrix written as a Kronecker product.', 'href': '/wiki/Generalized_linear_array_model', 'section': 'Regression analysis', 'title': 'Generalized linear array model'}\n",
      "{'definition': 'In statistics, a generalized linear mixed model (GLMM) is an extension to the generalized linear model (GLM) in which the linear predictor contains random effects in addition to the usual fixed effects.[1][2][3] They also inherit from GLMs the idea of extending linear mixed models to non-normal data.', 'href': '/wiki/Generalized_linear_mixed_model', 'section': 'Regression analysis', 'title': 'Generalized linear mixed model'}\n",
      "{'definition': 'In statistics, the generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.', 'href': '/wiki/Generalized_linear_model', 'section': 'Regression analysis', 'title': 'Generalized linear model'}\n",
      "{'definition': 'Growth curve can refer to:', 'href': '/wiki/Growth_curve', 'section': 'Regression analysis', 'title': 'Growth curve'}\n",
      "{'definition': 'In mathematical modeling, a guess value is more commonly called a starting value or initial value. These are necessary for most optimization problems which use search algorithms, because those algorithms are mainly deterministic and iterative, and they need to start somewhere. One common type of application is nonlinear regression.', 'href': '/wiki/Guess_value', 'section': 'Regression analysis', 'title': 'Guess value'}\n",
      "{'definition': 'In statistics, the projection matrix \\n\\n\\n\\n\\nP\\n\\n\\n\\n{\\\\displaystyle \\\\mathbf {P} }\\n\\n,[1] sometimes also called the influence matrix[2] or hat matrix \\n\\n\\n\\n\\nH\\n\\n\\n\\n{\\\\displaystyle \\\\mathbf {H} }\\n\\n, maps the vector of response values (dependent variable values) to the vector of fitted values (or predicted values). It describes the influence each response value has on each fitted value.[3][4] The diagonal elements of the projection matrix are the leverages, which describe the influence each response value has on the fitted value for that same observation.', 'href': '/wiki/Hat_matrix', 'section': 'Regression analysis', 'title': 'Hat matrix'}\n",
      "{'definition': \"The Heckman correction (the two-stage method, Heckman's lambda or the Heckit method[1]) is any of a number of related statistical methods developed by James Heckman at the University of Chicago in 1976 to 1979 which allow the researcher to correct for selection bias.[2] Selection bias problems are endemic to applied econometric problems,[3][4] which make Heckman’s original technique, and subsequent refinements by both himself and others, indispensable to applied econometricians. Heckman received the Economics Nobel Prize in 2000 for this achievement.\", 'href': '/wiki/Heckman_correction', 'section': 'Regression analysis', 'title': 'Heckman correction'}\n",
      "{'definition': 'The topic of heteroscedasticity-consistent (HC) standard errors arises in statistics and econometrics in the context of linear regression as well as time series analysis. These are also known as Eicker–Huber–White standard errors (also Huber–White standard errors or White standard errors),[1] to recognize the contributions of Friedhelm Eicker,[2] Peter J. Huber,[3] and Halbert White.[4]', 'href': '/wiki/Heteroscedasticity-consistent_standard_errors', 'section': 'Regression analysis', 'title': 'Heteroscedasticity-consistent standard errors'}\n",
      "{'definition': 'The Hosmer–Lemeshow test is a statistical test for goodness of fit for logistic regression models. It is used frequently in risk prediction models. The test assesses whether or not the observed event rates match expected event rates in subgroups of the model population. The Hosmer–Lemeshow test specifically identifies subgroups as the deciles of fitted risk values. Models for which expected and observed event rates in subgroups are similar are called well calibrated.', 'href': '/wiki/Hosmer%E2%80%93Lemeshow_test', 'section': 'Regression analysis', 'title': 'Hosmer–Lemeshow test'}\n",
      "{'definition': 'In statistics, econometrics, epidemiology and related disciplines, the method of instrumental variables (IV) is used to estimate causal relationships when controlled experiments are not feasible or when a treatment is not successfully delivered to every unit in a randomized experiment.[1] Intuitively, IV is used when an explanatory variable of interest is correlated with the error term, in which case ordinary least squares and ANOVA gives biased results. A valid instrument induces changes in the explanatory variable but has no independent effect on the dependent variable, allowing a researcher to uncover the causal effect of the explanatory variable on the dependent variable.', 'href': '/wiki/Instrumental_variable', 'section': 'Regression analysis', 'title': 'Instrumental variable'}\n",
      "{'definition': 'In statistics, an interaction[1][2] may arise when considering the relationship among three or more variables, and describes a situation in which the simultaneous influence of two variables on a third is not additive. Most commonly, interactions are considered in the context of regression analyses.', 'href': '/wiki/Interaction_(statistics)', 'section': 'Regression analysis', 'title': 'Interaction (statistics)'}\n",
      "{'definition': 'In statistics, isotonic regression or monotonic regression is the technique of fitting a free-form line to a sequence of observations under the following constraints: the fitted free-form line has to be non-decreasing everywhere, and it has to lie as close to the observations as possible.', 'href': '/wiki/Isotonic_regression', 'section': 'Regression analysis', 'title': 'Isotonic regression'}\n",
      "{'definition': 'The method of iteratively reweighted least squares (IRLS) is used to solve certain optimization problems with objective functions of the form:', 'href': '/wiki/Iteratively_reweighted_least_squares', 'section': 'Regression analysis', 'title': 'Iteratively reweighted least squares'}\n",
      "{'definition': 'Pejoratively, a kitchen sink regression is a statistical regression which uses a long list of possible independent variables to attempt to explain variance in a dependent variable. In economics, psychology, and other social sciences, regression analysis is typically used deductively to test hypotheses, but a kitchen sink regression does not follow this norm. Instead, the analyst throws \"everything but the kitchen sink\" into the regression in hopes of finding some statistical pattern.[citation needed]', 'href': '/wiki/Kitchen_sink_regression', 'section': 'Regression analysis', 'title': 'Kitchen sink regression'}\n",
      "{'definition': 'In statistics, a sum of squares due to lack of fit, or more tersely a lack-of-fit sum of squares, is one of the components of a partition of the sum of squares of residuals in an analysis of variance, used in the numerator in an F-test of the null hypothesis that says that a proposed model fits well. The other component is the pure-error sum of squares.', 'href': '/wiki/Lack-of-fit_sum_of_squares', 'section': 'Regression analysis', 'title': 'Lack-of-fit sum of squares'}\n",
      "{'definition': 'In statistics and in particular in regression analysis, leverage is a measure of how far away the independent variable values of an observation are from those of the other observations.', 'href': '/wiki/Leverage_(statistics)', 'section': 'Regression analysis', 'title': 'Leverage (statistics)'}\n",
      "{'definition': 'A limited dependent variable is a variable whose range of possible values is \"restricted in some important way.\"[1] In econometrics, the term is often used when estimation of the relationship between the limited dependent variable of interest and other variables requires methods that take this restriction into account. For example, this may arise when the variable of interest is constrained to lie between zero and one, as in the case of a probability, or is constrained to be positive, as in the case of wages or hours worked.', 'href': '/wiki/Limited_dependent_variable', 'section': 'Regression analysis', 'title': 'Limited dependent variable'}\n",
      "{'definition': 'In statistics, a linear probability model is a special case of a binomial regression model. Here the dependent variable for each observation takes values which are either 0 or 1. The probability of observing a 0 or 1 in any one case is treated as depending on one or more explanatory variables. For the \"linear probability model\", this relationship is a particularly simple one, and allows the model to be fitted by simple linear regression.', 'href': '/wiki/Linear_probability_model', 'section': 'Regression analysis', 'title': 'Linear probability model'}\n",
      "{'definition': \"In statistics, Mallows's Cp,[1][2] named for Colin Lingwood Mallows, is used to assess the fit of a regression model that has been estimated using ordinary least squares. It is applied in the context of model selection, where a number of predictor variables are available for predicting some outcome, and the goal is to find the best model involving a subset of these predictors. A small value of Cp means that the model is relatively precise.\", 'href': '/wiki/Mallows%27s_Cp', 'section': 'Regression analysis', 'title': \"Mallows's Cp\"}\n",
      "{'definition': 'In linear regression, mean response and predicted response are values of the dependent variable calculated from the regression parameters and a given value of the independent variable. The values of these two responses are the same, but their calculated variances are different.', 'href': '/wiki/Mean_and_predicted_response', 'section': 'Regression analysis', 'title': 'Mean and predicted response'}\n",
      "{'definition': 'A mixed model is a statistical model containing both fixed effects and random effects. These models are useful in a wide variety of disciplines in the physical, biological and social sciences. They are particularly useful in settings where repeated measurements are made on the same statistical units (longitudinal study), or where measurements are made on clusters of related statistical units. Because of their advantage in dealing with missing values, mixed effects models are often preferred over more traditional approaches such as repeated measures ANOVA.', 'href': '/wiki/Mixed_model', 'section': 'Regression analysis', 'title': 'Mixed model'}\n",
      "{'definition': 'In statistics and regression analysis, moderation occurs when the relationship between two variables depends on a third variable. The third variable is referred to as the moderator variable or simply the moderator.[1] The effect of a moderating variable is characterized statistically as an interaction;[1] that is, a categorical (e.g., sex, ethnicity, class) or quantitative (e.g., level of reward) variable that affects the direction and/or strength of the relation between dependent and independent variables. Specifically within a correlational analysis framework, a moderator is a third variable that affects the zero-order correlation between two other variables, or the value of the slope of the dependent variable on the independent variable. In analysis of variance (ANOVA) terms, a basic moderator effect can be represented as an interaction between a focal independent variable and a factor that specifies the appropriate conditions for its operation.[2]', 'href': '/wiki/Moderation_(statistics)', 'section': 'Regression analysis', 'title': 'Moderation (statistics)'}\n",
      "{'definition': 'Moving least squares is a method of reconstructing continuous functions from a set of unorganized point samples via the calculation of a weighted least squares measure biased towards the region around the point at which the reconstructed value is requested.', 'href': '/wiki/Moving_least_squares', 'section': 'Regression analysis', 'title': 'Moving least squares'}\n",
      "{'definition': 'In statistics, multicollinearity (also collinearity) is a phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy. In this situation the coefficient estimates of the multiple regression may change erratically in response to small changes in the model or the data. Multicollinearity does not reduce the predictive power or reliability of the model as a whole, at least within the sample data set; it only affects calculations regarding individual predictors. That is, a multivariate regression model with collinear predictors can indicate how well the entire bundle of predictors predicts the outcome variable, but it may not give valid results about any individual predictor, or about which predictors are redundant with respect to others.', 'href': '/wiki/Multicollinearity', 'section': 'Regression analysis', 'title': 'Multicollinearity'}\n",
      "{'definition': \"In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables. It is the correlation between the variable's values and the best predictions that can be computed linearly from the predictive variables.[1]\", 'href': '/wiki/Multiple_correlation', 'section': 'Regression analysis', 'title': 'Multiple correlation'}\n",
      "{'definition': 'In statistics and econometrics, the multivariate probit model is a generalization of the probit model used to estimate several correlated binary outcomes jointly. For example, if it is believed that the decisions of sending at least one child to public school and that of voting in favor of a school budget are correlated (both decisions are binary), then the multivariate probit model would be appropriate for jointly predicting these two choices on an individual-specific basis.', 'href': '/wiki/Multivariate_probit', 'section': 'Regression analysis', 'title': 'Multivariate probit'}\n",
      "{'definition': 'In statistics, multivariate adaptive regression splines (MARS) is a form of regression analysis introduced by Jerome H. Friedman in 1991.[1] It is a non-parametric regression technique and can be seen as an extension of linear models that automatically models nonlinearities and interactions between variables.', 'href': '/wiki/Multivariate_adaptive_regression_splines', 'section': 'Regression analysis', 'title': 'Multivariate adaptive regression splines'}\n",
      "{'definition': 'A Newey–West estimator is used in statistics and econometrics to provide an estimate of the covariance matrix of the parameters of a regression-type model when this model is applied in situations where the standard assumptions of regression analysis do not apply.[1] It was devised by Whitney K. Newey and Kenneth D. West in 1987, although there are a number of later variants.[2][3][4][5] The estimator is used to try to overcome autocorrelation (also called serial correlation), and heteroskedasticity in the error terms in the models, often for regressions applied to time series data.', 'href': '/wiki/Newey%E2%80%93West_estimator', 'section': 'Regression analysis', 'title': 'Newey–West estimator'}\n",
      "{'definition': 'Non-linear least squares is the form of least squares analysis used to fit a set of m observations with a model that is non-linear in n unknown parameters (m\\xa0>\\xa0n). It is used in some forms of nonlinear regression. The basis of the method is to approximate the model by a linear one and to refine the parameters by successive iterations. There are many similarities to linear least squares, but also some significant differences.', 'href': '/wiki/Non-linear_least_squares', 'section': 'Regression analysis', 'title': 'Non-linear least squares'}\n",
      "{'definition': 'In statistics, nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and depends on one or more independent variables. The data are fitted by a method of successive approximations.', 'href': '/wiki/Nonlinear_regression', 'section': 'Regression analysis', 'title': 'Nonlinear regression'}\n",
      "{'definition': 'The logit (/ˈloʊdʒɪt/ LOH-jit) function is the inverse of the sigmoidal \"logistic\" function or logistic transform used in mathematics, especially in statistics. When the function\\'s variable represents a probability p, the logit function gives the log-odds, or the logarithm of the odds p/(1 − p).[1]', 'href': '/wiki/Logit', 'section': 'Logistic Regression', 'title': 'Logit'}\n",
      "{'definition': 'In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes.[1] That is, it is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables (which may be real-valued, binary-valued, categorical-valued, etc.).', 'href': '/wiki/Multinomial_logit', 'section': 'Logistic Regression', 'title': 'Multinomial logit'}\n",
      "{'definition': 'In statistics, the logistic model (or logit model) is a statistical model that is usually taken to apply to a binary dependent variable. In regression analysis, logistic regression or logit regression is estimating the parameters of a logistic model. More formally, a logistic model is one where the log-odds of the probability of an event is a linear combination of independent or predictor variables. The two possible dependent variable values are often labelled as \"0\" and \"1\", which represent outcomes such as pass/fail, win/lose, alive/dead or healthy/sick. The binary logistic regression model can be generalized to more than two levels of the dependent variable: categorical outputs with more than two values are modelled by multinomial logistic regression, and if the multiple categories are ordered, by ordinal logistic regression, for example the proportional odds ordinal logistic model.[1]', 'href': '/wiki/Logistic_regression', 'section': 'Logistic Regression', 'title': 'Logistic regression'}\n",
      "{'definition': 'Bio-inspired computing, short for biologically inspired computing, is a field of study that loosely knits together subfields related to the topics of connectionism, social behaviour and emergence. It is often closely related to the field of artificial intelligence, as many of its pursuits can be linked to machine learning. It relies heavily on the fields of biology, computer science and mathematics. Briefly put, it is the use of computers to model the living phenomena, and simultaneously the study of life to improve the usage of computers. Biologically inspired computing is a major subset of natural computation.', 'href': '/wiki/Bio-inspired_computing', 'section': 'Bio-inspired Methods', 'title': 'Bio-inspired computing'}\n",
      "{'definition': 'In computer science and mathematical optimization, a metaheuristic is a higher-level procedure or heuristic designed to find, generate, or select a heuristic (partial search algorithm) that may provide a sufficiently good solution to an optimization problem, especially with incomplete or imperfect information or limited computation capacity.[1][2] Metaheuristics sample a set of solutions which is too large to be completely sampled. Metaheuristics may make few assumptions about the optimization problem being solved, and so they may be usable for a variety of problems.[3]', 'href': '/wiki/Metaheuristic', 'section': 'Bio-inspired Methods', 'title': 'Metaheuristic'}\n",
      "{'definition': 'Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial. The concept is employed in work on artificial intelligence. The expression was introduced by Gerardo Beni and Jing Wang in 1989, in the context of cellular robotic systems.[1]', 'href': '/wiki/Swarm_intelligence', 'section': 'Bio-inspired Methods', 'title': 'Swarm intelligence'}\n",
      "{'definition': \"In computer science, particle swarm optimization (PSO) is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. It solves a problem by having a population of candidate solutions, here dubbed particles, and moving these particles around in the search-space according to simple mathematical formulae over the particle's position and velocity. Each particle's movement is influenced by its local best known position, but is also guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. This is expected to move the swarm toward the best solutions.\", 'href': '/wiki/Particle_swarm_optimization', 'section': 'Bio-inspired Methods', 'title': 'Particle swarm optimization'}\n",
      "{'definition': \"In computer science and operations research, the ant colony optimization algorithm (ACO) is a probabilistic technique for solving computational problems which can be reduced to finding good paths through graphs. Artificial Ants stand for multi-agent methods inspired by the behavior of real ants. The pheromone-based communication of biological ants is often the predominant paradigm used.[2] Combinations of Artificial Ants and local search algorithms have become a method of choice for numerous optimization tasks involving some sort of graph, e. g., vehicle routing and internet routing. The burgeoning activity in this field has led to conferences dedicated solely to Artificial Ants, and to numerous commercial applications by specialized companies such as AntOptima. As an example, Ant colony optimization[3] is a class of optimization algorithms modeled on the actions of an ant colony. Artificial 'ants' (e.g. simulation agents) locate optimal solutions by moving through a parameter space representing all possible solutions. Real ants lay down pheromones directing each other to resources while exploring their environment. The simulated 'ants' similarly record their positions and the quality of their solutions, so that in later simulation iterations more ants locate better solutions.[4] One variation on this approach is the bees algorithm, which is more analogous to the foraging patterns of the honey bee, another social insect.\", 'href': '/wiki/Ant_colony_optimization_algorithms', 'section': 'Bio-inspired Methods', 'title': 'Ant colony optimization algorithms'}\n",
      "{'definition': \"In artificial intelligence, artificial immune systems (AIS) are a class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate immune system. The algorithms are typically modeled after the immune system's characteristics of learning and memory for use in problem-solving.\", 'href': '/wiki/Artificial_immune_system', 'section': 'Bio-inspired Methods', 'title': 'Artificial immune system'}\n",
      "{'definition': 'In mathematical optimization, the firefly algorithm is a metaheuristic proposed by Xin-She Yang and inspired by the flashing behaviour of fireflies.[1]', 'href': '/wiki/Firefly_algorithm', 'section': 'Bio-inspired Methods', 'title': 'Firefly algorithm'}\n",
      "{'definition': 'In operations research, cuckoo search is an optimization algorithm developed by Xin-she Yang and Suash Deb in 2009.[1][2] It was inspired by the obligate brood parasitism of some cuckoo species by laying their eggs in the nests of other host birds (of other species). Some host birds can engage direct conflict with the intruding cuckoos. For example, if a host bird discovers the eggs are not their own, it will either throw these alien eggs away or simply abandon its nest and build a new nest elsewhere. Some cuckoo species such as the New World brood-parasitic Tapera have evolved in such a way that female parasitic cuckoos are often very specialized in the mimicry in colors and pattern of the eggs of a few chosen host species [3] Cuckoo search idealized such breeding behavior, and thus can be applied for various optimization problems.', 'href': '/wiki/Cuckoo_search', 'section': 'Bio-inspired Methods', 'title': 'Cuckoo search'}\n",
      "{'definition': 'The Bat algorithm is a metaheuristic algorithm for global optimization. It was inspired by the echolocation behaviour of microbats, with varying pulse rates of emission and loudness.[1][2] The Bat algorithm was developed by Xin-She Yang in 2010.[3]', 'href': '/wiki/Bat_algorithm', 'section': 'Bio-inspired Methods', 'title': 'Bat algorithm'}\n",
      "{'definition': 'The term evolvability is used for a recent framework of computational learning introduced by Leslie Valiant in his paper of the same name and described below. The aim of this theory is to model biological evolution and categorize which types of mechanisms are evolvable. Evolution is an extension of PAC learning and learning from statistical queries.', 'href': '/wiki/Evolvability_(computer_science)', 'section': 'Evolutionary Algorithms', 'title': 'Evolvability (computer science)'}\n",
      "{'definition': 'In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial and error problem solvers with a metaheuristic or stochastic optimization character.', 'href': '/wiki/Evolutionary_computation', 'section': 'Evolutionary Algorithms', 'title': 'Evolutionary computation'}\n",
      "{'definition': 'In artificial intelligence, an evolutionary algorithm (EA) is a subset of evolutionary computation[1], a generic population-based metaheuristic optimization algorithm. An EA uses mechanisms inspired by biological evolution, such as reproduction, mutation, recombination, and selection. Candidate solutions to the optimization problem play the role of individuals in a population, and the fitness function determines the quality of the solutions (see also loss function). Evolution of the population then takes place after the repeated application of the above operators.', 'href': '/wiki/Evolutionary_algorithm', 'section': 'Evolutionary Algorithms', 'title': 'Evolutionary algorithm'}\n",
      "{'definition': 'In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired operators such as mutation, crossover and selection.[1]', 'href': '/wiki/Genetic_algorithm', 'section': 'Evolutionary Algorithms', 'title': 'Genetic algorithm'}\n",
      "{'definition': 'In genetic algorithms, a chromosome (also sometimes called a genotype) is a set of parameters which define a proposed solution to the problem that the genetic algorithm is trying to solve. The set of all solutions is known as the population.[1] The chromosome is often represented as a binary string, although a wide variety of other data structures are also used.', 'href': '/wiki/Chromosome_(genetic_algorithm)', 'section': 'Evolutionary Algorithms', 'title': 'Chromosome (genetic algorithm)'}\n",
      "{'definition': 'In genetic algorithms and evolutionary computation, crossover, also called recombination, is a genetic operator used to combine the genetic information of two parents to generate new offspring. It is one way to stochastically generate new solutions from an existing population, and analogous to the crossover that happens during sexual reproduction in biology. Solutions can also be generated by cloning an existing solution, which is analogous to asexual reproduction. Newly generated solutions are typically mutated before being added to the population.', 'href': '/wiki/Crossover_(genetic_algorithm)', 'section': 'Evolutionary Algorithms', 'title': 'Crossover (genetic algorithm)'}\n",
      "{'definition': 'A fitness function is a particular type of objective function that is used to summarise, as a single figure of merit, how close a given design solution is to achieving the set aims. Fitness functions are used in genetic programming and genetic algorithms to guide simulations towards optimal design solutions.', 'href': '/wiki/Fitness_function', 'section': 'Evolutionary Algorithms', 'title': 'Fitness function'}\n",
      "{'definition': 'Evolutionary data mining, or genetic data mining is an umbrella term for any data mining using evolutionary algorithms. While it can be used for mining data from DNA sequences,[1] it is not limited to biological contexts and can be used in any classification-based prediction scenario, which helps \"predict the value ... of a user-specified goal attribute based on the values of other attributes.\"[2] For instance, a banking institution might want to predict whether a customer\\'s credit would be \"good\" or \"bad\" based on their age, income and current savings.[2] Evolutionary algorithms for data mining work by creating a series of random rules to be checked against a training dataset.[3] The rules which most closely fit the data are selected and are mutated.[3] The process is iterated many times and eventually, a rule will arise that approaches 100% similarity with the training data.[2] This rule is then checked against a test dataset, which was previously invisible to the genetic algorithm.[2]', 'href': '/wiki/Evolutionary_data_mining', 'section': 'Evolutionary Algorithms', 'title': 'Evolutionary data mining'}\n",
      "{'definition': 'In artificial intelligence, genetic programming (GP) is a technique whereby computer programs are encoded as a set of genes that are then modified (evolved) using an evolutionary algorithm (often a genetic algorithm, \"GA\") – it is an application of (for example) genetic algorithms where the space of solutions consists of computer programs. The results are computer programs able to perform well in a predefined task. The methods used to encode a computer program in an artificial chromosome and to evaluate its fitness with respect to the predefined task are central in the GP technique and still the subject of active research.', 'href': '/wiki/Genetic_programming', 'section': 'Evolutionary Algorithms', 'title': 'Genetic programming'}\n",
      "{'definition': 'The learnable evolution model (LEM) is a novel, non-Darwinian methodology for evolutionary computation that employs machine learning to guide the generation of new individuals (candidate problem solutions). Unlike standard, Darwinian-type evolutionary computation methods that use random or semi-random operators for generating new individuals (such as mutations and/or recombinations), LEM employs hypothesis generation and instantiation operators.', 'href': '/wiki/Learnable_Evolution_Model', 'section': 'Evolutionary Algorithms', 'title': 'Learnable Evolution Model'}\n",
      "{'definition': 'Stochastic diffusion search (SDS) was first described in 1989 as a population-based, pattern-matching algorithm [Bishop, 1989]. It belongs to a family of swarm intelligence and naturally inspired search and optimisation algorithms which includes ant colony optimization, particle swarm optimization and genetic algorithms; as such SDS was the first Swarm Intelligence metaheuristic. Unlike stigmergetic communication employed in ant colony optimization, which is based on modification of the physical properties of a simulated environment, SDS uses a form of direct (one-to-one) communication between the agents similar to the tandem calling mechanism employed by one species of ants, Leptothorax acervorum.', 'href': '/wiki/Stochastic_diffusion_search', 'section': 'Evolutionary Algorithms', 'title': 'Stochastic diffusion search'}\n",
      "{'definition': 'The term neural network was traditionally used to refer to a network or circuit of neurons.[1] The modern usage of the term often refers to artificial neural networks, which are composed of artificial neurons or nodes. Thus the term may refer to either biological neural networks, made up of real biological neurons, or artificial neural networks, for solving artificial intelligence problems.The connections of the biological neuron are modeled as weights. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed altogether. This activity is referred as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be -1 and 1.', 'href': '/wiki/Neural_network', 'section': 'Neural Networks', 'title': 'Neural network'}\n",
      "{'definition': 'Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains.[1] Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any a priori knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the learning material that they process.', 'href': '/wiki/Artificial_neural_network', 'section': 'Neural Networks', 'title': 'Artificial neural network'}\n",
      "{'definition': \"An artificial neuron is a mathematical function conceived as a model of biological neurons, a neural network. Artificial neurons are elementary units in an artificial neural network. The artificial neuron receives one or more inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or activation, representing a neuron's action potential which is transmitted along its axon). Usually each input is separately weighted, and the sum is passed through a non-linear function known as an activation function or transfer function[clarification needed]. The transfer functions usually have a sigmoid shape, but they may also take the form of other non-linear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable and bounded. The thresholding function has inspired building logic gates referred to as threshold logic; applicable to building logic circuits resembling brain processing. For example, new devices such as memristors have been extensively used to develop such logic in recent times.[1]\", 'href': '/wiki/Artificial_neuron', 'section': 'Neural Networks', 'title': 'Artificial neuron'}\n",
      "{'definition': 'There are many types of artificial neural networks (ANN).', 'href': '/wiki/Types_of_artificial_neural_networks', 'section': 'Neural Networks', 'title': 'Types of artificial neural networks'}\n",
      "{'definition': 'In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not).[1] It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.', 'href': '/wiki/Perceptron', 'section': 'Neural Networks', 'title': 'Perceptron'}\n",
      "{'definition': 'A multilayer perceptron (MLP) is a class of feedforward artificial neural network. An MLP consists of at least three layers of nodes. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training.[1][2] Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable.[3]', 'href': '/wiki/Multilayer_perceptron', 'section': 'Neural Networks', 'title': 'Multilayer perceptron'}\n",
      "{'definition': 'In computational networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input. This is similar to the behavior of the linear perceptron in neural networks. However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes. In artificial neural networks this function is also called the transfer function.', 'href': '/wiki/Activation_function', 'section': 'Neural Networks', 'title': 'Activation function'}\n",
      "{'definition': 'A self-organizing map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map, and is therefore a method to do dimensionality reduction. Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning (such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.', 'href': '/wiki/Self-organizing_map', 'section': 'Neural Networks', 'title': 'Self-organizing map'}\n",
      "{'definition': 'An attractor network is a type of recurrent dynamical network, that evolves toward a stable pattern over time. Nodes in the attractor network converge toward a pattern that may either be fixed-point (a single state), cyclic (with regularly recurring states), chaotic (locally but not globally unstable) or random (stochastic).[1] Attractor networks have largely been used in computational neuroscience to model neuronal processes such as associative memory[2] and motor behavior, as well as in biologically inspired methods of machine learning. An attractor network contains a set of n nodes, which can be represented as vectors in a d-dimensional space where n>d. Over time, the network state tends toward one of a set of predefined states on a d-manifold; these are the attractors.', 'href': '/wiki/Attractor_network', 'section': 'Neural Networks', 'title': 'Attractor network'}\n",
      "{'definition': 'ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network.[1][2][3][4][5] The network uses memistors. It was developed by Professor Bernard Widrow and his graduate student Ted Hoff at Stanford University in 1960. It is based on the McCulloch–Pitts neuron. It consists of a weight, a bias and a summation function.', 'href': '/wiki/ADALINE', 'section': 'Neural Networks', 'title': 'ADALINE'}\n",
      "{'definition': 'An adaptive neuro-fuzzy inference system or adaptive network-based fuzzy inference system (ANFIS) is a kind of artificial neural network that is based on Takagi–Sugeno fuzzy inference system. The technique was developed in the early 1990s.[1][2] Since it integrates both neural networks and fuzzy logic principles, it has potential to capture the benefits of both in a single framework. Its inference system corresponds to a set of fuzzy IF–THEN rules that have learning capability to approximate nonlinear functions.[3] Hence, ANFIS is considered to be a universal estimator.[4] For using the ANFIS in a more efficient and optimal way, one can use the best parameters obtained by genetic algorithm.[5][6]', 'href': '/wiki/Adaptive_Neuro_Fuzzy_Inference_System', 'section': 'Neural Networks', 'title': 'Adaptive Neuro Fuzzy Inference System'}\n",
      "{'definition': 'Adaptive resonance theory (ART) is a theory developed by Stephen Grossberg and Gail Carpenter on aspects of how the brain processes information. It describes a number of neural network models which use supervised and unsupervised learning methods, and address problems such as pattern recognition and prediction.', 'href': '/wiki/Adaptive_resonance_theory', 'section': 'Neural Networks', 'title': 'Adaptive resonance theory'}\n",
      "{'definition': 'IPO underpricing is the increase in stock value from the initial offering price to the first-day closing price. Many believe that underpriced IPOs leave money on the table for corporations, but some believe that underpricing is inevitable. Investors state that underpricing signals high interest to the market which increases the demand. On the other hand, overpriced stocks will drop long-term as the price stabilizes so underpricing may keep the issuers safe from investor litigation.', 'href': '/wiki/IPO_underpricing_algorithm', 'section': 'Neural Networks', 'title': 'IPO underpricing algorithm'}\n",
      "{'definition': 'ALOPEX (an acronym from \"ALgorithms Of Pattern EXtraction\") is a correlation based machine learning algorithm first proposed by Tzanakou and Harth in 1974.', 'href': '/wiki/ALOPEX', 'section': 'Neural Networks', 'title': 'ALOPEX'}\n",
      "{'definition': 'Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence. They claimed to have found, in research, the \"mechanisms of knowledge representation in the brain which is equivalent to finding artificial intelligence\",[1] before moving into the developmental phase.', 'href': '/wiki/Artificial_Intelligence_System', 'section': 'Neural Networks', 'title': 'Artificial Intelligence System'}\n",
      "{'definition': 'Autoassociative memory, also known as auto-association memory or an autoassociation network, is any type of memory that enables one to retrieve a piece of data from only a tiny sample of itself. It is often misunderstood to be only a form of backpropagation or other neural networks.[citation needed]', 'href': '/wiki/Autoassociative_memory', 'section': 'Neural Networks', 'title': 'Autoassociative memory'}\n",
      "{'definition': 'An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner.[1][2] The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction. Recently, the autoencoder concept has become more widely used for learning generative models of data.[3][4] Some of the most powerful AI in the 2010s has involved sparse autoencoders stacked inside of deep neural networks.[5]', 'href': '/wiki/Autoencoder', 'section': 'Neural Networks', 'title': 'Autoencoder'}\n",
      "{'definition': 'Backpropagation is a method used in artificial neural networks to calculate a gradient that is needed in the calculation of the weights to be used in the network.[1] It is commonly used to train deep neural networks,[2] a term referring to neural networks with more than one hidden layer.[3]', 'href': '/wiki/Backpropagation', 'section': 'Neural Networks', 'title': 'Backpropagation'}\n",
      "{'definition': 'A Bayesian Confidence Neural Network (BCPNN) is an artificial neural network inspired by Bayes\\' theorem: node activations represent probability (\"confidence\") in the presence of input features or categories, synaptic weights are based on estimated correlations and the spread of activation corresponds to calculating posteriori probabilities. It was originally proposed by Anders Lansner and Örjan Ekeberg at KTH.[1]', 'href': '/wiki/Bcpnn', 'section': 'Neural Networks', 'title': 'Bcpnn'}\n",
      "{'definition': 'Bidirectional associative memory (BAM) is a type of recurrent neural network. BAM was introduced by Bart Kosko in 1988.[1] There are two types of associative memory, auto-associative and hetero-associative. BAM is hetero-associative, meaning given a pattern it can return another pattern which is potentially of a different size. It is similar to the Hopfield network in that they are both forms of associative memory. However, Hopfield nets return patterns of the same size.', 'href': '/wiki/Bidirectional_associative_memory', 'section': 'Neural Networks', 'title': 'Bidirectional associative memory'}\n",
      "{'definition': 'In neuroscience, a biological neural network is a population of neurons that are interconnected by synapses so that the group of cells can carry out a specific function when activated. Biological neural networks have inspired the design of artificial neural networks.', 'href': '/wiki/Biological_neural_network', 'section': 'Neural Networks', 'title': 'Biological neural network'}\n",
      "{'definition': 'A Boltzmann machine (also called stochastic Hopfield network with hidden units) is a type of stochastic recurrent neural network (and Markov random field[citation needed]).', 'href': '/wiki/Boltzmann_machine', 'section': 'Neural Networks', 'title': 'Boltzmann machine'}\n",
      "{'definition': 'A restricted Boltzmann machine (RBM) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs.', 'href': '/wiki/Restricted_Boltzmann_machine', 'section': 'Neural Networks', 'title': 'Restricted Boltzmann machine'}\n",
      "{'definition': 'In computer science and machine learning, cellular neural networks (CNN) (or cellular nonlinear networks (CNN)) are a parallel computing paradigm similar to neural networks, with the difference that communication is allowed between neighbouring units only. Typical applications include image processing, analyzing 3D surfaces, solving partial differential equations, reducing non-visual problems to geometric maps, modelling biological vision and other sensory-motor organs.', 'href': '/wiki/Cellular_neural_network', 'section': 'Neural Networks', 'title': 'Cellular neural network'}\n",
      "{'definition': 'The cerebellar model arithmetic computer (CMAC) is a type of neural network based on a model of the mammalian cerebellum. It is also known as the cerebellar model articulation controller. It is a type of associative memory.[2]', 'href': '/wiki/Cerebellar_Model_Articulation_Controller', 'section': 'Neural Networks', 'title': 'Cerebellar Model Articulation Controller'}\n",
      "{'definition': 'A committee machine is a type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts) are combined into a single response.[1] The combined response of the committee machine is supposed to be superior to those of its constituent experts. Compare with ensembles of classifiers.', 'href': '/wiki/Committee_machine', 'section': 'Neural Networks', 'title': 'Committee machine'}\n",
      "{'definition': 'Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data.[1] A variant of Hebbian learning, competitive learning works by increasing the specialization of each node in the network. It is well suited to finding clusters within data.', 'href': '/wiki/Competitive_learning', 'section': 'Neural Networks', 'title': 'Competitive learning'}\n",
      "{'definition': 'Compositional pattern-producing networks (CPPNs) are a variation of artificial neural networks (ANNs) that have an architecture whose evolution is guided by genetic algorithms.[1]', 'href': '/wiki/Compositional_pattern-producing_network', 'section': 'Neural Networks', 'title': 'Compositional pattern-producing network'}\n",
      "{'definition': 'Computational cybernetics is the integration of cybernetics and computational intelligence techniques. Though the term Cybernetics entered the technical lexicon in the 1940s and 1950s, it was first used informally as a popular noun in the 1960s, when it became associated with computers, robotics, Artificial Intelligence and Science fiction.', 'href': '/wiki/Computational_cybernetics', 'section': 'Neural Networks', 'title': 'Computational cybernetics'}\n",
      "{'definition': 'Computational neurogenetic modeling (CNGM) is concerned with the study and development of dynamic neuronal models for modeling brain functions with respect to genes and dynamic interactions between genes. These include neural network models and their integration with gene network models. This area brings together knowledge from various scientific disciplines, such as computer and information science, neuroscience and cognitive science, genetics and molecular biology, as well as engineering.', 'href': '/wiki/Computational_neurogenetic_modeling', 'section': 'Neural Networks', 'title': 'Computational neurogenetic modeling'}\n",
      "{'definition': 'A confabulation, also known as a false, degraded, or corrupted memory, is a stable pattern of activation in an artificial neural network or neural assembly that does not correspond to any previously learned patterns. The same term is also applied to the (nonartificial) neural mistake-making process leading to a false memory (confabulation).', 'href': '/wiki/Confabulation_(neural_networks)', 'section': 'Neural Networks', 'title': 'Confabulation (neural networks)'}\n",
      "{'definition': 'A cortical column, also called hypercolumn, macrocolumn,[1] functional column[2] or sometimes cortical module,[3] is a group of neurons in the cortex of the brain that can be successively penetrated by a probe inserted perpendicularly to the cortical surface, and which have nearly identical receptive fields.[citation needed] Neurons within a minicolumn (microcolumn) encode similar features, whereas a hypercolumn \"denotes a unit containing a full set of values for any given set of receptive field parameters\".[4] A cortical module is defined as either synonymous with a hypercolumn (Mountcastle) or as a tissue block of multiple overlapping hypercolumns.[5]', 'href': '/wiki/Cortical_column', 'section': 'Neural Networks', 'title': 'Cortical column'}\n",
      "{'definition': None, 'href': '/w/index.php?title=Counterpropagation_network&action=edit&redlink=1', 'section': 'Neural Networks', 'title': 'Counterpropagation network (page does not exist)'}\n",
      "{'definition': \"Cover's Theorem is a statement in computational learning theory and is one of the primary theoretical motivations for the use of non-linear kernel methods in machine learning applications. The theorem states that given a set of training data that is not linearly separable, one can with high probability transform it into a training set that is linearly separable by projecting it into a higher-dimensional space via some non-linear transformation. The theorem is named after the information theorist Thomas M. Cover who stated it in 1965.\", 'href': '/wiki/Cover%27s_theorem', 'section': 'Neural Networks', 'title': \"Cover's theorem\"}\n",
      "{'definition': 'A cultured neuronal network is a cell culture of neurons that is used as a model to study the central nervous system, especially the brain. Often, cultured neuronal networks are connected to an input/output device such as a multi-electrode array (MEA), thus allowing two-way communication between the researcher and the network. This model has proved to be an invaluable tool to scientists studying the underlying principles behind neuronal learning, memory, plasticity, connectivity, and information processing.[1]', 'href': '/wiki/Cultured_neuronal_network', 'section': 'Neural Networks', 'title': 'Cultured neuronal network'}\n",
      "{'definition': 'The Dehaene–Changeux model (DCM), also known as the global neuronal workspace or the global cognitive workspace model is a part of Bernard Baars\\'s \"global workspace model\" for consciousness.', 'href': '/wiki/Dehaene-Changeux_Model', 'section': 'Neural Networks', 'title': 'Dehaene-Changeux Model'}\n",
      "{'definition': \"In machine learning, the Delta rule is a gradient descent learning rule for updating the weights of the inputs to artificial neurons in a single-layer neural network.[1] It is a special case of the more general backpropagation algorithm. For a neuron \\n\\n\\n\\nj\\n\\n\\n{\\\\displaystyle j}\\n\\n with activation function \\n\\n\\n\\ng\\n(\\nx\\n)\\n\\n\\n{\\\\displaystyle g(x)}\\n\\n, the delta rule for \\n\\n\\n\\nj\\n\\n\\n{\\\\displaystyle j}\\n\\n's \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\nth weight \\n\\n\\n\\n\\nw\\n\\nj\\ni\\n\\n\\n\\n\\n{\\\\displaystyle w_{ji}}\\n\\n is given by\", 'href': '/wiki/Delta_rule', 'section': 'Neural Networks', 'title': 'Delta rule'}\n",
      "{'definition': \"In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased generalization error. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation.\", 'href': '/wiki/Early_stopping', 'section': 'Neural Networks', 'title': 'Early stopping'}\n",
      "{'definition': 'The echo state network (ESN),[1][2] is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned. The weights of output neurons can be learned so that the network can (re)produce specific temporal patterns. The main interest of this network is that although its behaviour is non-linear, the only weights that are modified during training are for the synapses that connect the hidden neurons to output neurons. Thus, the error function is quadratic with respect to the parameter vector and can be differentiated easily to a linear system.', 'href': '/wiki/Echo_state_network', 'section': 'Neural Networks', 'title': 'Echo state network'}\n",
      "{'definition': \"The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind [1] is a 2006 book by cognitive scientist Marvin Minsky that elaborates and expands on Minsky's ideas as presented in his earlier book Society of Mind.\", 'href': '/wiki/The_Emotion_Machine', 'section': 'Neural Networks', 'title': 'The Emotion Machine'}\n",
      "{'definition': 'Evolutionary acquisition of neural topologies (EANT/EANT2) is an evolutionary reinforcement learning method that evolves both the topology and weights of artificial neural networks. It is closely related to the works of Angeline et al.[1] and Stanley and Miikkulainen.[2] Like the work of Angeline et al., the method uses a type of parametric mutation that comes from evolution strategies and evolutionary programming (now using the most advanced form of the evolution strategies CMA-ES in EANT2), in which adaptive step sizes are used for optimizing the weights of the neural networks. Similar to the work of Stanley (NEAT), the method starts with minimal structures which gain complexity along the evolution path.', 'href': '/wiki/Evolutionary_Acquisition_of_Neural_Topologies', 'section': 'Neural Networks', 'title': 'Evolutionary Acquisition of Neural Topologies'}\n",
      "{'definition': 'Extension neural network is a pattern recognition method found by M. H. Wang and C. P. Hung in 2003 to classify instances of data sets. Extension neural network is composed of artificial neural network and extension theory concepts. It uses the fast and adaptive learning capability of neural network and correlation estimation property of extension theory by calculating extension distance.\\nENN was used in:', 'href': '/wiki/Extension_neural_network', 'section': 'Neural Networks', 'title': 'Extension neural network'}\n",
      "{'definition': 'Feed-forward, sometimes written feedforward, is a term describing an element or pathway within a control system that passes a controlling signal from a source in its external environment, often a command signal from an external operator, to a load elsewhere in its external environment. A control system which has only feed-forward behavior responds to its control signal in a pre-defined way without responding to how the load reacts; it is in contrast with a system that also has feedback, which adjusts the output to take account of how it affects the load, and how the load itself may vary unpredictably; the load is considered to belong to the external environment of the system.', 'href': '/wiki/Feed_forward_(control)', 'section': 'Neural Networks', 'title': 'Feed forward (control)'}\n",
      "{'definition': 'A feedforward neural network is an artificial neural network wherein connections between the nodes do not form a cycle.[1] As such, it is different from recurrent neural networks.', 'href': '/wiki/Feedforward_neural_network', 'section': 'Neural Networks', 'title': 'Feedforward neural network'}\n",
      "{'definition': \"The Generalized Hebbian Algorithm (GHA), also known in the literature as Sanger's rule, is a linear feedforward neural network model for unsupervised learning with applications primarily in principal components analysis. First defined in 1989,[1] it is similar to Oja's rule in its formulation and stability, except it can be applied to networks with multiple outputs. The name originates because of the similarity between the algorithm and a hypothesis made by Donald Hebb[2] about the way in which synaptic strengths in the brain are modified in response to experience, i.e., that changes are proportional to the correlation between the firing of pre- and post-synaptic neurons.[3]\", 'href': '/wiki/Generalized_Hebbian_Algorithm', 'section': 'Neural Networks', 'title': 'Generalized Hebbian Algorithm'}\n",
      "{'definition': 'Generative topographic map (GTM) is a machine learning method that is a probabilistic counterpart of the self-organizing map (SOM), is probably convergent and does not require a shrinking neighborhood or a decreasing step size. It is a generative model: the data is assumed to arise by first probabilistically picking a point in a low-dimensional space, mapping the point to the observed high-dimensional input space (via a smooth function), then adding noise in that space. The parameters of the low-dimensional probability distribution, the smooth map and the noise are all learned from the training data using the expectation-maximization (EM) algorithm. GTM was introduced in 1996 in a paper by Christopher Bishop, Markus Svensen, and Christopher K. I. Williams.', 'href': '/wiki/Generative_topographic_map', 'section': 'Neural Networks', 'title': 'Generative topographic map'}\n",
      "{'definition': 'Group method of data handling (GMDH) is a family of inductive algorithms for computer-based mathematical modeling of multi-parametric datasets that features fully automatic structural and parametric optimization of models.', 'href': '/wiki/Group_method_of_data_handling', 'section': 'Neural Networks', 'title': 'Group method of data handling'}\n",
      "{'definition': 'A growing self-organizing map (GSOM) is a growing variant of a self-organizing map (SOM). The GSOM was developed to address the issue of identifying a suitable map size in the SOM. It starts with a minimal number of nodes (usually 4) and grows new nodes on the boundary based on a heuristic. By using the value called Spread Factor (SF), the data analyst has the ability to control the growth of the GSOM.', 'href': '/wiki/Growing_self-organizing_map', 'section': 'Neural Networks', 'title': 'Growing self-organizing map'}\n",
      "{'definition': 'The memory-prediction framework is a theory of brain function created by Jeff Hawkins and described in his 2004 book On Intelligence. This theory concerns the role of the mammalian neocortex and its associations with the hippocampi and the thalamus in matching sensory inputs to stored memory patterns and how this process leads to predictions of what will happen in the future.', 'href': '/wiki/Memory-prediction_framework', 'section': 'Neural Networks', 'title': 'Memory-prediction framework'}\n",
      "{'definition': 'The Helmholtz machine is a type of artificial neural network that can account for the hidden structure of a set of data by being trained to create a generative model of the original set of data. The hope is that by learning economical representations of the data, the underlying structure of the generative model should reasonably approximate the hidden structure of the data set. A Helmholtz machine contains two networks, a bottom-up recognition network that takes the data as input and produces a distribution over hidden variables, and a top-down \"generative\" network that generates values of the hidden variables and the data itself.', 'href': '/wiki/Helmholtz_machine', 'section': 'Neural Networks', 'title': 'Helmholtz machine'}\n",
      "{'definition': 'Hierarchical temporal memory (HTM) is a biologically constrained theory of machine intelligence originally described in the 2004 book On Intelligence[1] by Jeff Hawkins with Sandra Blakeslee. HTM is based on neuroscience and the physiology and interaction of pyramidal neurons in the neocortex of the human brain. The technology has been tested and implemented in software through example applications from Numenta and commercial applications from Numenta’s partners.', 'href': '/wiki/Hierarchical_temporal_memory', 'section': 'Neural Networks', 'title': 'Hierarchical temporal memory'}\n",
      "{'definition': 'A Hopfield network is a form of recurrent artificial neural network popularized by John Hopfield in 1982, but described earlier by Little in 1974.[1][2] Hopfield nets serve as content-addressable (\"associative\") memory systems with binary threshold nodes. They are guaranteed to converge to a local minimum, but will sometimes converge to a false pattern (wrong local minimum) rather than the stored pattern (expected local minimum). Hopfield networks also provide a model for understanding human memory.', 'href': '/wiki/Hopfield_network', 'section': 'Neural Networks', 'title': 'Hopfield network'}\n",
      "{'definition': 'The term hybrid neural network can have two meanings:', 'href': '/wiki/Hybrid_neural_network', 'section': 'Neural Networks', 'title': 'Hybrid neural network'}\n",
      "{'definition': 'Hypercube-based NEAT, or HyperNEAT,[1] is a generative encoding that evolves artificial neural networks (ANNs) with the principles of the widely used NeuroEvolution of Augmented Topologies (NEAT) algorithm.[2] It is a novel technique for evolving large-scale neural networks using the geometric regularities of the task domain. It uses Compositional Pattern Producing Networks [3] (CPPNs), which are used to generate the images for Picbreeder.org and shapes for EndlessForms.com. HyperNEAT has recently been extended to also evolve plastic ANNs [4] and to evolve the location of every neuron in the network.[5]', 'href': '/wiki/HyperNEAT', 'section': 'Neural Networks', 'title': 'HyperNEAT'}\n",
      "{'definition': 'Infomax is an optimization principle for artificial neural networks and other information processing systems. It prescribes that a function that maps a set of input values I to a set of output values O should be chosen or learned so as to maximize the average Shannon mutual information between I and O, subject to a set of specified constraints and/or noise processes. Infomax algorithms are learning algorithms that perform this optimization process. The principle was described by Linsker in 1988.[1]', 'href': '/wiki/Infomax', 'section': 'Neural Networks', 'title': 'Infomax'}\n",
      "{'definition': 'Instantaneously trained neural networks are feedforward artificial neural networks proposed by Subhash Kak that create a new hidden neuron node for each novel training sample. The weights to this hidden neuron separate out not only this training sample but others that are near it, thus providing generalization.[1][2] This separation is done using the nearest hyperplane that can be written down instantaneously. In the two most important implementations the neighborhood of generalization either varies with the training sample (CC1 network) or remains constant (CC4 network) These networks use unary coding for an effective representation of the data sets.[3]', 'href': '/wiki/Instantaneously_trained_neural_networks', 'section': 'Neural Networks', 'title': 'Instantaneously trained neural networks'}\n",
      "{'definition': 'Interactive activation and competition (IAC) networks are artificial neural networks used to model memory and intuitive generalizations. They are made up of nodes or artificial neurons which are arrayed and activated in ways that emulate the behaviors of human memory.', 'href': '/wiki/Interactive_Activation_and_Competition', 'section': 'Neural Networks', 'title': 'Interactive Activation and Competition'}\n",
      "{'definition': 'Leabra stands for local, error-driven and associative, biologically realistic algorithm. It is a model of learning which is a balance between Hebbian and error-driven learning with other network-derived characteristics. This model is used to mathematically predict outcomes based on inputs and previous learning influences. This model is heavily influenced by and contributes to neural network designs and models. This algorithm is the default algorithm in emergent (successor of PDP++) when making a new project, and is extensively used in various simulations.', 'href': '/wiki/Leabra', 'section': 'Neural Networks', 'title': 'Leabra'}\n",
      "{'definition': 'In computer science, learning vector quantization (LVQ), is a prototype-based supervised classification algorithm. LVQ is the supervised counterpart of vector quantization systems.', 'href': '/wiki/Learning_Vector_Quantization', 'section': 'Neural Networks', 'title': 'Learning Vector Quantization'}\n",
      "{'definition': 'Lernmatrix, an associative-memory-like architecture of an artificial neural network, invented around 1960 by Karl Steinbuch.', 'href': '/wiki/Lernmatrix', 'section': 'Neural Networks', 'title': 'Lernmatrix'}\n",
      "{'definition': 'The Linde–Buzo–Gray algorithm (introduced by Yoseph Linde, Andrés Buzo and Robert M. Gray in 1980) is a vector quantization algorithm to derive a good codebook.', 'href': '/wiki/Linde%E2%80%93Buzo%E2%80%93Gray_algorithm', 'section': 'Neural Networks', 'title': 'Linde–Buzo–Gray algorithm'}\n",
      "{'definition': 'A liquid state machine (LSM) is a particular kind of spiking neural network. An LSM consists of a large collection of units (called nodes, or neurons). Each node receives time varying input from external sources (the inputs) as well as from other nodes. Nodes are randomly connected to each other. The recurrent nature of the connections turns the time varying input into a spatio-temporal pattern of activations in the network nodes. The spatio-temporal patterns of activation are read out by linear discriminant units.', 'href': '/wiki/Liquid_state_machine', 'section': 'Neural Networks', 'title': 'Liquid state machine'}\n",
      "{'definition': 'Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A RNN composed of LSTM units is often called an LSTM network. A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for \"remembering\" values over arbitrary time intervals; hence the word \"memory\" in LSTM. Each of the three gates can be thought of as a \"conventional\" artificial neuron, as in a multi-layer (or feedforward) neural network: that is, they compute an activation (using an activation function) of a weighted sum. Intuitively, they can be thought as regulators of the flow of values that goes through the connections of the LSTM; hence the denotation \"gate\". There are connections between these gates and the cell.', 'href': '/wiki/Long_short-term_memory', 'section': 'Neural Networks', 'title': 'Long short-term memory'}\n",
      "{'definition': 'Madaline may refer to:', 'href': '/wiki/Madaline', 'section': 'Neural Networks', 'title': 'Madaline'}\n",
      "{'definition': \"A modular neural network is an artificial neural network characterized by a series of independent neural networks moderated by some intermediary. Each independent neural network serves as a module and operates on separate inputs to accomplish some subtask of the task the network hopes to perform.[1] The intermediary takes the outputs of each module and processes them to produce the output of the network as a whole. The intermediary only accepts the modules' outputs—it does not respond to, nor otherwise signal, the modules. As well, the modules do not interact with each other.\", 'href': '/wiki/Modular_neural_networks', 'section': 'Neural Networks', 'title': 'Modular neural networks'}\n",
      "{'definition': 'MoneyBee was a distributed computing project in the fields of economics, finance and stock markets, that generated stock forecasts by application of artificial intelligence with the aid of artificial neural networks. MoneyBee acted as a screensaver. The project was run by i42 Informationsmanagement GmbH, a consulting private company from Mannheim, Germany. The project was suspended with a standing invitation for any interested in joining the MoneyBee2 project, but MoneyBee2 seems to have been abandoned in early 2010.', 'href': '/wiki/MoneyBee', 'section': 'Neural Networks', 'title': 'MoneyBee'}\n",
      "{'definition': 'The neocognitron is a hierarchical, multilayered artificial neural network proposed by Kunihiko Fukushima in the 1980s. It has been used for handwritten character recognition and other pattern recognition tasks, and served as the inspiration for convolutional neural networks.[1]', 'href': '/wiki/Neocognitron', 'section': 'Neural Networks', 'title': 'Neocognitron'}\n",
      "{'definition': 'Network of human nervous system comprises nodes (for example, neurons) that are connected by links (for example, synapses). The connectivity may be viewed anatomically, functionally, or electrophysiologically. These are presented in several Wikipedia articles that include Connectionism (a.k.a. Parallel Distributed Processing (PDP)), Biological neural network, Artificial neural network (a.k.a. Neural network), Computational neuroscience, as well as in several books by Ascoli, G. A. (2002),[1] Sterratt, D., Graham, B., Gillies, A., & Willshaw, D. (2011),[2] Gerstner, W., & Kistler, W. (2002),[3] and Rumelhart, J. L., McClelland, J. L., and PDP Research Group (1986)[4] among others. The focus of this article is a comprehensive view of modeling a neural network (technically neuronal network based on neuron model). Once an approach based on the perspective and connectivity is chosen, the models are developed at microscopic (ion and neuron), mesoscopic (functional or population), or macroscopic (system) levels. Computational modeling refers to models that are developed using computing tools.', 'href': '/wiki/Nervous_system_network_models', 'section': 'Neural Networks', 'title': 'Nervous system network models'}\n",
      "{'definition': 'NETtalk is an artificial neural network. It is the result of research carried out in the mid-1980s by Terrence Sejnowski and Charles Rosenberg. The intent behind NETtalk was to construct simplified models that might shed light on the complexity of learning human level cognitive tasks, and their implementation as a connectionist model that could also learn to perform a comparable task.', 'href': '/wiki/NETtalk_(artificial_neural_network)', 'section': 'Neural Networks', 'title': 'NETtalk (artificial neural network)'}\n",
      "{'definition': 'Neural backpropagation is the phenomenon in which the action potential of a neuron creates a voltage spike both at the end of the axon (normal propagation) and back through to the dendritic arbor or dendrites, from which much of the original input current originated. In addition to active backpropagation of the action potential, there is also passive electrotonic spread. While there is ample evidence to prove the existence of backpropagating action potentials, the function of such action potentials and the extent to which they invade the most distal dendrites remains highly controversial.', 'href': '/wiki/Neural_backpropagation', 'section': 'Neural Networks', 'title': 'Neural backpropagation'}\n",
      "{'definition': 'Neural coding is a neuroscience field concerned with characterising the relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble.[1] Based on the theory that sensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information.[2]', 'href': '/wiki/Neural_coding', 'section': 'Neural Networks', 'title': 'Neural coding'}\n",
      "{'definition': 'Neural cryptography is a branch of cryptography dedicated to analyzing the application of stochastic algorithms, especially artificial neural network algorithms, for use in encryption and cryptanalysis.', 'href': '/wiki/Neural_cryptography', 'section': 'Neural Networks', 'title': 'Neural cryptography'}\n",
      "{'definition': 'Neural decoding is a neuroscience-related field concerned with the reconstruction of sensory and other stimuli from information that has already been encoded and represented in the brain by networks of neurons. Reconstruction refers to the ability of the researcher to predict what sensory stimuli the subject is receiving based purely on neuron action potentials. Therefore, the main goal of neural decoding is to characterize how the electrical activity of neurons elicit activity and responses in the brain.[1]', 'href': '/wiki/Neural_decoding', 'section': 'Neural Networks', 'title': 'Neural decoding'}\n",
      "{'definition': 'Neural gas is an artificial neural network, inspired by the self-organizing map and introduced in 1991 by Thomas Martinetz and Klaus Schulten.[1] The neural gas is a simple algorithm for finding optimal data representations based on feature vectors. The algorithm was coined \"neural gas\" because of the dynamics of the feature vectors during the adaptation process, which distribute themselves like a gas within the data space. It is applied where data compression or vector quantization is an issue, for example speech recognition,[2] image processing[3] or pattern recognition. As a robustly converging alternative to the k-means clustering it is also used for cluster analysis.[4]', 'href': '/wiki/Neural_gas', 'section': 'Neural Networks', 'title': 'Neural gas'}\n",
      "{'definition': 'The Conference and Workshop on Neural Information Processing Systems (NIPS) is a machine learning and computational neuroscience conference held every December. The conference is currently a double-track meeting (single-track until 2015) that includes invited talks as well as oral and poster presentations of refereed papers, followed by parallel-track workshops that up to 2013 were held at ski resorts.', 'href': '/wiki/Neural_Information_Processing_Systems', 'section': 'Neural Networks', 'title': 'Neural Information Processing Systems'}\n",
      "{'definition': 'Neural modeling field (NMF) is a mathematical framework for machine learning which combines ideas from neural networks, fuzzy logic, and model based recognition. It has also been referred to as modeling fields, modeling fields theory (MFT), Maximum likelihood artificial neural networks (MLANS). [1] [2] [3] [4] [5] [6] This framework has been developed by Leonid Perlovsky at the AFRL. NMF is interpreted as a mathematical description of mind’s mechanisms, including concepts, emotions, instincts, imagination, thinking, and understanding. NMF is a multi-level, hetero-hierarchical system. At each level in NMF there are concept-models encapsulating the knowledge; they generate so-called top-down signals, interacting with input, bottom-up signals. These interactions are governed by dynamic equations, which drive concept-model learning, adaptation, and formation of new concept-models for better correspondence to the input, bottom-up signals.', 'href': '/wiki/Neural_modeling_fields', 'section': 'Neural Networks', 'title': 'Neural modeling fields'}\n",
      "{'definition': 'Neural oscillation, or brainwave, is rhythmic or repetitive neural activity in the central nervous system. Neural tissue can generate oscillatory activity in many ways, driven either by mechanisms within individual neurons or by interactions between neurons. In individual neurons, oscillations can appear either as oscillations in membrane potential or as rhythmic patterns of action potentials, which then produce oscillatory activation of post-synaptic neurons. At the level of neural ensembles, synchronized activity of large numbers of neurons can give rise to macroscopic oscillations, which can be observed in an electroencephalogram. Oscillatory activity in groups of neurons generally arises from feedback connections between the neurons that result in the synchronization of their firing patterns. The interaction between neurons can give rise to oscillations at a different frequency than the firing frequency of individual neurons. A well-known example of macroscopic neural oscillations is alpha activity.', 'href': '/wiki/Neural_oscillation', 'section': 'Neural Networks', 'title': 'Neural oscillation'}\n",
      "{'definition': 'A neurally controlled animat is the conjunction of', 'href': '/wiki/Neurally_controlled_animat', 'section': 'Neural Networks', 'title': 'Neurally controlled animat'}\n",
      "{'definition': 'NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm (GA) for the generation of evolving artificial neural networks (a neuroevolution technique) developed by Ken Stanley in 2002 while at The University of Texas at Austin. It alters both the weighting parameters and structures of networks, attempting to find a balance between the fitness of evolved solutions and their diversity. It is based on applying three key techniques: tracking genes with history markers to allow crossover among topologies, applying speciation (the evolution of species) to preserve innovations, and developing topologies incrementally from simple initial structures (\"complexifying\").', 'href': '/wiki/Neuroevolution_of_augmenting_topologies', 'section': 'Neural Networks', 'title': 'Neuroevolution of augmenting topologies'}\n",
      "{'definition': \"Neuroplasticity, also known as brain plasticity and neural plasticity, is the ability of the brain to change throughout an individual's life, e.g., brain activity associated with a given function can be transferred to a different location, the proportion of grey matter can change, and synapses may strengthen or weaken over time.\", 'href': '/wiki/Neuroplasticity', 'section': 'Neural Networks', 'title': 'Neuroplasticity'}\n",
      "{'definition': \"The Ni1000 is an artificial neural network chip developed by Nestor Corporation. The chip is aimed at image analysis applications, contains more than 3 million transistors and can analyze patterns at the rate of 40,000 per second. Prototypes running with Nestor's OCR software in 1994 were capable of recognizing around 100 handwritten characters per second.\", 'href': '/wiki/Ni1000', 'section': 'Neural Networks', 'title': 'Ni1000'}\n",
      "{'definition': 'Non-spiking neurons are neurons that are located in the central and peripheral nervous systems and function as intermediary relays for sensory-motor neurons. They do not exhibit the characteristic spiking behavior of action potential generating neurons.', 'href': '/wiki/Nonspiking_neurons', 'section': 'Neural Networks', 'title': 'Nonspiking neurons'}\n",
      "{'definition': 'Nonsynaptic plasticity is a form of neuroplasticity that involves modification of ion channel function in the axon, dendrites, and cell body that results in specific changes in the integration of excitatory postsynaptic potentials (EPSPs) and inhibitory postsynaptic potentials (IPSPs). Nonsynaptic plasticity is a modification of the intrinsic excitability of the neuron. It interacts with synaptic plasticity, but it is considered a separate entity from synaptic plasticity. Intrinsic modification of the electrical properties of neurons plays a role in many aspects of plasticity from homeostatic plasticity to learning and memory itself. Nonsynaptic plasticity affects synaptic integration, subthreshold propagation, spike generation, and other fundamental mechanisms of neurons at the cellular level. These individual neuronal alterations can result in changes in higher brain function, especially learning and memory. However, as an emerging field in neuroscience, much of the knowledge about nonsynaptic plasticity is uncertain and still requires further investigation to better define its role in brain function and behavior.', 'href': '/wiki/Nonsynaptic_plasticity', 'section': 'Neural Networks', 'title': 'Nonsynaptic plasticity'}\n",
      "{'definition': \"Oja's learning rule, or simply Oja's rule, named after Finnish computer scientist Erkki Oja, is a model of how neurons in the brain or in artificial neural networks change connection strength, or learn, over time. It is a modification of the standard Hebb's Rule (see Hebbian learning) that, through multiplicative normalization, solves all stability problems and generates an algorithm for principal components analysis. This is a computational form of an effect which is believed to happen in biological neurons.\", 'href': '/wiki/Oja%27s_rule', 'section': 'Neural Networks', 'title': \"Oja's rule\"}\n",
      "{'definition': 'An optical neural network is a physical implementation of an artificial neural network with optical components.', 'href': '/wiki/Optical_neural_network', 'section': 'Neural Networks', 'title': 'Optical neural network'}\n",
      "{'definition': 'Neural coding is a neuroscience field concerned with characterising the relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble.[1] Based on the theory that sensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information.[2]', 'href': '/wiki/Phase-of-firing_code', 'section': 'Neural Networks', 'title': 'Phase-of-firing code'}\n",
      "{'definition': 'The promoter based genetic algorithm (PBGA) is a genetic algorithm for neuroevolution developed by F. Bellas and R.J. Duro in the Integrated Group for Engineering Research (GII) at the University of Coruña, in Spain. It evolves variable size feedforward artificial neural networks (ANN) that are encoded into sequences of genes for constructing a basic ANN unit. Each of these blocks is preceded by a gene promoter acting as an on/off switch that determines if that particular unit will be expressed or not.', 'href': '/wiki/Promoter_based_genetic_algorithm', 'section': 'Neural Networks', 'title': 'Promoter based genetic algorithm'}\n",
      "{'definition': 'Pulse-coupled networks or pulse-coupled neural networks (PCNNs) are neural models proposed by modeling a cat’s visual cortex, and developed for high-performance biomimetic image processing[1].', 'href': '/wiki/Pulse-coupled_networks', 'section': 'Neural Networks', 'title': 'Pulse-coupled networks'}\n",
      "{'definition': 'Quantum neural networks (QNNs) are neural network models which are based on the principles of quantum mechanics. There are two different approaches to QNN research, one exploiting quantum information processing to improve existing neural network models (sometimes also vice versa), and the other one searching for potential quantum effects in the brain.', 'href': '/wiki/Quantum_neural_network', 'section': 'Neural Networks', 'title': 'Quantum neural network'}\n",
      "{'definition': 'A radial basis function (RBF) is a real-valued function whose value depends only on the distance from the origin, so that \\n\\n\\n\\nϕ\\n(\\n\\nx\\n\\n)\\n=\\nϕ\\n(\\n‖\\n\\nx\\n\\n‖\\n)\\n\\n\\n{\\\\displaystyle \\\\phi (\\\\mathbf {x} )=\\\\phi (\\\\|\\\\mathbf {x} \\\\|)}\\n\\n; or alternatively on the distance from some other point c, called a center, so that \\n\\n\\n\\nϕ\\n(\\n\\nx\\n\\n,\\n\\nc\\n\\n)\\n=\\nϕ\\n(\\n‖\\n\\nx\\n\\n−\\n\\nc\\n\\n‖\\n)\\n\\n\\n{\\\\displaystyle \\\\phi (\\\\mathbf {x} ,\\\\mathbf {c} )=\\\\phi (\\\\|\\\\mathbf {x} -\\\\mathbf {c} \\\\|)}\\n\\n. Any function \\n\\n\\n\\nϕ\\n\\n\\n{\\\\displaystyle \\\\phi }\\n\\n that satisfies the property \\n\\n\\n\\nϕ\\n(\\n\\nx\\n\\n)\\n=\\nϕ\\n(\\n‖\\n\\nx\\n\\n‖\\n)\\n\\n\\n{\\\\displaystyle \\\\phi (\\\\mathbf {x} )=\\\\phi (\\\\|\\\\mathbf {x} \\\\|)}\\n\\n is a radial function. The norm is usually Euclidean distance, although other distance functions are also possible.', 'href': '/wiki/Radial_basis_function', 'section': 'Neural Networks', 'title': 'Radial basis function'}\n",
      "{'definition': 'In the field of mathematical modeling, a radial basis function network is an artificial neural network that uses radial basis functions as activation functions. The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters. Radial basis function networks have many uses, including function approximation, time series prediction, classification, and system control. They were first formulated in a 1988 paper by Broomhead and Lowe, both researchers at the Royal Signals and Radar Establishment.[1][2][3]', 'href': '/wiki/Radial_basis_function_network', 'section': 'Neural Networks', 'title': 'Radial basis function network'}\n",
      "{'definition': 'The random neural network (RNN) is a mathematical representation of an interconnected network of neurons or cells which exchange spiking signals. It was invented by Erol Gelenbe and is linked to the G-network model of queueing networks as well as to Gene Regulatory Network models. Each cell state is represented by an integer whose value rises when the cell receives an excitatory spike and drops when it receives an inhibitory spike. The spikes can originate outside the network itself, or they can come from other cells in the networks. Cells whose internal excitatory state has a positive value are allowed to send out spikes of either kind to other cells in the network according to specific cell-dependent spiking rates. The model has a mathematical solution in steady-state which provides the joint probability distribution of the network in terms of the individual probabilities that each cell is excited and able to send out spikes. Computing this solution is based on solving a set of non-linear algebraic equations whose parameters are related to the spiking rates of individual cells and their connectivity to other cells, as well as the arrival rates of spikes from outside the network. The RNN is a recurrent model, i.e. a neural network that is allowed to have complex feedback loops.', 'href': '/wiki/Random_neural_network', 'section': 'Neural Networks', 'title': 'Random neural network'}\n",
      "{'definition': 'A recurrent neural network (RNN) is a class of artificial neural network where connections between nodes form a directed graph along a sequence. This allows it to exhibit dynamic temporal behavior for a time sequence. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition[1] or speech recognition.[2][3]', 'href': '/wiki/Recurrent_neural_network', 'section': 'Neural Networks', 'title': 'Recurrent neural network'}\n",
      "{'definition': 'Reentry is a neural structuring of the brain, specifically in humans, which is characterized by the ongoing bidirectional exchange of signals along reciprocal axonal fibers linking two or more brain areas.[1] It is hypothesized to allow for widely distributed groups of neurons to achieve integrated and synchronized firing,[2] which is proposed to be a requirement for consciousness, as outlined by Gerald Edelman and Giulio Tononi in their book A Universe of Consciousness (2000).[3]', 'href': '/wiki/Reentry_(neural_circuitry)', 'section': 'Neural Networks', 'title': 'Reentry (neural circuitry)'}\n",
      "{'definition': 'Reservoir computing is a framework for computation that may be viewed as an extension of neural networks.[1] Typically an input signal is fed into a fixed (random) dynamical system called a reservoir and the dynamics of the reservoir map the input to a higher dimension. Then a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output. The main benefit is that training is performed only at the readout stage and the reservoir is fixed. Liquid-state machines[2] and echo state networks[3] are two major types of reservoir computing.[4]', 'href': '/wiki/Reservoir_computing', 'section': 'Neural Networks', 'title': 'Reservoir computing'}\n",
      "{'definition': 'Rprop, short for resilient backpropagation, is a learning heuristic for supervised learning in feedforward artificial neural networks. This is a first-order optimization algorithm. This algorithm was created by Martin Riedmiller and Heinrich Braun in 1992.[1]', 'href': '/wiki/Rprop', 'section': 'Neural Networks', 'title': 'Rprop'}\n",
      "{'definition': \"Semantic neural network (SNN) is based on John von Neumann's neural network [von Neumann, 1966] and Nikolai Amosov M-Network.[1][2] There are limitations to a link topology for the von Neumann’s network but SNN accept a case without these limitations. Only logical values can be processed, but SNN accept that fuzzy values can be processed too. All neurons into the von Neumann network are synchronized by tacts. For further use of self-synchronizing circuit technique SNN accepts neurons can be self-running or synchronized.\", 'href': '/wiki/Semantic_neural_network', 'section': 'Neural Networks', 'title': 'Semantic neural network'}\n",
      "{'definition': 'A sigmoid function is a mathematical function having a characteristic \"S\"-shaped curve or sigmoid curve. Often, sigmoid function refers to the special case of the logistic function shown in the first figure and defined by the formula', 'href': '/wiki/Sigmoid_function', 'section': 'Neural Networks', 'title': 'Sigmoid function'}\n",
      "{'definition': 'SNARC may refer to:', 'href': '/wiki/SNARC', 'section': 'Neural Networks', 'title': 'SNARC'}\n",
      "{'definition': 'In mathematics, the softmax function, or normalized exponential function,[1]:198 is a generalization of the logistic function that \"squashes\" a K-dimensional vector \\n\\n\\n\\n\\nz\\n\\n\\n\\n{\\\\displaystyle \\\\mathbf {z} }\\n\\n of arbitrary real values to a K-dimensional vector \\n\\n\\n\\nσ\\n(\\n\\nz\\n\\n)\\n\\n\\n{\\\\displaystyle \\\\sigma (\\\\mathbf {z} )}\\n\\n of real values, where each entry is in the range (0, 1), and all the entries adds up to 1. The function is given by', 'href': '/wiki/Softmax_activation_function', 'section': 'Neural Networks', 'title': 'Softmax activation function'}\n",
      "{'definition': 'Spiking neural networks (SNNs) fall into the third generation of artificial neural network models, increasing the level of realism in a neural simulation.[1] In addition to neuronal and synaptic state, SNNs also incorporate the concept of time into their operating model. The idea is that neurons in the SNN do not fire at each propagation cycle (as it happens with typical multi-layer perceptron networks), but rather fire only when a membrane potential\\xa0– an intrinsic quality of the neuron related to its membrane electrical charge\\xa0– reaches a specific value. When a neuron fires, it generates a signal which travels to other neurons which, in turn, increase or decrease their potentials in accordance with this signal.', 'href': '/wiki/Spiking_neural_network', 'section': 'Neural Networks', 'title': 'Spiking neural network'}\n",
      "{'definition': \"Stochastic neural networks are a type of artificial neural networks built by introducing random variations into the network, either by giving the network's neurons stochastic transfer functions, or by giving them stochastic weights. This makes them useful tools for optimization problems, since the random fluctuations help it escape from local minima.\", 'href': '/wiki/Stochastic_neural_network', 'section': 'Neural Networks', 'title': 'Stochastic neural network'}\n",
      "{'definition': 'In neuroscience, synaptic plasticity is the ability of synapses to strengthen or weaken over time, in response to increases or decreases in their activity.[1]', 'href': '/wiki/Synaptic_plasticity', 'section': 'Neural Networks', 'title': 'Synaptic plasticity'}\n",
      "{'definition': 'In neuroscience and computer science, synaptic weight refers to the strength or amplitude of a connection between two nodes, corresponding in biology to the amount of influence the firing of one neuron has on another. The term is typically used in artificial and biological neural network research.[1]', 'href': '/wiki/Synaptic_weight', 'section': 'Neural Networks', 'title': 'Synaptic weight'}\n",
      "{'definition': 'A tensor product network, in artificial neural networks, is a network that exploits the properties of tensors to model associative concepts such as variable assignment. Orthonormal vectors are chosen to model the ideas (such as variable names and target assignments), and the tensor product of these vectors construct a network whose mathematical properties allow the user to easily extract the association from it.', 'href': '/wiki/Tensor_product_network', 'section': 'Neural Networks', 'title': 'Tensor product network'}\n",
      "{'definition': 'Time delay neural network (TDNN) [1] is a multilayer artificial neural network architecture whose purpose is to 1) classify patterns with shift-invariance, and 2) model context at each layer of the network.', 'href': '/wiki/Time_delay_neural_network', 'section': 'Neural Networks', 'title': 'Time delay neural network'}\n",
      "{'definition': 'The U-matrix (unified distance matrix) is a representation of a self-organizing map (SOM) where the Euclidean distance between the codebook vectors of neighboring neurons is depicted in a grayscale image. This image is used to visualize the data in a high-dimensional space using a 2D image.[1]', 'href': '/wiki/U-Matrix', 'section': 'Neural Networks', 'title': 'U-Matrix'}\n",
      "{'definition': 'In the mathematical theory of artificial neural networks, the universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of Rn, under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters.', 'href': '/wiki/Universal_approximation_theorem', 'section': 'Neural Networks', 'title': 'Universal approximation theorem'}\n",
      "{'definition': 'Winner-take-all is a computational principle applied in computational models of neural networks by which neurons in a layer compete with each other for activation. In the classical form, only the neuron with the highest activation stays active while all other neurons shut down; however, other variations allow more than one neuron to be active, for example the soft winner take-all, by which a power function is applied to the neurons.', 'href': '/wiki/Winner-take-all_(computing)', 'section': 'Neural Networks', 'title': 'Winner-take-all (computing)'}\n",
      "{'definition': 'The winnow algorithm[1] is a technique from machine learning for learning a linear classifier from labeled examples. It is very similar to the perceptron algorithm. However, the perceptron algorithm uses an additive weight-update scheme, while Winnow uses a multiplicative scheme that allows it to perform much better when many dimensions are irrelevant (hence its name). It is a simple algorithm that scales well to high-dimensional data. During training, Winnow is shown a sequence of positive and negative examples. From these it learns a decision hyperplane that can then be used to label novel examples as positive or negative. The algorithm can also be used in the online learning setting, where the learning and the classification phase are not clearly separated.', 'href': '/wiki/Winnow_(algorithm)', 'section': 'Neural Networks', 'title': 'Winnow (algorithm)'}\n",
      "{'definition': 'Reinforcement learning (RL) is an area of machine learning inspired by behaviourist psychology[citation needed], concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In the operations research and control literature, reinforcement learning is called approximate dynamic programming, or neuro-dynamic programming.[1][2] The problems of interest in reinforcement learning have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation, particularly in the absence of a mathematical model of the environment. In economics and game theory, reinforcement learning may be used to explain how equilibrium may arise under bounded rationality.[citation needed]', 'href': '/wiki/Reinforcement_learning', 'section': 'Reinforcement learning', 'title': 'Reinforcement learning'}\n",
      "{'definition': \"Markov decision processes (MDPs) provide a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. MDPs are useful for studying a wide range of optimization problems solved via dynamic programming and reinforcement learning. MDPs were known at least as early as the 1950s (cf. Bellman 1957); a core body of research on Markov decision processes resulted from Ronald A. Howard's book published in 1960, Dynamic Programming and Markov Processes.[1] They are used in a wide area of disciplines, including robotics, automatic control, economics, and manufacturing.\", 'href': '/wiki/Markov_decision_process', 'section': 'Reinforcement learning', 'title': 'Markov decision process'}\n",
      "{'definition': \"A Bellman equation, named after Richard E. Bellman, is a necessary condition for optimality associated with the mathematical optimization method known as dynamic programming.[1] It writes the value of a decision problem at a certain point in time in terms of the payoff from some initial choices and the value of the remaining decision problem that results from those initial choices.[citation needed] This breaks a dynamic optimization problem into a sequence of simpler subproblems, as Bellman's “principle of optimality” prescribes.[2]\", 'href': '/wiki/Bellman_equation', 'section': 'Reinforcement learning', 'title': 'Bellman equation'}\n",
      "{'definition': 'Q-learning is a reinforcement learning technique used in machine learning. The technique does not require a model of the environment. Q-learning can handle problems with stochastic transitions and rewards, without requiring adaptations.', 'href': '/wiki/Q-learning', 'section': 'Reinforcement learning', 'title': 'Q-learning'}\n",
      "{'definition': 'Temporal difference (TD) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic programming methods.[1]', 'href': '/wiki/Temporal_difference_learning', 'section': 'Reinforcement learning', 'title': 'Temporal difference learning'}\n",
      "{'definition': 'Sarsa may refer to:', 'href': '/wiki/SARSA', 'section': 'Reinforcement learning', 'title': 'SARSA'}\n",
      "{'definition': 'In probability theory, the multi-armed bandit problem (sometimes called the K-[1] or N-armed bandit problem[2]) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice\\'s properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.[3][4] The name comes from imagining a gambler at a row of slot machines (sometimes known as \"one-armed bandits\"), who has to decide which machines to play, how many times to play each machine and in which order to play them, and whether to continue with the current machine or try a different machine.[5] The multi-armed bandit problem also falls into the broad category of Stochastic scheduling.', 'href': '/wiki/Multi-armed_bandit', 'section': 'Reinforcement learning', 'title': 'Multi-armed bandit'}\n",
      "{'definition': 'In artificial intelligence, apprenticeship learning (or learning from demonstration) is the process of learning by observing an expert.[1][2] It can be viewed as a form of supervised learning, where the training dataset consists of task executions by a demonstration teacher.[2]', 'href': '/wiki/Apprenticeship_learning', 'section': 'Reinforcement learning', 'title': 'Apprenticeship learning'}\n",
      "{'definition': \"Predictive learning is a technique of machine learning in which an agent tries to build a model of its environment by trying out different actions in various circumstances. It uses knowledge of the effects its actions appear to have, turning them into planning operators. These allow the agent to act purposefully in its world. Predictive learning is one attempt to learn with a minimum of pre-existing mental structure. It may have been inspired by Piaget's account of how children construct knowledge of the world by interacting with it. Gary Drescher's book 'Made-up Minds' was seminal for the area.\", 'href': '/wiki/Predictive_learning', 'section': 'Reinforcement learning', 'title': 'Predictive learning'}\n",
      "{'definition': \"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning. Text mining usually involves the process of structuring the input text (usually parsing, along with the addition of some derived linguistic features and the removal of others, and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output. 'High quality' in text mining usually refers to some combination of relevance, novelty, and interestingness. Typical text mining tasks include text categorization, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\", 'href': '/wiki/Text_mining', 'section': 'Text Mining', 'title': 'Text mining'}\n",
      "{'definition': 'Natural-language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to fruitfully process large amounts of natural language\\xa0data.', 'href': '/wiki/Natural_language_processing', 'section': 'Text Mining', 'title': 'Natural language processing'}\n",
      "{'definition': 'Document classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" (or \"intellectually\") or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is therefore interdisciplinary research on document classification.', 'href': '/wiki/Document_classification', 'section': 'Text Mining', 'title': 'Document classification'}\n",
      "{'definition': 'The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). Also known as the vector space model[1]. In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. The bag-of-words model has also been used for computer vision.[2]', 'href': '/wiki/Bag_of_words_model', 'section': 'Text Mining', 'title': 'Bag of words model'}\n",
      "{'definition': 'In the fields of computational linguistics and probability, an n-gram is a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus. When the items are words, n-grams may also be called shingles[clarification needed].[1]', 'href': '/wiki/N-gram', 'section': 'Text Mining', 'title': 'N-gram'}\n",
      "{'definition': 'In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech,[1] based on both its definition and its context—i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.', 'href': '/wiki/Part-of-speech_tagging', 'section': 'Text Mining', 'title': 'Part-of-speech tagging'}\n",
      "{'definition': 'Opinion mining (sometimes known as sentiment analysis or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.', 'href': '/wiki/Sentiment_analysis', 'section': 'Text Mining', 'title': 'Sentiment analysis'}\n",
      "{'definition': 'Information extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video could be seen as information extraction.', 'href': '/wiki/Information_extraction', 'section': 'Text Mining', 'title': 'Information extraction'}\n",
      "{'definition': 'In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document\\'s balance of topics is.', 'href': '/wiki/Topic_model', 'section': 'Text Mining', 'title': 'Topic model'}\n",
      "{'definition': 'Concept mining is an activity that results in the extraction of concepts from artifacts. Solutions to the task typically involve aspects of artificial intelligence and statistics, such as data mining and text mining.[1] Because artifacts are typically a loosely structured sequence of words and other symbols (rather than concepts), the problem is nontrivial, but it can provide powerful insights into the meaning, provenance and similarity of documents.', 'href': '/wiki/Concept_mining', 'section': 'Text Mining', 'title': 'Concept mining'}\n",
      "{'definition': 'In machine learning, semantic analysis of a corpus is the task of building structures that approximate concepts from a large set of documents. It generally does not involve prior semantic understanding of the documents.', 'href': '/wiki/Semantic_analysis_(machine_learning)', 'section': 'Text Mining', 'title': 'Semantic analysis (machine learning)'}\n",
      "{'definition': 'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.', 'href': '/wiki/Automatic_summarization', 'section': 'Text Mining', 'title': 'Automatic summarization'}\n",
      "{'definition': 'In machine learning and data mining, a string kernel is a kernel function that operates on strings, i.e. finite sequences of symbols that need not be of the same length. String kernels can be intuitively understood as functions measuring the similarity of pairs of strings: the more similar two strings a and b are, the higher the value of a string kernel K(a, b) will be.', 'href': '/wiki/String_kernel', 'section': 'Text Mining', 'title': 'String kernel'}\n",
      "{'definition': 'Biomedical text mining (also known as BioNLP) refers to text mining applied to texts and literature of the biomedical and molecular biology domain. It is a rather recent research field on the edge of natural language processing, bioinformatics, medical informatics and computational linguistics.', 'href': '/wiki/Biomedical_text_mining', 'section': 'Text Mining', 'title': 'Biomedical text mining'}\n",
      "{'definition': 'Never-Ending Language Learning system (NELL) is a semantic machine learning system developed by a research team at Carnegie Mellon University, and supported by grants from DARPA, Google, NSF, and CNPq with portions of the system running on a supercomputing cluster provided by Yahoo!.[1]', 'href': '/wiki/Never-Ending_Language_Learning', 'section': 'Text Mining', 'title': 'Never-Ending Language Learning'}\n",
      "{'definition': 'Structure mining or structured data mining is the process of finding and extracting useful information from semi-structured data sets. Graph mining, sequential pattern mining and molecule mining are special cases of structured data mining[citation needed].', 'href': '/wiki/Structure_mining', 'section': 'Structure Mining', 'title': 'Structure mining'}\n",
      "{'definition': 'Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values.[1]', 'href': '/wiki/Structured_learning', 'section': 'Structure Mining', 'title': 'Structured learning'}\n",
      "{'definition': 'Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values.[1]', 'href': '/wiki/Structured_prediction', 'section': 'Structure Mining', 'title': 'Structured prediction'}\n",
      "{'definition': 'Sequential pattern mining is a topic of data mining concerned with finding statistically relevant patterns between data examples where the values are delivered in a sequence.[1] It is usually presumed that the values are discrete, and thus time series mining is closely related, but usually considered a different activity. Sequential pattern mining is a special case of structured data mining.', 'href': '/wiki/Sequence_mining', 'section': 'Structure Mining', 'title': 'Sequence mining'}\n",
      "{'definition': 'In machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. A common example of a sequence labeling task is part of speech tagging, which seeks to assign a part of speech to each word in an input sentence or document. Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence. However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements, using special algorithms to choose the globally best set of labels for the entire sequence at once.', 'href': '/wiki/Sequence_labeling', 'section': 'Structure Mining', 'title': 'Sequence labeling'}\n",
      "{'definition': 'Process mining is a family of techniques in the field of process management that support the analysis of business processes based on event logs. During process mining, specialized data mining algorithms are applied to event log data in order to identify trends, patterns and details contained in event logs recorded by an information system. Process mining aims to improve process efficiency and understanding of processes.[1] Process mining is also known as Automated Business Process Discovery (ABPD).[2] However, in academic literature[3] the term Automated Business Process Discovery is used in a narrower sense to refer specifically to techniques that take as input an event log and produce as output a business process model. The term Process Mining is used in a broader setting to refer not only to techniques for discovering process models, but also techniques for business process conformance and performance analysis based on event logs.', 'href': '/wiki/Process_mining', 'section': 'Structure Mining', 'title': 'Process mining'}\n",
      "{'definition': 'In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance. Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to.', 'href': '/wiki/Multi-label_classification', 'section': 'Advanced Learning Tasks', 'title': 'Multi-label classification'}\n",
      "{'definition': 'Automated machine learning (AutoML) is the process of automating the end-to-end process of applying machine learning to real-world problems. In a typical machine learning application, practitioners must apply the appropriate data pre-processing, feature engineering, feature extraction, and feature selection methods that make the dataset amenable for machine learning. Following those preprocessing steps, practitioners must then perform algorithm selection and hyperparameter optimization to maximize the predictive performance of their final machine learning model. As many of these steps are often beyond the abilities of non-experts, AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.[1][2] Automating the end-to-end process of applying machine learning offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform models that were designed by hand.', 'href': '/wiki/Automated_machine_learning', 'section': 'Advanced Learning Tasks', 'title': 'Automated machine learning'}\n",
      "{'definition': 'Classifier chains is a machine learning method for problem transformation in multi-label classification. It combines the computational efficiency of the Binary Relevance method while still being able to take the label dependencies into account for classification.[1]', 'href': '/wiki/Classifier_chains', 'section': 'Advanced Learning Tasks', 'title': 'Classifier chains'}\n",
      "{'definition': 'Web mining is the application of data mining techniques to discover patterns from the World Wide Web. As the name proposes, this is information gathered by mining the web. It makes utilization of automated apparatuses to reveal and extricate data from servers and web2 reports, and it permits organizations to get to both organized and unstructured information from browser activities, server logs, website and link structure, page content and different sources.', 'href': '/wiki/Web_mining', 'section': 'Advanced Learning Tasks', 'title': 'Web mining'}\n",
      "{'definition': 'In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.[1] Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.[2]', 'href': '/wiki/Anomaly_detection', 'section': 'Advanced Learning Tasks', 'title': 'Anomaly detection'}\n",
      "{'definition': \"Anomaly Detection at Multiple Scales, or ADAMS, is a $35 million DARPA project designed to identify patterns and anomalies in very large data sets. It is under DARPA's Information Innovation office and began in 2011.[1][2][3][4]\", 'href': '/wiki/Anomaly_Detection_at_Multiple_Scales', 'section': 'Advanced Learning Tasks', 'title': 'Anomaly Detection at Multiple Scales'}\n",
      "{'definition': 'In anomaly detection, the local outlier factor (LOF) is an algorithm proposed by Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng and Jörg Sander in 2000 for finding anomalous data points by measuring the local deviation of a given data point with respect to its neighbours.[1]', 'href': '/wiki/Local_outlier_factor', 'section': 'Advanced Learning Tasks', 'title': 'Local outlier factor'}\n",
      "{'definition': 'In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.[1] Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.[2]', 'href': '/wiki/Novelty_detection', 'section': 'Advanced Learning Tasks', 'title': 'Novelty detection'}\n",
      "{'definition': 'GSP algorithm (Generalized Sequential Pattern algorithm) is an algorithm used for sequence mining. The algorithms for solving sequence mining problems are mostly based on the a priori (level-wise) algorithm. One way to use the level-wise paradigm is to first discover all the frequent items in a level-wise fashion. It simply means counting the occurrences of all singleton elements in the database. Then, the transactions are filtered by removing the non-frequent items. At the end of this step, each transaction consists of only the frequent elements it originally contained. This modified database becomes an input to the GSP algorithm. This process requires one pass over the whole database.', 'href': '/wiki/GSP_Algorithm', 'section': 'Advanced Learning Tasks', 'title': 'GSP Algorithm'}\n",
      "{'definition': 'Optimal matching is a sequence analysis method used in social science, to assess the dissimilarity of ordered arrays of tokens that usually represent a time-ordered sequence of socio-economic states two individuals have experienced. Once such distances have been calculated for a set of observations (e.g. individuals in a cohort) classical tools (such as cluster analysis) can be used. The method was tailored to social sciences[1] from a technique originally introduced to study molecular biology (protein or genetic) sequences (see sequence alignment). Optimal matching uses the Needleman-Wunsch algorithm.', 'href': '/wiki/Optimal_matching', 'section': 'Advanced Learning Tasks', 'title': 'Optimal matching'}\n",
      "{'definition': 'Record linkage (RL) is the task of finding records in a data set that refer to the same entity across different data sources (e.g., data files, books, websites, and databases). Record linkage is necessary when joining data sets based on entities that may or may not share a common identifier (e.g., database key, URI, National identification number), which may be due to differences in record shape, storage location, or curator style or preference. A data set that has undergone RL-oriented reconciliation may be referred to as being cross-linked. Record linkage is called data linkage in many jurisdictions, but is the same process.', 'href': '/wiki/Record_linkage', 'section': 'Advanced Learning Tasks', 'title': 'Record linkage'}\n",
      "{'definition': 'Meta learning is a subfield of machine learning where automatic learning algorithms are applied on metadata about machine learning experiments. As of 2017 the term had not found a standard interpretation, however the main goal is to use such metadata to understand how automatic learning can become flexible in solving learning problems, hence to improve the performance of existing learning algorithms or to learn (induce) the learning algorithm itself, hence the alternative term learning to learn.', 'href': '/wiki/Meta_learning_(computer_science)', 'section': 'Advanced Learning Tasks', 'title': 'Meta learning (computer science)'}\n",
      "{'definition': 'A learning automaton is one type of machine learning algorithm studied since 1970s. Learning automata select their current action based on past experiences from the environment. It will fall into the range of reinforcement learning if the environment is stochastic and Markov Decision Process (MDP) is used.', 'href': '/wiki/Learning_automata', 'section': 'Advanced Learning Tasks', 'title': 'Learning automata'}\n",
      "{'definition': 'Learning to rank[1] or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning, in the construction of ranking models for information retrieval systems.[2] Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model\\'s purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is \"similar\" to rankings in the training data in some sense.', 'href': '/wiki/Learning_to_rank', 'section': 'Advanced Learning Tasks', 'title': 'Learning to rank'}\n",
      "{'definition': 'In machine learning, multiple-instance learning (MIL) is a variation on supervised learning. Instead of receiving a set of instances which are individually labeled, the learner receives a set of labeled bags, each containing many instances. In the simple case of multiple-instance binary classification, a bag may be labeled negative if all the instances in it are negative. On the other hand, a bag is labeled positive if there is at least one instance in it which is positive. From a collection of labeled bags, the learner tries to either (i) induce a concept that will label individual instances correctly or (ii) learn how to label bags without inducing the concept.', 'href': '/wiki/Multiple-instance_learning', 'section': 'Advanced Learning Tasks', 'title': 'Multiple-instance learning'}\n",
      "{'definition': 'Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure.[1][2] Note that SRL is sometimes called Relational Machine Learning (RML) in the literature. Typically, the knowledge representation formalisms developed in SRL use (a subset of) first-order logic to describe relational properties of a domain in a general manner (universal quantification) and draw upon probabilistic graphical models (such as Bayesian networks or Markov networks) to model the uncertainty; some also build upon the methods of inductive logic programming. Significant contributions to the field have been made since the late 1990s.[3]', 'href': '/wiki/Statistical_relational_learning', 'section': 'Advanced Learning Tasks', 'title': 'Statistical relational learning'}\n",
      "{'definition': 'Relational data mining is the data mining technique for relational databases.[1] Unlike traditional data mining algorithms, which look for patterns in a single table (propositional patterns), relational data mining algorithms look for patterns among multiple tables (relational patterns). For most types of propositional patterns, there are corresponding relational patterns. For example, there are relational classification rules (relational classification), relational regression tree, and relational association rules.', 'href': '/wiki/Relational_classification', 'section': 'Advanced Learning Tasks', 'title': 'Relational classification'}\n",
      "{'definition': 'Data Stream Mining is the process of extracting knowledge structures from continuous, rapid data records. A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities.', 'href': '/wiki/Data_stream_mining', 'section': 'Advanced Learning Tasks', 'title': 'Data stream mining'}\n",
      "{'definition': 'The α-algorithm is an algorithm used in process mining, aimed at reconstructing causality from a set of sequences of events. It was first put forward by van der Aalst, Weijters and Măruşter.[1] Several extensions or modifications of it have since been presented, which will be listed below.', 'href': '/wiki/Alpha_algorithm', 'section': 'Advanced Learning Tasks', 'title': 'Alpha algorithm'}\n",
      "{'definition': 'Syntactic pattern recognition or structural pattern recognition is a form of pattern recognition, in which each object can be represented by a variable-cardinality set of symbolic, nominal features. This allows for representing pattern structures, taking into account more complex interrelationships between attributes than is possible in the case of flat, numerical feature vectors of fixed dimensionality, that are used in statistical classification.', 'href': '/wiki/Syntactic_pattern_recognition', 'section': 'Advanced Learning Tasks', 'title': 'Syntactic pattern recognition'}\n",
      "{'definition': 'Multispectral remote sensing is the collection and analysis of reflected, emitted, or back-scattered energy from an object or an area of interest in multiple bands of regions of the electromagnetic spectrum (Jensen, 2005). Subcategories of multispectral remote sensing include hyperspectral, in which hundreds of bands are collected and analyzed, and ultraspectral remote sensing where many hundreds of bands are used (Logicon, 1997). The main purpose of multispectral imaging is the potential to classify the image using multispectral classification. This is a much faster method of image analysis than is possible by human interpretation.', 'href': '/wiki/Multispectral_pattern_recognition', 'section': 'Advanced Learning Tasks', 'title': 'Multispectral pattern recognition'}\n",
      "{'definition': 'Algorithmic learning theory is a mathematical framework for analyzing machine learning problems and algorithms. Synonyms include formal learning theory and algorithmic inductive inference. Algorithmic learning theory is different from statistical learning theory in that it does not make use of statistical assumptions and analysis. Both algorithmic and statistical learning theory are concerned with machine learning and can thus be viewed as branches of computational learning theory.', 'href': '/wiki/Algorithmic_learning_theory', 'section': 'Advanced Learning Tasks', 'title': 'Algorithmic learning theory'}\n",
      "{'definition': 'Deep learning (also known as deep structured learning or hierarchical learning) is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms. Learning can be supervised, semi-supervised or unsupervised.[1][2][3]', 'href': '/wiki/Deep_learning', 'section': 'Advanced Learning Tasks', 'title': 'Deep learning'}\n",
      "{'definition': 'A Bongard problem is a kind of puzzle invented by the Russian computer scientist Mikhail Moiseevich Bongard (Михаил Моисеевич Бонгард, 1924–1971), probably in the mid-1960s. They were published in his 1967 book on pattern recognition. Bongard, in the introduction of the book (which deals with a number of topics including perceptrons) credits the ideas in it to a group including M. N. Vaintsvaig, V. V. Maksimov, and M. S. Smirnov.', 'href': '/wiki/Bongard_problem', 'section': 'Advanced Learning Tasks', 'title': 'Bongard problem'}\n",
      "{'definition': 'Learning with errors (LWE) is a problem in machine learning that is conjectured to be hard to solve. Introduced[1] by Oded Regev in 2005 (Who won the 2018 Gödel Prize for this work), it is a generalization of the parity learning problem. Regev showed, furthermore, that the LWE problem is as hard to solve as several worst-case lattice problems. The LWE problem has recently[1][2] been used as a hardness assumption to create public-key cryptosystems, such as the ring learning with errors key exchange by Peikert.[3]', 'href': '/wiki/Learning_with_errors', 'section': 'Advanced Learning Tasks', 'title': 'Learning with errors'}\n",
      "{'definition': 'Parity learning is a problem in machine learning. An algorithm that solves this problem must find a function ƒ, given some samples (x,\\xa0ƒ(x)) and the assurance that ƒ computes the parity of bits at some fixed locations. The samples are generated using some distribution over the input. The problem is easy to solve using Gaussian elimination provided that a sufficient number of samples (from a distribution which is not too skewed) are provided to the algorithm.', 'href': '/wiki/Parity_learning', 'section': 'Advanced Learning Tasks', 'title': 'Parity learning'}\n",
      "{'definition': 'Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.[1] For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited.', 'href': '/wiki/Inductive_transfer', 'section': 'Advanced Learning Tasks', 'title': 'Inductive transfer'}\n",
      "{'definition': 'Granular computing (GrC) is an emerging computing paradigm of information processing. It concerns the processing of complex information entities called information granules, which arise in the process of data abstraction and derivation of knowledge from information or data. Generally speaking, information granules are collections of entities that usually originate at the numeric level and are arranged together due to their similarity, functional or physical adjacency, indistinguishability, coherency, or the like.', 'href': '/wiki/Granular_computing', 'section': 'Advanced Learning Tasks', 'title': 'Granular computing'}\n",
      "{'definition': 'Conceptual clustering is a machine learning paradigm for unsupervised classification developed mainly during the 1980s. It is distinguished from ordinary data clustering by generating a concept description for each generated class. Most conceptual clustering methods are capable of generating hierarchical category structures; see Categorization for more information on hierarchy. Conceptual clustering is closely related to formal concept analysis, decision tree learning, and mixture model learning.', 'href': '/wiki/Conceptual_clustering', 'section': 'Advanced Learning Tasks', 'title': 'Conceptual clustering'}\n",
      "{'definition': 'Formal concept analysis (FCA) is a principled way of deriving a concept hierarchy or formal ontology from a collection of objects and their properties. Each concept in the hierarchy represents the objects sharing some set of properties; and each sub-concept in the hierarchy represents a subset of the objects (as well as a superset of the properties) in the concepts above it. The term was introduced by Rudolf Wille in 1980, and builds on the mathematical theory of lattices and ordered sets that was developed by Garrett Birkhoff and others in the 1930s.', 'href': '/wiki/Formal_concept_analysis', 'section': 'Advanced Learning Tasks', 'title': 'Formal concept analysis'}\n",
      "{'definition': 'Biclustering, block clustering ,[1] [2] co-clustering, or two-mode clustering[3][4][5] is a data mining technique which allows simultaneous clustering of the rows and columns of a matrix. The term was first introduced by Boris Mirkin[6] to name a technique introduced many years earlier,[6] in 1972, by J.\\xa0A.\\xa0Hartigan.[7]', 'href': '/wiki/Biclustering', 'section': 'Advanced Learning Tasks', 'title': 'Biclustering'}\n",
      "{'definition': 'Information visualization or information visualisation is the study of (interactive) visual representations of abstract data to reinforce human cognition. The abstract data include both numerical and non-numerical data, such as text and geographic information. However, information visualization differs from scientific visualization: \"it’s infovis [information visualization] when the spatial representation is chosen, and it’s scivis [scientific visualization] when the spatial representation is given\".[1]', 'href': '/wiki/Information_visualization', 'section': 'Advanced Learning Tasks', 'title': 'Information visualization'}\n",
      "{'definition': 'Co-occurrence networks are generally used to provide a graphic visualization of potential relationships between people, organizations, concepts or other entities represented within written material. The generation and visualization of co-occurrence networks has become practical with the advent of electronically stored text amenable to text mining.', 'href': '/wiki/Co-occurrence_networks', 'section': 'Advanced Learning Tasks', 'title': 'Co-occurrence networks'}\n",
      "{'definition': \"A problem domain is the area of expertise or application that needs to be examined to solve a problem. Focusing on a problem domain is simply looking at only the topics of an individual's interest, and excluding everything else. For example, when developing a system to measure good practice in medicine, carpet drawings at hospitals would not be included in the problem domain. In this example, the domain refers to relevant topics solely within the delimited area of interest: medicine.\", 'href': '/wiki/Problem_domain', 'section': 'Applications', 'title': 'Problem domain'}\n",
      "{'definition': 'A recommender system or a recommendation system (sometimes replacing \"system\" with a synonym such as platform or engine) is a subclass of information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give to an item.[1][2]', 'href': '/wiki/Recommender_system', 'section': 'Applications', 'title': 'Recommender system'}\n",
      "{'definition': 'Collaborative filtering (CF) is a technique used by recommender systems.[1] Collaborative filtering has two senses, a narrow one and a more general one.[2]', 'href': '/wiki/Collaborative_filtering', 'section': 'Applications', 'title': 'Collaborative filtering'}\n",
      "{'definition': 'In information science, profiling refers to the process of construction and application of user profiles generated by computerized data analysis.', 'href': '/wiki/Profiling_(information_science)', 'section': 'Applications', 'title': 'Profiling (information science)'}\n",
      "{'definition': 'Speech recognition is the inter-disciplinary sub-field of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers. It is also known as \"automatic speech recognition\" (ASR), \"computer speech recognition\", or just \"speech to text\" (STT). It incorporates knowledge and research in the linguistics, computer science, and electrical engineering fields.', 'href': '/wiki/Speech_recognition', 'section': 'Applications', 'title': 'Speech recognition'}\n",
      "{'definition': 'Stock Forecast can refer to:', 'href': '/wiki/Stock_forecast', 'section': 'Applications', 'title': 'Stock forecast'}\n",
      "{'definition': \"Activity recognition aims to recognize the actions and goals of one or more agents from a series of observations on the agents' actions and the environmental conditions. Since the 1980s, this research field has captured the attention of several computer science communities due to its strength in providing personalized support for many different applications and its connection to many different fields of study such as medicine, human-computer interaction, or sociology.\", 'href': '/wiki/Activity_recognition', 'section': 'Applications', 'title': 'Activity recognition'}\n",
      "{'definition': 'Fraud is a billion-dollar business and it is increasing every year.[citation needed] The PwC global economic crime survey of 2016 suggests that more than one in three (36%) of organizations experienced economic crime.[1]', 'href': '/wiki/Data_Analysis_Techniques_for_Fraud_Detection', 'section': 'Applications', 'title': 'Data Analysis Techniques for Fraud Detection'}\n",
      "{'definition': 'This page describes mining for molecules. Since molecules may be represented by molecular graphs this is strongly related to graph mining and structured data mining. The main problem is how to represent molecules while discriminating the data instances. One way to do this is chemical similarity metrics, which has a long tradition in the field of cheminformatics.', 'href': '/wiki/Molecule_mining', 'section': 'Applications', 'title': 'Molecule mining'}\n",
      "{'definition': 'Behavioral targeting comprises a range of technologies and techniques used by online website brands, publishers and advertisers aimed at increasing the effectiveness of marketing and advertising using user web-browsing behavior information. In particular, \"behavioral targeting uses information collected from an individual\\'s web-browsing behavior (e.g., the pages that they have visited or searched) to select advertisements to display\".[1] This activity extends to behavioral marketing by using that same browsing behavior to prompt relevant email and onsite messaging to users and consumers.', 'href': '/wiki/Behavioral_targeting', 'section': 'Applications', 'title': 'Behavioral targeting'}\n",
      "{'definition': \"PRODIGAL (Proactive discovery of insider threats using graph analysis and learning) is a computer system for predicting anomalous behavior among humans, by data mining network traffic such as emails, text messages and server log entries.[1] It is part of DARPA's Anomaly Detection at Multiple Scales (ADAMS) project.[2] The initial schedule is for two years and the budget $9\\xa0million.[3]\", 'href': '/wiki/Proactive_Discovery_of_Insider_Threats_Using_Graph_Analysis_and_Learning', 'section': 'Applications', 'title': 'Proactive Discovery of Insider Threats Using Graph Analysis and Learning'}\n",
      "{'definition': 'Robot learning is a research field at the intersection of machine learning and robotics. It studies techniques allowing a robot to acquire novel skills or adapt to its environment through learning algorithms. The embodiment of the robot, situated in a physical embedding, provides at the same time specific difficulties (e.g. high-dimensionality, real time constraints for collecting data and learning) and opportunities for guiding the learning process (e.g. sensorimotor synergies, motor primitives).', 'href': '/wiki/Robot_learning', 'section': 'Applications', 'title': 'Robot learning'}\n",
      "{'definition': 'Computer vision is an interdisciplinary field that deals with how computers can be made for gaining high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.[1][2][3]', 'href': '/wiki/Computer_vision', 'section': 'Applications', 'title': 'Computer vision'}\n",
      "{'definition': 'A facial recognition system is a technology capable of identifying or verifying a person from a digital image or a video frame from a video source. There are multiples methods in which facial recognition systems work, but in general, they work by comparing selected facial features from given image with faces within a database.', 'href': '/wiki/Facial_recognition_system', 'section': 'Applications', 'title': 'Facial recognition system'}\n",
      "{'definition': 'In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.[1] Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.[2]', 'href': '/wiki/Outlier_detection', 'section': 'Applications', 'title': 'Outlier detection'}\n",
      "{'definition': 'In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.[1] Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.[2]', 'href': '/wiki/Anomaly_detection', 'section': 'Applications', 'title': 'Anomaly detection'}\n",
      "{'definition': 'In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.[1] Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.[2]', 'href': '/wiki/Novelty_detection', 'section': 'Applications', 'title': 'Novelty detection'}\n"
     ]
    }
   ],
   "source": [
    "for row, val in json1_data.items():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(query_vec, def_vec):\n",
    "    return (np.sum((query_vec * def_vec))\n",
    "            / (np.sqrt(np.sum((query_vec ** 2)))\n",
    "               * np.sqrt(np.sum((def_vec ** 2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168551"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(dog.vector, cat.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88316804"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, uq_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhaskar = \"Overfitting is where the model fits to each and every point in the feature set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_nlp = model.nlp(bhaskar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90095067"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, b_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emily = \"Overfitting is when your predictive model is trying to be too close to too many points and so it loses its predictive power\"\n",
    "e_nlp = model.nlp(emily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176628"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, e_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = \"Costco sells a hot dog and a soda for $1.50\"\n",
    "r_nlp = model.nlp(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60963613"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, r_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hack = 'statistics overfitting set data observations'\n",
    "hack_nlp = model.nlp(hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66674113"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, hack_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = def_nlp.noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[statistics,\n",
       " overfitting,\n",
       " the production,\n",
       " an analysis,\n",
       " a particular set,\n",
       " data,\n",
       " additional data,\n",
       " future observations]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_root = [chunk.root.lemma_ for chunk in list(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_root = set(nc_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis',\n",
       " 'datum',\n",
       " 'observation',\n",
       " 'overfitting',\n",
       " 'production',\n",
       " 'set',\n",
       " 'statistic'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(def_nlp.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In prep\n",
      "statistics pobj\n",
      ", punct\n",
      "overfitting nsubj\n",
      "is ROOT\n",
      "\" punct\n",
      "the det\n",
      "production attr\n",
      "of prep\n",
      "an det\n",
      "analysis pobj\n",
      "that nsubj\n",
      "corresponds relcl\n",
      "too advmod\n",
      "closely advmod\n",
      "or cc\n",
      "exactly conj\n",
      "to prep\n",
      "a det\n",
      "particular amod\n",
      "set pobj\n",
      "of prep\n",
      "data pobj\n",
      ", punct\n",
      "and cc\n",
      "may aux\n",
      "therefore advmod\n",
      "fail conj\n",
      "to aux\n",
      "fit xcomp\n",
      "additional amod\n",
      "data dobj\n",
      "or cc\n",
      "predict conj\n",
      "future amod\n",
      "observations dobj\n",
      "reliably advmod\n",
      "\" punct\n"
     ]
    }
   ],
   "source": [
    "for token in sent:\n",
    "    print(token, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobjs = [token.lemma_ for token in sent if token.dep_ == 'pobj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistic', 'analysis', 'set', 'datum']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pobjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get:\n",
    "* list of multiword noun chunks (remove det tokens)\n",
    "* list of lemmatized roots of noun chunks\n",
    "* overall sentence embedding\n",
    "\n",
    "score:\n",
    "top noun chunks that match / total num of noun chunks in the definition * sentence similarity + num of multiword noun chunks that match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36585009"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(model.nlp('rain').vector, model.nlp('umbrella').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mw_nc(doc):\n",
    "    \"\"\"Get list of multiword noun chunks.\n",
    "    \n",
    "    Tokens with dependency of 'det' are removed.\n",
    "    \n",
    "    Arguments:\n",
    "        doc (spaCy doc object)\n",
    "    \n",
    "    Returns:\n",
    "        pruned_mw (list): list of multiword noun chunks\n",
    "    \"\"\"\n",
    "    mw_nc = list(doc.noun_chunks)\n",
    "    \n",
    "    # remove det tokens\n",
    "\n",
    "    pruned_mw = []\n",
    "\n",
    "    for chunk in mw_nc:\n",
    "        replace = []\n",
    "        for token in chunk:\n",
    "            if token.dep_ is not 'det':\n",
    "                token = token.lemma_\n",
    "                replace.append(token)\n",
    "        if len(replace) > 1:\n",
    "            pruned_mw.append(\" \".join(replace))\n",
    "    \n",
    "    return pruned_mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_roots(doc):\n",
    "    \"\"\"Get list of lemmatized roots of noun chunks.\n",
    "    \n",
    "    Arguments:\n",
    "        doc (spaCy doc object)\n",
    "    \n",
    "    Returns:\n",
    "        lemma_roots (list): list of lemmatized roots of noun chunks\n",
    "    \"\"\"\n",
    "    nc = list(doc.noun_chunks)\n",
    "\n",
    "    roots = [token.root.lemma_ for token in nc]\n",
    "    \n",
    "    return roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistic',\n",
       " 'overfitting',\n",
       " 'production',\n",
       " 'analysis',\n",
       " 'set',\n",
       " 'datum',\n",
       " 'datum',\n",
       " 'observation']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemma_roots(def_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
