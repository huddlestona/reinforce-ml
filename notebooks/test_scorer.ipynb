{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nguyen/projects/reinforce-ml\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = 'In statistics, overfitting is \"the production of an analysis that corresponds too closely ' \\\n",
    "             'or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_nlp = model.nlp(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subm = 'When the model memorizes the training data and performs badly with the test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_nlp = model.nlp(user_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root score: 0.38894438104970114\n",
      "sentence similarity score: 0.8831680417060852\n",
      "bonus score: 0.5019652446111044\n",
      "total calculated score: 0.8454684919553543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84546849195535434"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(definition, user_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(query_vec, def_vec):\n",
    "    return (np.sum((query_vec * def_vec))\n",
    "            / (np.sqrt(np.sum((query_vec ** 2)))\n",
    "               * np.sqrt(np.sum((def_vec ** 2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168551"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(dog.vector, cat.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88316804"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, uq_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhaskar = \"Overfitting is where the model fits to each and every point in the feature set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_nlp = model.nlp(bhaskar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90095067"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, b_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emily = \"Overfitting is when your predictive model is trying to be too close to too many points and so it loses its predictive power\"\n",
    "e_nlp = model.nlp(emily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176628"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, e_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = \"Costco sells a hot dog and a soda for $1.50\"\n",
    "r_nlp = model.nlp(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60963613"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, r_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hack = 'statistics overfitting set data observations'\n",
    "hack_nlp = model.nlp(hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66674113"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(def_nlp.vector, hack_nlp.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = def_nlp.noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[statistics,\n",
       " overfitting,\n",
       " the production,\n",
       " an analysis,\n",
       " a particular set,\n",
       " data,\n",
       " additional data,\n",
       " future observations]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_root = [chunk.root.lemma_ for chunk in list(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_root = set(nc_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis',\n",
       " 'datum',\n",
       " 'observation',\n",
       " 'overfitting',\n",
       " 'production',\n",
       " 'set',\n",
       " 'statistic'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(def_nlp.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In prep\n",
      "statistics pobj\n",
      ", punct\n",
      "overfitting nsubj\n",
      "is ROOT\n",
      "\" punct\n",
      "the det\n",
      "production attr\n",
      "of prep\n",
      "an det\n",
      "analysis pobj\n",
      "that nsubj\n",
      "corresponds relcl\n",
      "too advmod\n",
      "closely advmod\n",
      "or cc\n",
      "exactly conj\n",
      "to prep\n",
      "a det\n",
      "particular amod\n",
      "set pobj\n",
      "of prep\n",
      "data pobj\n",
      ", punct\n",
      "and cc\n",
      "may aux\n",
      "therefore advmod\n",
      "fail conj\n",
      "to aux\n",
      "fit xcomp\n",
      "additional amod\n",
      "data dobj\n",
      "or cc\n",
      "predict conj\n",
      "future amod\n",
      "observations dobj\n",
      "reliably advmod\n",
      "\" punct\n"
     ]
    }
   ],
   "source": [
    "for token in sent:\n",
    "    print(token, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobjs = [token.lemma_ for token in sent if token.dep_ == 'pobj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistic', 'analysis', 'set', 'datum']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pobjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get:\n",
    "* list of multiword noun chunks (remove det tokens)\n",
    "* list of lemmatized roots of noun chunks\n",
    "* overall sentence embedding\n",
    "\n",
    "score:\n",
    "top noun chunks that match / total num of noun chunks in the definition * sentence similarity + num of multiword noun chunks that match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36585009"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(model.nlp('rain').vector, model.nlp('umbrella').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mw_nc(doc):\n",
    "    \"\"\"Get list of multiword noun chunks.\n",
    "    \n",
    "    Tokens with dependency of 'det' are removed.\n",
    "    \n",
    "    Arguments:\n",
    "        doc (spaCy doc object)\n",
    "    \n",
    "    Returns:\n",
    "        pruned_mw (list): list of multiword noun chunks\n",
    "    \"\"\"\n",
    "    mw_nc = list(doc.noun_chunks)\n",
    "    \n",
    "    # remove det tokens\n",
    "\n",
    "    pruned_mw = []\n",
    "\n",
    "    for chunk in mw_nc:\n",
    "        replace = []\n",
    "        for token in chunk:\n",
    "            if token.dep_ is not 'det':\n",
    "                token = token.lemma_\n",
    "                replace.append(token)\n",
    "        if len(replace) > 1:\n",
    "            pruned_mw.append(\" \".join(replace))\n",
    "    \n",
    "    return pruned_mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_roots(doc):\n",
    "    \"\"\"Get list of lemmatized roots of noun chunks.\n",
    "    \n",
    "    Arguments:\n",
    "        doc (spaCy doc object)\n",
    "    \n",
    "    Returns:\n",
    "        lemma_roots (list): list of lemmatized roots of noun chunks\n",
    "    \"\"\"\n",
    "    nc = list(doc.noun_chunks)\n",
    "\n",
    "    roots = [token.root.lemma_ for token in nc]\n",
    "    \n",
    "    return roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistic',\n",
       " 'overfitting',\n",
       " 'production',\n",
       " 'analysis',\n",
       " 'set',\n",
       " 'datum',\n",
       " 'datum',\n",
       " 'observation']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemma_roots(def_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
